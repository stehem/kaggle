{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "sales_train = sales_train[sales_train['year'] != 2013]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "sales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "sales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "sales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "ids_reject = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < 1000)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['item_cnt_block'] = training['item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\", \"shop_cat\", \"shop_item\", \"date_block_num\"]\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\",  \"date_block_num\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>2635</td>\n",
       "      <td>32</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29714</th>\n",
       "      <td>11655</td>\n",
       "      <td>26</td>\n",
       "      <td>1.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18564</th>\n",
       "      <td>7007</td>\n",
       "      <td>32</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18613</th>\n",
       "      <td>7019</td>\n",
       "      <td>31</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52793</th>\n",
       "      <td>20717</td>\n",
       "      <td>31</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41385</th>\n",
       "      <td>16046</td>\n",
       "      <td>33</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>4364</td>\n",
       "      <td>32</td>\n",
       "      <td>0.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41371</th>\n",
       "      <td>16045</td>\n",
       "      <td>27</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38581</th>\n",
       "      <td>15193</td>\n",
       "      <td>15</td>\n",
       "      <td>0.061224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>12563</td>\n",
       "      <td>28</td>\n",
       "      <td>0.113636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  date_block_num  item_cnt_block\n",
       "5858      2635              32        0.255814\n",
       "29714    11655              26        1.239130\n",
       "18564     7007              32        0.046512\n",
       "18613     7019              31        0.380952\n",
       "52793    20717              31        0.261905\n",
       "41385    16046              33        0.295455\n",
       "11450     4364              32        0.116279\n",
       "41371    16045              27        0.042553\n",
       "38581    15193              15        0.061224\n",
       "31935    12563              28        0.113636"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['item_id','date_block_num']\n",
    "\n",
    "training.groupby(cols,as_index=False)['item_cnt_block'].mean().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:946: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  'representation', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_block\n",
      "cat_block\n",
      "shop_cat_block\n",
      "shop_item_block\n"
     ]
    }
   ],
   "source": [
    "def add_block_units_stats(df, cols, name):\n",
    "    print(name)\n",
    "    name_units = name + '_units'\n",
    "    name_mean = name + '_mean'\n",
    "    name_median = name + '_median'\n",
    "    name_max = name + '_max'\n",
    "    name_min = name + '_min'\n",
    "    name_std = name + '_std'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        df.drop(columns=[name_units, name_mean, name_median],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    block_units = df.groupby(cols,as_index=False)['item_cnt_block'].sum()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_units})\n",
    "    df = df.merge(block_units, on=cols, how='left')\n",
    "    df[name_units].fillna(0,inplace=True)\n",
    "    df[name_units] = pd.to_numeric(df[name_units].astype(int),downcast='unsigned')\n",
    "    del block_units\n",
    "    \n",
    "    block_units_med = df.groupby(cols,as_index=False)['item_cnt_block'].median()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_median})\n",
    "    df = df.merge(block_units_med, on=cols, how='left')\n",
    "    df[name_median].fillna(0,inplace=True)\n",
    "    df[name_median] = pd.to_numeric(df[name_median].astype(int),downcast='unsigned')\n",
    "    del block_units_med\n",
    "    \n",
    "    block_means = df.groupby(cols,as_index=False)['item_cnt_block'].mean()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_mean})\n",
    "    df = df.merge(block_means, on=cols, how='left')\n",
    "    df[name_mean].fillna(0,inplace=True)\n",
    "    df[name_mean] = pd.to_numeric(df[name_mean],downcast='float')\n",
    "    del block_means\n",
    "    \n",
    "    block_max = df.groupby(cols,as_index=False)['item_cnt_block'].max()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_max})\n",
    "    df = df.merge(block_max, on=cols, how='left')\n",
    "    df[name_max].fillna(0,inplace=True)\n",
    "    df[name_max] = pd.to_numeric(df[name_max],downcast='float')\n",
    "    del block_max\n",
    "    \n",
    "    block_min = df.groupby(cols,as_index=False)['item_cnt_block'].min()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_min})\n",
    "    df = df.merge(block_min, on=cols, how='left')\n",
    "    df[name_min].fillna(0,inplace=True)\n",
    "    df[name_min] = pd.to_numeric(df[name_min],downcast='float')\n",
    "    del block_min\n",
    "    \n",
    "    block_std = df.groupby(cols,as_index=False)['item_cnt_block'].std()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_std})\n",
    "    df = df.merge(block_std, on=cols, how='left')\n",
    "    df[name_std].fillna(0,inplace=True)\n",
    "    df[name_std] = pd.to_numeric(df[name_std],downcast='float')\n",
    "    del block_std\n",
    "    \n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "training = add_block_units_stats(training, ['item_id','date_block_num'], 'item_block')\n",
    "training = add_block_units_stats(training, ['shop_id','date_block_num'], 'shop_block')\n",
    "training = add_block_units_stats(training, ['item_category_id','date_block_num'], 'cat_block')\n",
    "training = add_block_units_stats(training, ['shop_id', 'item_category_id','date_block_num'], 'shop_cat_block')\n",
    "training = add_block_units_stats(training, ['shop_id', 'item_id','date_block_num'], 'shop_item_block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_items: 17054\n",
      "number_of_categories: 79\n",
      "number_of_shops: 54\n",
      "number_of_days: 669\n",
      "number_of_blocks: 22\n",
      "total_sales: 2085473.0\n",
      "average_price: 1015.5023073772021\n"
     ]
    }
   ],
   "source": [
    "number_of_items = sales_train['item_id'].nunique()\n",
    "print(\"number_of_items:\", number_of_items)\n",
    "number_of_categories = sales_train['item_category_id'].nunique()\n",
    "print(\"number_of_categories:\", number_of_categories)\n",
    "number_of_shops = sales_train['shop_id'].nunique()\n",
    "print(\"number_of_shops:\", number_of_shops)\n",
    "number_of_days = 365 + 365 - 30 - 31\n",
    "print(\"number_of_days:\", number_of_days)\n",
    "number_of_blocks = sales_train['date_block_num'].nunique()\n",
    "print(\"number_of_blocks:\", number_of_blocks)\n",
    "total_sales = sales_train['item_cnt_day'].sum()\n",
    "print(\"total_sales:\", total_sales)\n",
    "average_price = sales_train['item_price'].mean()\n",
    "print(\"average_price:\", average_price)\n",
    "\n",
    "training['item_units'] = pd.to_numeric(training.groupby(['date_block_num'])['item_block_units'].transform(np.sum),downcast='unsigned')\n",
    "training['cat_units'] = pd.to_numeric(training.groupby(['date_block_num'])['cat_block_units'].transform(np.sum),downcast='unsigned')\n",
    "training['shop_units'] = pd.to_numeric(training.groupby(['date_block_num'])['shop_block_units'].transform(np.sum),downcast='unsigned')\n",
    "\n",
    "training['item_share_of_total_units'] = pd.to_numeric(training['item_units'] * 100 / total_sales,downcast='float')\n",
    "training['category_share_of_total_units'] = pd.to_numeric(training['cat_units'] * 100 / total_sales,downcast='float')\n",
    "training['shop_share_of_units'] = pd.to_numeric(training['shop_units'] * 100 / total_sales,downcast='float')\n",
    "training['shop_item_units'] = pd.to_numeric(training.groupby(['date_block_num'])\\\n",
    "                                            ['shop_item_block_units'].transform(np.sum),downcast='unsigned')\n",
    "\n",
    "training['shop_item_share_of_total_units'] = pd.to_numeric(training['shop_item_units'] * 100\\\n",
    "                        / total_sales,downcast='float')\n",
    "training['shop_item_share_of_shop_units'] = pd.to_numeric(training['shop_item_units'] * 100\\\n",
    "                        / training['shop_units'],downcast='float')\n",
    "\n",
    "\n",
    "training['item_share_of_shop_units'] = pd.to_numeric(training['shop_item_units'] * 100 / training['shop_units'],downcast='float')\n",
    "\n",
    "training['shop_item_share_of_shop_units_mean'] = training.groupby('item_id')['shop_item_share_of_shop_units'].transform(np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\", \"shop_cat\", \"shop_item\", \"date_block_num\"]\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\",  \"date_block_num\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "shop\n",
      "cat\n",
      "shop_cat\n",
      "shop_item\n"
     ]
    }
   ],
   "source": [
    "def add_min_max_quantiles(df, cols, name):\n",
    "    print(name)\n",
    "\n",
    "    block_name = name+'_block_units'\n",
    "    units_name = name+'_units'\n",
    "    max_name = name+'_max_units_block'\n",
    "    min_name = name+'_min_units_block'\n",
    "    \n",
    "    try:\n",
    "        df.drop(columns=[units_name, max_name, min_name, min_max_name],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    df[units_name] = pd.to_numeric(df.groupby(['date_block_num'])[block_name].transform(np.sum), downcast='unsigned')\n",
    "    df[max_name] = pd.to_numeric(df.groupby(cols)[block_name].transform(np.max), downcast='unsigned')\n",
    "    df[min_name] = pd.to_numeric(df.groupby(cols)[block_name].transform(np.min), downcast='unsigned')\n",
    "    \n",
    "\n",
    "\n",
    "    for q in [0.25,0.50,0.75]:\n",
    "        qname = name+'_minmax_q' + str(q)\n",
    "        try:\n",
    "            df.drop(columns=[qname],inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        df[qname] =  pd.to_numeric(df[[min_name,max_name]].quantile(q,axis=1), downcast='unsigned')\n",
    "        \n",
    "    return df\n",
    "\n",
    "training = add_min_max_quantiles(training, ['item_id'], 'item')\n",
    "training = add_min_max_quantiles(training, ['shop_id'], 'shop')\n",
    "training = add_min_max_quantiles(training, ['item_category_id'], 'cat')\n",
    "training = add_min_max_quantiles(training, ['shop_id','item_category_id'], 'shop_cat')\n",
    "training = add_min_max_quantiles(training, ['shop_id','item_id'], 'shop_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_units 3\n",
      "item_block_mean 3\n",
      "item_block_median 3\n",
      "item_block_min 3\n",
      "item_block_max 3\n",
      "item_block_std 3\n",
      "shop_block_units 3\n",
      "shop_block_mean 3\n",
      "shop_block_median 3\n",
      "shop_block_min 3\n",
      "shop_block_max 3\n",
      "shop_block_std 3\n",
      "cat_block_units 3\n",
      "cat_block_mean 3\n",
      "cat_block_median 3\n",
      "cat_block_min 3\n",
      "cat_block_max 3\n",
      "cat_block_std 3\n",
      "shop_cat_block_units 3\n",
      "shop_cat_block_mean 3\n",
      "shop_cat_block_median 3\n",
      "shop_cat_block_min 3\n",
      "shop_cat_block_max 3\n",
      "shop_cat_block_std 3\n"
     ]
    }
   ],
   "source": [
    "def add_rolls(df, cols, name, rolls = [3]):\n",
    "    for roll in rolls:\n",
    "        print(name, roll)\n",
    "        roll_name = name+\"_rolling_\" + str(roll)\n",
    "        roll_name_tmp = roll_name + \"_tmp\"\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[roll_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "    \n",
    "        block_units_rolling_temp = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].rolling(roll,min_periods=2).mean().reset_index()\\\n",
    "            .rename(columns={name:roll_name_tmp})\\\n",
    "            [cols+[roll_name_tmp]]\n",
    "        \n",
    "    \n",
    "        df = df.merge(block_units_rolling_temp, on=cols, how='left')\n",
    "        #print(df.columns.values)\n",
    "        del block_units_rolling_temp\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "        block_units_rolling = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [roll_name_tmp].shift(1)\\\n",
    "            .rename(columns={roll_name_tmp:roll_name}).reset_index()\n",
    "\n",
    "        df = df.merge(block_units_rolling, on=cols, how='left')\n",
    "        df[roll_name].fillna(0,inplace=True)\n",
    "        df[roll_name] = pd.to_numeric(df[roll_name], downcast='float')\n",
    "        df.drop(columns=[roll_name_tmp], inplace=True)\n",
    "        del block_units_rolling\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_units')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_mean')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_median')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_min')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_max')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_std')\n",
    "\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_units')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_median')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_min')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_max')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_std')\n",
    "\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_units')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_mean')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_median')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_min')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_max')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_std')\n",
    "\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_units')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_min')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_max')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_std')\n",
    "#training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 3\n"
     ]
    }
   ],
   "source": [
    "training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n",
    "\n",
    "training['block_total'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.sum)\n",
    "\n",
    "training['item_share_block'] = training['item_block_units'] * 100 / training['block_total']\n",
    "training['shop_share_block'] = training['shop_block_units'] * 100 / training['block_total']\n",
    "training['comp2'] = training['item_share_block'] * training['shop_share_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_units 1\n",
      "item_block_mean 1\n",
      "item_block_median 1\n",
      "item_block_min 1\n",
      "item_block_max 1\n",
      "item_block_std 1\n",
      "shop_block_units 1\n",
      "shop_block_mean 1\n",
      "shop_block_median 1\n",
      "shop_block_min 1\n",
      "shop_block_max 1\n",
      "shop_block_std 1\n",
      "cat_block_units 1\n",
      "cat_block_mean 1\n",
      "cat_block_median 1\n",
      "cat_block_min 1\n",
      "cat_block_max 1\n",
      "cat_block_std 1\n",
      "shop_cat_block_units 1\n",
      "shop_cat_block_mean 1\n",
      "shop_cat_block_median 1\n",
      "shop_cat_block_min 1\n",
      "shop_cat_block_max 1\n",
      "shop_cat_block_std 1\n",
      "shop_item_block_units 1\n",
      "shop_item_block_mean 1\n",
      "shop_item_block_median 1\n",
      "shop_item_block_min 1\n",
      "shop_item_block_max 1\n",
      "shop_item_block_std 1\n"
     ]
    }
   ],
   "source": [
    "def add_lags(df, cols, name, lags = [1]):\n",
    "    \n",
    "    for lag in lags:\n",
    "        print(name, lag)\n",
    "        lag_name = name + \"_lag_\" + str(lag)\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[lag_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "        result = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].shift(lag)\\\n",
    "            .rename(columns={name:lag_name}).reset_index()\n",
    "\n",
    "        df = df.merge(result, on=cols, how='left')\n",
    "        df[lag_name].fillna(0,inplace=True)\n",
    "        if \"mean\" in name:\n",
    "            df[lag_name] = pd.to_numeric(df[lag_name], downcast='float')\n",
    "        else:\n",
    "            df[lag_name] = pd.to_numeric(df[lag_name].astype(int), downcast='unsigned')\n",
    "        del result\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "                                         \n",
    "\n",
    "                                        \n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_units')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_mean')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_median')                                        \n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_min')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_max')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_units')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_median')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_min')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_max')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_std')\n",
    "\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_units')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_mean')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_median')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_min')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_max')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_units')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_min')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_max')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_units')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_median')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_min')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_max')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_share_block 1\n",
      "shop_share_block 1\n",
      "comp2 1\n"
     ]
    }
   ],
   "source": [
    "training = add_lags(training, ['item_id','date_block_num'], 'item_share_block')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_share_block')\n",
    "training = add_lags(training, ['shop_id', 'item_id', 'date_block_num'], 'comp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_shops = training.groupby('shop_id')['item_cnt_block'].sum().sum()\n",
    "training['shop_share'] = training.groupby('shop_id')['item_cnt_block'].transform(np.sum) *100 / total_sum_shops\n",
    "\n",
    "total_sum_items = training.groupby('item_id')['item_cnt_block'].sum().sum()\n",
    "training['item_share'] = training.groupby('item_id')['item_cnt_block'].transform(np.sum) *100 / total_sum_items\n",
    "\n",
    "training['comp1'] = training['shop_share'] * training['item_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_block_units_lag_comp1'] = pd.to_numeric(training['shop_block_units_lag_1'] * training['item_share_of_shop_units'],downcast='unsigned')\n",
    "\n",
    "#training['shop_share_item_units_comp'] = training['item_units'] * training['shop_share_of_units']\n",
    "training['item_block_units_lag_comp1'] = pd.to_numeric(training['item_block_units_lag_1'] * training['item_share_of_shop_units'],downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['blocks_without_sales'] = training['item_id'].map(training[training['item_cnt_block'] == 0].groupby(['item_id'])['date_block_num'].unique().apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train['item_days_of_activity'] = pd.to_numeric(sales_train.groupby(['item_id'])['date'].transform(\"nunique\"), downcast='unsigned') \n",
    "sales_train['item_blocks_of_activity'] = pd.to_numeric(sales_train.groupby(['item_id'])['date_block_num'].transform(\"nunique\"), downcast='unsigned') \n",
    "\n",
    "def get_number_of_days_since_start(day,month, year):\n",
    "    days = 0\n",
    "    if year == 2015:\n",
    "        days = 365\n",
    "    def is_even(num):\n",
    "        return num % 2 == 0\n",
    "    half_of_month = int(month/2)\n",
    "    even = (30*half_of_month) + (31*half_of_month)\n",
    "    if is_even(month):\n",
    "        days = days + even - 30 - day\n",
    "    else:\n",
    "        days = days + even + day\n",
    "    return days\n",
    "\n",
    "sales_train['item_days_since_start'] = pd.to_numeric(sales_train.apply(lambda row: get_number_of_days_since_start(row['day'],row['month'], row['year']),axis=1), downcast='unsigned') \n",
    "\n",
    "def get_average_days_between_sales(days):\n",
    "    days = sorted(np.unique(days))\n",
    "    if len(days) == 0:\n",
    "        return 9999\n",
    "    if len(days) == 1:\n",
    "        return 999\n",
    "    return np.mean(np.ediff1d(days)) / len(days)\n",
    "\n",
    "average_days_between_sales = sales_train.groupby(['item_id'])['item_days_since_start'].apply(list).apply(lambda x: get_average_days_between_sales(x))\n",
    "\n",
    "sales_train['item_mean_day_between_activity'] = pd.to_numeric(sales_train['item_id'].map(average_days_between_sales), downcast='unsigned')\n",
    "\n",
    "training['item_mean_day_between_activity'] = training['item_id'].map(sales_train.drop_duplicates('item_id').set_index('item_id')['item_mean_day_between_activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n",
    "\n",
    "\n",
    "shop_cat_models = {}\n",
    "\n",
    "for shop_id in all_shop_ids:\n",
    "    shop_cat_models[shop_id] = {}\n",
    "    for cat_id in training['item_category_id'].unique():\n",
    "    \n",
    "        shop_cat_data = training[(training['shop_id'] == shop_id) & (training['item_category_id'] == cat_id)].groupby(['date_block_num'],as_index=False)['item_cnt_block'].sum()\n",
    "        if len(shop_cat_data) == 0:\n",
    "            continue\n",
    "\n",
    "        regr = linear_model.Ridge()\n",
    "\n",
    "        X = shop_cat_data['date_block_num'].values.reshape(len(shop_cat_data),1)\n",
    "        y = shop_cat_data['item_cnt_block'].values.reshape(len(shop_cat_data),1)\n",
    "        \n",
    "        #y = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        regr.fit(X, y)\n",
    "        shop_cat_models[shop_id][cat_id] = regr\n",
    "            \n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    #preds = regr.predict(X)\n",
    "\n",
    "\n",
    "print(\"applying\")\n",
    "\n",
    "def predict(shop_id, cat_id, dbn):\n",
    "    return shop_cat_models[shop_id][cat_id].predict([[dbn]])[0][0]\n",
    "\n",
    "training['shop_cat_pred'] = training.apply(lambda row: predict(row['shop_id'],row['item_category_id'], row['date_block_num']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n",
    "\n",
    "\n",
    "item_models = {}\n",
    "\n",
    "for item_id in training['item_id'].unique():\n",
    "    \n",
    "    item_data = training[(training['item_id'] == item_id)].groupby(['date_block_num'],as_index=False)['item_cnt_block'].sum()\n",
    "    if len(item_data) == 0:\n",
    "        continue\n",
    "\n",
    "    regr = linear_model.Ridge()\n",
    "\n",
    "    X = item_data['date_block_num'].values.reshape(len(item_data),1)\n",
    "    y = item_data['item_cnt_block'].values.reshape(len(item_data),1)\n",
    "\n",
    "    #y = MinMaxScaler().fit_transform(y)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X, y)\n",
    "    item_models[item_id] = regr\n",
    "\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    #preds = regr.predict(X)\n",
    "\n",
    "\n",
    "print(\"applying\")\n",
    "\n",
    "def predict(item_id, dbn):\n",
    "    if item_id in item_models:\n",
    "        return item_models[item_id].predict([[dbn]])[0][0]\n",
    "\n",
    "training['item_pred'] = training.apply(lambda row: predict(row['item_id'], row['date_block_num']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "      <th>month_mean_encoding</th>\n",
       "      <th>date_block_num_mean_encoding</th>\n",
       "      <th>item_block_units</th>\n",
       "      <th>item_block_median</th>\n",
       "      <th>item_block_mean</th>\n",
       "      <th>item_block_max</th>\n",
       "      <th>item_block_min</th>\n",
       "      <th>item_block_std</th>\n",
       "      <th>shop_block_units</th>\n",
       "      <th>shop_block_median</th>\n",
       "      <th>shop_block_mean</th>\n",
       "      <th>shop_block_max</th>\n",
       "      <th>shop_block_min</th>\n",
       "      <th>shop_block_std</th>\n",
       "      <th>cat_block_units</th>\n",
       "      <th>cat_block_median</th>\n",
       "      <th>cat_block_mean</th>\n",
       "      <th>cat_block_max</th>\n",
       "      <th>cat_block_min</th>\n",
       "      <th>cat_block_std</th>\n",
       "      <th>shop_cat_block_units</th>\n",
       "      <th>shop_cat_block_median</th>\n",
       "      <th>shop_cat_block_mean</th>\n",
       "      <th>shop_cat_block_max</th>\n",
       "      <th>shop_cat_block_min</th>\n",
       "      <th>shop_cat_block_std</th>\n",
       "      <th>shop_item_block_units</th>\n",
       "      <th>shop_item_block_median</th>\n",
       "      <th>shop_item_block_mean</th>\n",
       "      <th>shop_item_block_max</th>\n",
       "      <th>shop_item_block_min</th>\n",
       "      <th>shop_item_block_std</th>\n",
       "      <th>item_units</th>\n",
       "      <th>cat_units</th>\n",
       "      <th>shop_units</th>\n",
       "      <th>item_share_of_total_units</th>\n",
       "      <th>category_share_of_total_units</th>\n",
       "      <th>shop_share_of_units</th>\n",
       "      <th>shop_item_units</th>\n",
       "      <th>shop_item_share_of_total_units</th>\n",
       "      <th>shop_item_share_of_shop_units</th>\n",
       "      <th>item_share_of_shop_units</th>\n",
       "      <th>shop_item_share_of_shop_units_mean</th>\n",
       "      <th>item_max_units_block</th>\n",
       "      <th>item_min_units_block</th>\n",
       "      <th>item_minmax_q0.25</th>\n",
       "      <th>item_minmax_q0.5</th>\n",
       "      <th>item_minmax_q0.75</th>\n",
       "      <th>shop_max_units_block</th>\n",
       "      <th>shop_min_units_block</th>\n",
       "      <th>shop_minmax_q0.25</th>\n",
       "      <th>shop_minmax_q0.5</th>\n",
       "      <th>shop_minmax_q0.75</th>\n",
       "      <th>cat_max_units_block</th>\n",
       "      <th>cat_min_units_block</th>\n",
       "      <th>cat_minmax_q0.25</th>\n",
       "      <th>cat_minmax_q0.5</th>\n",
       "      <th>cat_minmax_q0.75</th>\n",
       "      <th>shop_cat_units</th>\n",
       "      <th>shop_cat_max_units_block</th>\n",
       "      <th>shop_cat_min_units_block</th>\n",
       "      <th>shop_cat_minmax_q0.25</th>\n",
       "      <th>shop_cat_minmax_q0.5</th>\n",
       "      <th>shop_cat_minmax_q0.75</th>\n",
       "      <th>shop_item_max_units_block</th>\n",
       "      <th>shop_item_min_units_block</th>\n",
       "      <th>shop_item_minmax_q0.25</th>\n",
       "      <th>shop_item_minmax_q0.5</th>\n",
       "      <th>shop_item_minmax_q0.75</th>\n",
       "      <th>item_block_units_rolling_3</th>\n",
       "      <th>item_block_mean_rolling_3</th>\n",
       "      <th>item_block_median_rolling_3</th>\n",
       "      <th>item_block_min_rolling_3</th>\n",
       "      <th>item_block_max_rolling_3</th>\n",
       "      <th>item_block_std_rolling_3</th>\n",
       "      <th>shop_block_units_rolling_3</th>\n",
       "      <th>shop_block_mean_rolling_3</th>\n",
       "      <th>shop_block_median_rolling_3</th>\n",
       "      <th>shop_block_min_rolling_3</th>\n",
       "      <th>shop_block_max_rolling_3</th>\n",
       "      <th>shop_block_std_rolling_3</th>\n",
       "      <th>cat_block_units_rolling_3</th>\n",
       "      <th>cat_block_mean_rolling_3</th>\n",
       "      <th>cat_block_median_rolling_3</th>\n",
       "      <th>cat_block_min_rolling_3</th>\n",
       "      <th>cat_block_max_rolling_3</th>\n",
       "      <th>cat_block_std_rolling_3</th>\n",
       "      <th>shop_cat_block_units_rolling_3</th>\n",
       "      <th>shop_cat_block_mean_rolling_3</th>\n",
       "      <th>shop_cat_block_median_rolling_3</th>\n",
       "      <th>shop_cat_block_min_rolling_3</th>\n",
       "      <th>shop_cat_block_max_rolling_3</th>\n",
       "      <th>shop_cat_block_std_rolling_3</th>\n",
       "      <th>shop_item_block_mean_rolling_3</th>\n",
       "      <th>block_total</th>\n",
       "      <th>item_share_block</th>\n",
       "      <th>shop_share_block</th>\n",
       "      <th>comp2</th>\n",
       "      <th>item_block_units_lag_1</th>\n",
       "      <th>item_block_mean_lag_1</th>\n",
       "      <th>item_block_median_lag_1</th>\n",
       "      <th>item_block_min_lag_1</th>\n",
       "      <th>item_block_max_lag_1</th>\n",
       "      <th>item_block_std_lag_1</th>\n",
       "      <th>shop_block_units_lag_1</th>\n",
       "      <th>shop_block_mean_lag_1</th>\n",
       "      <th>shop_block_median_lag_1</th>\n",
       "      <th>shop_block_min_lag_1</th>\n",
       "      <th>shop_block_max_lag_1</th>\n",
       "      <th>shop_block_std_lag_1</th>\n",
       "      <th>cat_block_units_lag_1</th>\n",
       "      <th>cat_block_mean_lag_1</th>\n",
       "      <th>cat_block_median_lag_1</th>\n",
       "      <th>cat_block_min_lag_1</th>\n",
       "      <th>cat_block_max_lag_1</th>\n",
       "      <th>cat_block_std_lag_1</th>\n",
       "      <th>shop_cat_block_units_lag_1</th>\n",
       "      <th>shop_cat_block_mean_lag_1</th>\n",
       "      <th>shop_cat_block_median_lag_1</th>\n",
       "      <th>shop_cat_block_min_lag_1</th>\n",
       "      <th>shop_cat_block_max_lag_1</th>\n",
       "      <th>shop_cat_block_std_lag_1</th>\n",
       "      <th>shop_item_block_units_lag_1</th>\n",
       "      <th>shop_item_block_mean_lag_1</th>\n",
       "      <th>shop_item_block_median_lag_1</th>\n",
       "      <th>shop_item_block_min_lag_1</th>\n",
       "      <th>shop_item_block_max_lag_1</th>\n",
       "      <th>shop_item_block_std_lag_1</th>\n",
       "      <th>item_share_block_lag_1</th>\n",
       "      <th>shop_share_block_lag_1</th>\n",
       "      <th>comp2_lag_1</th>\n",
       "      <th>shop_share</th>\n",
       "      <th>item_share</th>\n",
       "      <th>comp1</th>\n",
       "      <th>shop_block_units_lag_comp1</th>\n",
       "      <th>item_block_units_lag_comp1</th>\n",
       "      <th>blocks_without_sales</th>\n",
       "      <th>item_mean_day_between_activity</th>\n",
       "      <th>shop_cat_pred</th>\n",
       "      <th>item_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2494448</th>\n",
       "      <td>21137</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.484878</td>\n",
       "      <td>0.195796</td>\n",
       "      <td>0.401477</td>\n",
       "      <td>0.334405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463794</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1365</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260695</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>3.369748</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2573868</td>\n",
       "      <td>530591380</td>\n",
       "      <td>233461527</td>\n",
       "      <td>123.418907</td>\n",
       "      <td>728.626282</td>\n",
       "      <td>897.310242</td>\n",
       "      <td>58497</td>\n",
       "      <td>2.804975</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1851</td>\n",
       "      <td>1287</td>\n",
       "      <td>1428.00</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1710.00</td>\n",
       "      <td>1365</td>\n",
       "      <td>1</td>\n",
       "      <td>342.00</td>\n",
       "      <td>683.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>12058895</td>\n",
       "      <td>401</td>\n",
       "      <td>167</td>\n",
       "      <td>225.50</td>\n",
       "      <td>284.0</td>\n",
       "      <td>342.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.082226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>541.666687</td>\n",
       "      <td>0.188718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58497.0</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.923603</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>4</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0.139251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>4.175000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257843</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>32.247559</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>3</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>399.397260</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377987</th>\n",
       "      <td>11498</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>0.337821</td>\n",
       "      <td>0.290225</td>\n",
       "      <td>0.279504</td>\n",
       "      <td>0.438036</td>\n",
       "      <td>0.373480</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212169</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.284719</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124294</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2177047</td>\n",
       "      <td>378130476</td>\n",
       "      <td>158924431</td>\n",
       "      <td>104.391045</td>\n",
       "      <td>1655.887817</td>\n",
       "      <td>1442.138672</td>\n",
       "      <td>50629</td>\n",
       "      <td>2.427699</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>11.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.50</td>\n",
       "      <td>1438</td>\n",
       "      <td>522</td>\n",
       "      <td>751.00</td>\n",
       "      <td>980.0</td>\n",
       "      <td>1209.00</td>\n",
       "      <td>3796</td>\n",
       "      <td>1376</td>\n",
       "      <td>1981.00</td>\n",
       "      <td>2586.0</td>\n",
       "      <td>3191.00</td>\n",
       "      <td>8793732</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>15.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.181265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.333313</td>\n",
       "      <td>0.229463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2134.000000</td>\n",
       "      <td>0.279663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.666666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.101615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50629.0</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>5</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>681</td>\n",
       "      <td>0.223939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.324960</td>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.037995</td>\n",
       "      <td>21.694807</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>22</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>21.110445</td>\n",
       "      <td>13.645644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858540</th>\n",
       "      <td>6952</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.377221</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>0.435371</td>\n",
       "      <td>0.375346</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318254</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080711</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2177047</td>\n",
       "      <td>378130476</td>\n",
       "      <td>158924431</td>\n",
       "      <td>104.391045</td>\n",
       "      <td>1655.887817</td>\n",
       "      <td>1442.138672</td>\n",
       "      <td>50629</td>\n",
       "      <td>2.427699</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1480</td>\n",
       "      <td>606</td>\n",
       "      <td>824.50</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1261.50</td>\n",
       "      <td>675</td>\n",
       "      <td>171</td>\n",
       "      <td>297.00</td>\n",
       "      <td>423.0</td>\n",
       "      <td>549.00</td>\n",
       "      <td>8793732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.033366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>0.343248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453.333344</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.666666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50629.0</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.678741</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "      <td>0.330155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.715012</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>31.984707</td>\n",
       "      <td>0.063715</td>\n",
       "      <td>7</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.359606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019374</th>\n",
       "      <td>16377</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.916918</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>0.565155</td>\n",
       "      <td>0.528563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946554</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094265</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586650</td>\n",
       "      <td>490180900</td>\n",
       "      <td>194611629</td>\n",
       "      <td>171.982574</td>\n",
       "      <td>850.382507</td>\n",
       "      <td>1093.897461</td>\n",
       "      <td>71733</td>\n",
       "      <td>3.439651</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.043287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4116</td>\n",
       "      <td>1392</td>\n",
       "      <td>2073.00</td>\n",
       "      <td>2754.0</td>\n",
       "      <td>3435.00</td>\n",
       "      <td>675</td>\n",
       "      <td>171</td>\n",
       "      <td>297.00</td>\n",
       "      <td>423.0</td>\n",
       "      <td>549.00</td>\n",
       "      <td>9803618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2860.666748</td>\n",
       "      <td>1.127768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>0.075637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71733.0</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.839112</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4116</td>\n",
       "      <td>1.514906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>0.082647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.181697</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>151.713974</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>6</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215317</th>\n",
       "      <td>2140</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>1.124088</td>\n",
       "      <td>0.296085</td>\n",
       "      <td>0.314365</td>\n",
       "      <td>0.391270</td>\n",
       "      <td>0.338399</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249656</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192062</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2293921</td>\n",
       "      <td>415853516</td>\n",
       "      <td>193809651</td>\n",
       "      <td>109.995239</td>\n",
       "      <td>1405.266724</td>\n",
       "      <td>1055.442017</td>\n",
       "      <td>53347</td>\n",
       "      <td>2.558029</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>0.036109</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>37.75</td>\n",
       "      <td>70.5</td>\n",
       "      <td>103.25</td>\n",
       "      <td>1356</td>\n",
       "      <td>413</td>\n",
       "      <td>648.75</td>\n",
       "      <td>884.5</td>\n",
       "      <td>1120.25</td>\n",
       "      <td>11613</td>\n",
       "      <td>4757</td>\n",
       "      <td>6471.00</td>\n",
       "      <td>8185.0</td>\n",
       "      <td>9899.00</td>\n",
       "      <td>9671012</td>\n",
       "      <td>252</td>\n",
       "      <td>88</td>\n",
       "      <td>129.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>211.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.289406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>922.666687</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5802.333496</td>\n",
       "      <td>0.247697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.666672</td>\n",
       "      <td>0.291058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>53347.0</td>\n",
       "      <td>0.018745</td>\n",
       "      <td>0.471704</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>14</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1113</td>\n",
       "      <td>0.322049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5742</td>\n",
       "      <td>0.245448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0.258528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.345255</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.082240</td>\n",
       "      <td>30.635838</td>\n",
       "      <td>0.385356</td>\n",
       "      <td>15</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>150.927703</td>\n",
       "      <td>-8.029893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592282</th>\n",
       "      <td>13383</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>0.327276</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.437078</td>\n",
       "      <td>0.374134</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226187</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221305</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2177047</td>\n",
       "      <td>378130476</td>\n",
       "      <td>158924431</td>\n",
       "      <td>104.391045</td>\n",
       "      <td>1655.887817</td>\n",
       "      <td>1442.138672</td>\n",
       "      <td>50629</td>\n",
       "      <td>2.427699</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.044335</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1600</td>\n",
       "      <td>587</td>\n",
       "      <td>840.25</td>\n",
       "      <td>1093.5</td>\n",
       "      <td>1346.75</td>\n",
       "      <td>639</td>\n",
       "      <td>383</td>\n",
       "      <td>447.00</td>\n",
       "      <td>511.0</td>\n",
       "      <td>575.00</td>\n",
       "      <td>8793732</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.072197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>0.272495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.666687</td>\n",
       "      <td>0.205183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.666666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.061638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50629.0</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.107922</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>0.235449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>0.166025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.489296</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>22.809811</td>\n",
       "      <td>0.063715</td>\n",
       "      <td>21</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>2.281495</td>\n",
       "      <td>3.821197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316364</th>\n",
       "      <td>2921</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693902</td>\n",
       "      <td>0.287891</td>\n",
       "      <td>0.485467</td>\n",
       "      <td>0.567823</td>\n",
       "      <td>0.640303</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564875</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605978</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2059098</td>\n",
       "      <td>183422884</td>\n",
       "      <td>68308338</td>\n",
       "      <td>98.735298</td>\n",
       "      <td>557.388733</td>\n",
       "      <td>1215.967041</td>\n",
       "      <td>44763</td>\n",
       "      <td>2.146420</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>24.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>1175</td>\n",
       "      <td>528</td>\n",
       "      <td>689.75</td>\n",
       "      <td>851.5</td>\n",
       "      <td>1013.25</td>\n",
       "      <td>397</td>\n",
       "      <td>83</td>\n",
       "      <td>161.50</td>\n",
       "      <td>240.0</td>\n",
       "      <td>318.50</td>\n",
       "      <td>3987454</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44763.0</td>\n",
       "      <td>0.084892</td>\n",
       "      <td>0.461631</td>\n",
       "      <td>0.039189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.295708</td>\n",
       "      <td>0.058175</td>\n",
       "      <td>0.075378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>3.676050</td>\n",
       "      <td>21.900938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219249</th>\n",
       "      <td>2196</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.819648</td>\n",
       "      <td>1.113248</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.405230</td>\n",
       "      <td>0.363275</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872513</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6365</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262962</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716505</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2367014</td>\n",
       "      <td>412107515</td>\n",
       "      <td>149323330</td>\n",
       "      <td>113.500099</td>\n",
       "      <td>1225.643188</td>\n",
       "      <td>981.758606</td>\n",
       "      <td>50362</td>\n",
       "      <td>2.414896</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.039331</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>39.25</td>\n",
       "      <td>74.5</td>\n",
       "      <td>109.75</td>\n",
       "      <td>4524</td>\n",
       "      <td>1882</td>\n",
       "      <td>2542.50</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3863.50</td>\n",
       "      <td>11613</td>\n",
       "      <td>4757</td>\n",
       "      <td>6471.00</td>\n",
       "      <td>8185.0</td>\n",
       "      <td>9899.00</td>\n",
       "      <td>8768245</td>\n",
       "      <td>548</td>\n",
       "      <td>185</td>\n",
       "      <td>275.75</td>\n",
       "      <td>366.5</td>\n",
       "      <td>457.25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.25</td>\n",
       "      <td>30.333334</td>\n",
       "      <td>0.628628</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3560.666748</td>\n",
       "      <td>1.281519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7522.666504</td>\n",
       "      <td>0.318376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.333334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.333344</td>\n",
       "      <td>0.982165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.333334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>50362.0</td>\n",
       "      <td>0.019856</td>\n",
       "      <td>1.232914</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>21</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3114</td>\n",
       "      <td>1.070839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7806</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>0.921105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.070755</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.292074</td>\n",
       "      <td>105.025291</td>\n",
       "      <td>0.708263</td>\n",
       "      <td>18</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>380.231195</td>\n",
       "      <td>25.491818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822989</th>\n",
       "      <td>6624</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.261962</td>\n",
       "      <td>0.300891</td>\n",
       "      <td>0.455610</td>\n",
       "      <td>0.430599</td>\n",
       "      <td>0.523595</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.626822</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2173738</td>\n",
       "      <td>241470089</td>\n",
       "      <td>77456052</td>\n",
       "      <td>104.232376</td>\n",
       "      <td>1281.326782</td>\n",
       "      <td>1654.606812</td>\n",
       "      <td>44362</td>\n",
       "      <td>2.127191</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10.75</td>\n",
       "      <td>20.5</td>\n",
       "      <td>30.25</td>\n",
       "      <td>1272</td>\n",
       "      <td>444</td>\n",
       "      <td>651.00</td>\n",
       "      <td>858.0</td>\n",
       "      <td>1065.00</td>\n",
       "      <td>793</td>\n",
       "      <td>214</td>\n",
       "      <td>358.75</td>\n",
       "      <td>503.5</td>\n",
       "      <td>648.25</td>\n",
       "      <td>4927961</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.119122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>0.354653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.666656</td>\n",
       "      <td>0.569136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44362.0</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>1.298409</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "      <td>0.261023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>0.403061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.368098</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>25.429552</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>22</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>3.195560</td>\n",
       "      <td>9.680767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971714</th>\n",
       "      <td>8072</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267218</td>\n",
       "      <td>0.818710</td>\n",
       "      <td>0.233434</td>\n",
       "      <td>0.562547</td>\n",
       "      <td>0.633956</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1.586957</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>1.114024</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343685</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2059098</td>\n",
       "      <td>183422884</td>\n",
       "      <td>68308338</td>\n",
       "      <td>98.735298</td>\n",
       "      <td>557.388733</td>\n",
       "      <td>1215.967041</td>\n",
       "      <td>44763</td>\n",
       "      <td>2.146420</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>0.045094</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>19.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>4070</td>\n",
       "      <td>1645</td>\n",
       "      <td>2251.25</td>\n",
       "      <td>2857.5</td>\n",
       "      <td>3463.75</td>\n",
       "      <td>700</td>\n",
       "      <td>131</td>\n",
       "      <td>273.25</td>\n",
       "      <td>415.5</td>\n",
       "      <td>557.75</td>\n",
       "      <td>3987454</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>12.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44763.0</td>\n",
       "      <td>0.163081</td>\n",
       "      <td>0.869647</td>\n",
       "      <td>0.141823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.735360</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>0.082563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.042129</td>\n",
       "      <td>12.758191</td>\n",
       "      <td>31.601276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  item_cnt_block  item_category_id  month  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding  month_mean_encoding  date_block_num_mean_encoding  item_block_units  item_block_median  item_block_mean  item_block_max  item_block_min  item_block_std  shop_block_units  shop_block_median  shop_block_mean  shop_block_max  shop_block_min  shop_block_std  cat_block_units  cat_block_median  cat_block_mean  cat_block_max  cat_block_min  cat_block_std  shop_cat_block_units  shop_cat_block_median  shop_cat_block_mean  shop_cat_block_max  shop_cat_block_min  shop_cat_block_std  shop_item_block_units  shop_item_block_median  shop_item_block_mean  shop_item_block_max  shop_item_block_min  shop_item_block_std  item_units  cat_units  shop_units  item_share_of_total_units  category_share_of_total_units  shop_share_of_units  shop_item_units  shop_item_share_of_total_units  shop_item_share_of_shop_units  item_share_of_shop_units  shop_item_share_of_shop_units_mean  item_max_units_block  item_min_units_block  item_minmax_q0.25  item_minmax_q0.5  item_minmax_q0.75  shop_max_units_block  shop_min_units_block  shop_minmax_q0.25  shop_minmax_q0.5  shop_minmax_q0.75  cat_max_units_block  cat_min_units_block  cat_minmax_q0.25  cat_minmax_q0.5  cat_minmax_q0.75  shop_cat_units  shop_cat_max_units_block  shop_cat_min_units_block  shop_cat_minmax_q0.25  shop_cat_minmax_q0.5  shop_cat_minmax_q0.75  shop_item_max_units_block  shop_item_min_units_block  shop_item_minmax_q0.25  shop_item_minmax_q0.5  shop_item_minmax_q0.75  item_block_units_rolling_3  item_block_mean_rolling_3  item_block_median_rolling_3  item_block_min_rolling_3  item_block_max_rolling_3  item_block_std_rolling_3  shop_block_units_rolling_3  shop_block_mean_rolling_3  shop_block_median_rolling_3  shop_block_min_rolling_3  shop_block_max_rolling_3  shop_block_std_rolling_3  cat_block_units_rolling_3  cat_block_mean_rolling_3  cat_block_median_rolling_3  cat_block_min_rolling_3  cat_block_max_rolling_3  cat_block_std_rolling_3  shop_cat_block_units_rolling_3  shop_cat_block_mean_rolling_3  shop_cat_block_median_rolling_3  shop_cat_block_min_rolling_3  shop_cat_block_max_rolling_3  shop_cat_block_std_rolling_3  shop_item_block_mean_rolling_3  block_total  item_share_block  shop_share_block     comp2  item_block_units_lag_1  item_block_mean_lag_1  item_block_median_lag_1  item_block_min_lag_1  item_block_max_lag_1  item_block_std_lag_1  shop_block_units_lag_1  shop_block_mean_lag_1  shop_block_median_lag_1  shop_block_min_lag_1  shop_block_max_lag_1  shop_block_std_lag_1  cat_block_units_lag_1  cat_block_mean_lag_1  cat_block_median_lag_1  cat_block_min_lag_1  cat_block_max_lag_1  cat_block_std_lag_1  shop_cat_block_units_lag_1  shop_cat_block_mean_lag_1  shop_cat_block_median_lag_1  shop_cat_block_min_lag_1  shop_cat_block_max_lag_1  shop_cat_block_std_lag_1  shop_item_block_units_lag_1  shop_item_block_mean_lag_1  shop_item_block_median_lag_1  shop_item_block_min_lag_1  shop_item_block_max_lag_1  shop_item_block_std_lag_1  item_share_block_lag_1  shop_share_block_lag_1  comp2_lag_1  shop_share  item_share     comp1  shop_block_units_lag_comp1  item_block_units_lag_comp1  blocks_without_sales  item_mean_day_between_activity  shop_cat_pred  item_pred\n",
       "2494448  21137    20       33              0               61                10     0.085106               0.484878               0.195796                        0.401477             0.334405                      1                 0                  0.022727         1               0               0.0             1851              0                  0.463794         20              0               0.0             1365             0                 0.260695        20             0              0.0            401                   1                      3.369748             20                  0                   0.0                 0                      0                       0                     0                    0                    0.0                  2573868     530591380  233461527   123.418907                 728.626282                     897.310242           58497            2.804975                        0.025056                       0.025056                  0.027142                            4                     1                     1.75               2.5               3.25               1851                  1287                  1428.00            1569.0            1710.00            1365                 1                    342.00            683.0            1024.00           12058895        401                       167                       225.50                 284.0                 342.50                 0                          0                          0.00                    0.0                    0.00                    3.500000                    0.082226                   0.000000                     0.0                       3.000000                  0.0                       0.000000                    0.000000                   0.0                          0.0                       0.0                       0.0                       541.666687                 0.188718                  0.0                         0.0                      10.000000                0.0                      0.000000                        0.000000                       0.000000                         0.0                           0.000000                      0.0                           0.000000                        58497.0      0.001709          0.923603          0.001579  4                       0.093023               0                        0                     4                     0                     1287                    0.558594               0                        0                     20                    0                     491                    0.139251              0                       0                    8                    0                    167                         4.175000                   3                            0                         14                        0                         0                            0.0                         0                             0                          0                          0                          0                       1                       0            0.257843    0.000657    0.000169  32.247559                   0.100226                    3                     1.833333                        399.397260     2.000000 \n",
       "1377987  11498    4        29              0               37                6      0.337821               0.290225               0.279504                        0.438036             0.373480                      3                 0                  0.069767         1               0               0.0             666               0                  0.212169         20              0               0.0             2167             0                 0.284719        20             0              0.0            22                    0                      0.124294             2                   0                   0.0                 0                      0                       0                     0                    0                    0.0                  2177047     378130476  158924431   104.391045                 1655.887817                    1442.138672          50629            2.427699                        0.031857                       0.031857                  0.043519                            37                    3                     11.50              20.0              28.50              1438                  522                   751.00             980.0             1209.00            3796                 1376                 1981.00           2586.0           3191.00           8793732         36                        8                         15.00                  22.0                  29.00                  2                          0                          0.50                    1.0                    1.50                    8.333333                    0.181265                   0.000000                     0.0                       1.666667                  0.0                       681.333313                  0.229463                   0.0                          0.0                       20.0                      0.0                       2134.000000                0.279663                  0.0                         0.0                      19.666666                0.0                      17.000000                       0.101615                       0.000000                         0.0                           2.333333                      0.0                           0.000000                        50629.0      0.005925          0.021016          0.000125  5                       0.113636               0                        0                     2                     0                     681                     0.223939               0                        0                     20                    0                     1637                   0.220145              0                       0                    19                   0                    8                           0.047337                   0                            0                         2                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            1.324960    0.028677    0.037995  21.694807                   0.159286                    22                    0.015108                        21.110445      13.645644\n",
       "858540   6952     18       29              0               31                6      0.060606               0.377221               0.075075                        0.435371             0.375346                      5                 0                  0.116279         5               0               0.0             999               0                  0.318254         20              0               0.0             472              0                 0.080711        20             0              0.0            0                     0                      0.000000             0                   0                   0.0                 0                      0                       0                     0                    0                    0.0                  2177047     378130476  158924431   104.391045                 1655.887817                    1442.138672          50629            2.427699                        0.031857                       0.031857                  0.030071                            5                     1                     2.00               3.0               4.00               1480                  606                   824.50             1043.0            1261.50            675                  171                  297.00            423.0            549.00            8793732         0                         0                         0.00                   0.0                   0.00                   0                          0                          0.00                    0.0                    0.00                    1.500000                    0.033366                   0.000000                     0.0                       1.500000                  0.0                       1019.000000                 0.343248                   0.0                          0.0                       20.0                      0.0                       453.333344                 0.071856                  0.0                         0.0                      18.666666                0.0                      0.000000                        0.000000                       0.000000                         0.0                           0.000000                      0.0                           0.000000                        50629.0      0.009876          0.678741          0.006703  2                       0.045455               0                        0                     2                     0                     1004                    0.330155               0                        0                     20                    0                     495                    0.079787              0                       0                    20                   0                    0                           0.000000                   0                            0                         0                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            1.715012    0.001397    0.002396  31.984707                   0.063715                    7                     0.980952                        0.000000       2.359606 \n",
       "2019374  16377    42       24              0               31                1      0.022624               0.916918               0.076239                        0.565155             0.528563                      1                 0                  0.020000         1               0               0.0             2568              0                  0.946554         20              0               0.0             641              0                 0.094265        20             0              0.0            0                     0                      0.000000             0                   0                   0.0                 0                      0                       0                     0                    0                    0.0                  3586650     490180900  194611629   171.982574                 850.382507                     1093.897461          71733            3.439651                        0.036860                       0.036860                  0.043287                            1                     1                     1.00               1.0               1.00               4116                  1392                  2073.00            2754.0            3435.00            675                  171                  297.00            423.0            549.00            9803618         0                         0                         0.00                   0.0                   0.00                   0                          0                          0.00                    0.0                    0.00                    1.000000                    0.021074                   0.000000                     0.0                       1.000000                  0.0                       2860.666748                 1.127768                   0.0                          0.0                       20.0                      0.0                       484.000000                 0.075637                  0.0                         0.0                      20.000000                0.0                      0.000000                        0.000000                       0.000000                         0.0                           0.000000                      0.0                           0.000000                        71733.0      0.001394          0.839112          0.001170  1                       0.020408               0                        0                     1                     0                     4116                    1.514906               0                        0                     20                    0                     562                    0.082647              0                       0                    20                   0                    0                           0.000000                   0                            0                         0                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            4.181697    0.000493    0.002062  151.713974                  0.036860                    6                     21.200000                       0.000000       1.000000 \n",
       "215317   2140     37       32              1               55                9      1.124088               0.296085               0.314365                        0.391270             0.338399                      10                0                  0.232558         3               0               0.0             907               0                  0.249656         20              0               0.0             4757             0                 0.192062        10             0              0.0            96                    0                      0.166667             4                   0                   0.0                 1                      1                       1                     1                    1                    0.0                  2293921     415853516  193809651   109.995239                 1405.266724                    1055.442017          53347            2.558029                        0.027525                       0.027525                  0.036109                            136                   5                     37.75              70.5              103.25             1356                  413                   648.75             884.5             1120.25            11613                4757                 6471.00           8185.0           9899.00           9671012         252                       88                        129.00                 170.0                 211.00                 4                          0                          1.00                    2.0                    3.00                    12.333333                   0.289406                   0.000000                     0.0                       2.666667                  0.0                       922.666687                  0.277898                   0.0                          0.0                       20.0                      0.0                       5802.333496                0.247697                  0.0                         0.0                      15.666667                0.0                      159.666672                      0.291058                       0.000000                         0.0                           4.333333                      0.0                           0.333333                        53347.0      0.018745          0.471704          0.008842  14                      0.333333               0                        0                     2                     0                     1113                    0.322049               0                        0                     20                    0                     5742                   0.245448              0                       0                    13                   0                    144                         0.258528                   0                            0                         5                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            1.345255    0.061133    0.082240  30.635838                   0.385356                    15                    0.012805                        150.927703    -8.029893 \n",
       "1592282  13383    52       29              0               49                6      0.056581               0.327276               0.206480                        0.437078             0.374134                      5                 0                  0.116279         3               0               0.0             710               0                  0.226187         18              0               0.0             590              0                 0.221305        14             0              0.0            1                     0                      0.016129             1                   0                   0.0                 0                      0                       0                     0                    0                    0.0                  2177047     378130476  158924431   104.391045                 1655.887817                    1442.138672          50629            2.427699                        0.031857                       0.031857                  0.044335                            9                     1                     3.00               5.0               7.00               1600                  587                   840.25             1093.5            1346.75            639                  383                  447.00            511.0            575.00            8793732         6                         0                         1.50                   3.0                   4.50                   0                          0                          0.00                    0.0                    0.00                    3.333333                    0.072197                   0.000000                     0.0                       1.666667                  0.0                       808.000000                  0.272495                   0.0                          0.0                       20.0                      0.0                       560.666687                 0.205183                  0.0                         0.0                      17.666666                0.0                      3.666667                        0.061638                       0.000000                         0.0                           2.000000                      0.0                           0.000000                        50629.0      0.009876          0.107922          0.001066  2                       0.045455               0                        0                     1                     0                     716                     0.235449               0                        0                     20                    0                     431                    0.166025              0                       0                    14                   0                    1                           0.016949                   0                            0                         1                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            1.489296    0.005998    0.008933  22.809811                   0.063715                    21                    0.147319                        2.281495       3.821197 \n",
       "316364   2921     41       12              3               21                1      0.693902               0.287891               0.485467                        0.567823             0.640303                      38                0                  0.826087         4               0               0.0             862               0                  0.564875         20              0               0.0             223              0                 0.605978        4              0              0.0            7                     0                      0.875000             3                   0                   0.0                 3                      3                       3                     3                    3                    0.0                  2059098     183422884  68308338    98.735298                  557.388733                     1215.967041          44763            2.146420                        0.065531                       0.065531                  0.043519                            66                    10                    24.00              38.0              52.00              1175                  528                   689.75             851.5             1013.25            397                  83                   161.50            240.0            318.50            3987454         10                        0                         2.50                   5.0                   7.50                   3                          0                          0.75                    1.5                    2.25                    0.000000                    0.000000                   0.000000                     0.0                       0.000000                  0.0                       0.000000                    0.000000                   0.0                          0.0                       0.0                       0.0                       0.000000                   0.000000                  0.0                         0.0                      0.000000                 0.0                      0.000000                        0.000000                       0.000000                         0.0                           0.000000                      0.0                           0.000000                        44763.0      0.084892          0.461631          0.039189  0                       0.000000               0                        0                     0                     0                     0                       0.000000               0                        0                     0                     0                     0                      0.000000              0                       0                    0                    0                    0                           0.000000                   0                            0                         0                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            1.295708    0.058175    0.075378  0.000000                    0.000000                    22                    0.007882                        3.676050       21.900938\n",
       "219249   2196     28       27              1               55                4      0.819648               1.113248               0.314770                        0.405230             0.363275                      10                0                  0.212766         1               0               0.0             2587              0                  0.872513         20              0               0.0             6365             0                 0.262962        20             0              0.0            369                   0                      0.716505             8                   0                   0.0                 1                      1                       1                     1                    1                    0.0                  2367014     412107515  149323330   113.500099                 1225.643188                    981.758606           50362            2.414896                        0.033727                       0.033727                  0.039331                            145                   4                     39.25              74.5              109.75             4524                  1882                  2542.50            3203.0            3863.50            11613                4757                 6471.00           8185.0           9899.00           8768245         548                       185                       275.75                 366.5                 457.25                 7                          0                          1.75                    3.5                    5.25                    30.333334                   0.628628                   0.333333                     0.0                       3.333333                  0.0                       3560.666748                 1.281519                   0.0                          0.0                       20.0                      0.0                       7522.666504                0.318376                  0.0                         0.0                      18.333334                0.0                      486.333344                      0.982165                       0.666667                         0.0                           18.333334                     0.0                           2.000000                        50362.0      0.019856          1.232914          0.024481  21                      0.456522               0                        0                     3                     0                     3114                    1.070839               0                        0                     20                    0                     7806                   0.334705              0                       0                    20                   0                    467                         0.921105                   1                            0                         20                        0                         2                            2.0                         2                             2                          2                          0                          0                       0                       0            5.070755    0.057600    0.292074  105.025291                  0.708263                    18                    0.012339                        380.231195     25.491818\n",
       "822989   6624     14       16              0               22                5      0.261962               0.300891               0.455610                        0.430599             0.523595                      4                 0                  0.081633         1               0               0.0             576               0                  0.329897         20              0               0.0             430              0                 0.626822        20             0              0.0            2                     0                      0.142857             1                   0                   0.0                 0                      0                       0                     0                    0                    0.0                  2173738     241470089  77456052    104.232376                 1281.326782                    1654.606812          44362            2.127191                        0.057274                       0.057274                  0.043519                            40                    1                     10.75              20.5              30.25              1272                  444                   651.00             858.0             1065.00            793                  214                  358.75            503.5            648.25            4927961         11                        0                         2.75                   5.5                   8.25                   1                          0                          0.25                    0.5                    0.75                    5.666667                    0.119122                   0.000000                     0.0                       1.666667                  0.0                       575.000000                  0.354653                   0.0                          0.0                       20.0                      0.0                       283.666656                 0.569136                  0.0                         0.0                      7.666667                 0.0                      1.666667                        0.155556                       0.000000                         0.0                           1.333333                      0.0                           0.000000                        44362.0      0.009017          1.298409          0.011707  1                       0.020408               0                        0                     1                     0                     444                     0.261023               0                        0                     20                    0                     237                    0.403061              0                       0                    4                    0                    2                           0.166667                   0                            0                         1                         0                         0                            0.0                         0                             0                          0                          0                          0                       1                       0            1.368098    0.022596    0.030914  25.429552                   0.057274                    22                    0.023147                        3.195560       9.680767 \n",
       "971714   8072     57       12              1               41                1      0.267218               0.818710               0.233434                        0.562547             0.633956                      73                1                  1.586957         9               0               0.0             1700              0                  1.114024         20              0               0.0             332              0                 0.343685        13             0              0.0            11                    0                      0.523810             2                   0                   0.0                 1                      1                       1                     1                    1                    0.0                  2059098     183422884  68308338    98.735298                  557.388733                     1215.967041          44763            2.146420                        0.065531                       0.065531                  0.045094                            73                    1                     19.00              37.0              55.00              4070                  1645                  2251.25            2857.5            3463.75            700                  131                  273.25            415.5            557.75            3987454         33                        5                         12.00                  19.0                  26.00                  3                          0                          0.75                    1.5                    2.25                    0.000000                    0.000000                   0.000000                     0.0                       0.000000                  0.0                       0.000000                    0.000000                   0.0                          0.0                       0.0                       0.0                       0.000000                   0.000000                  0.0                         0.0                      0.000000                 0.0                      0.000000                        0.000000                       0.000000                         0.0                           0.000000                      0.0                           0.000000                        44763.0      0.163081          0.869647          0.141823  0                       0.000000               0                        0                     0                     0                     0                       0.000000               0                        0                     0                     0                     0                      0.000000              0                       0                    0                    0                    0                           0.000000                   0                            0                         0                         0                         0                            0.0                         0                             0                          0                          0                          0                       0                       0            3.735360    0.022103    0.082563  0.000000                    0.000000                    20                    0.042129                        12.758191      31.601276"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'item_cnt_block',\n",
       "       'item_category_id', 'month', 'item_id_mean_encoding',\n",
       "       'shop_id_mean_encoding', 'item_category_id_mean_encoding',\n",
       "       'month_mean_encoding', 'date_block_num_mean_encoding',\n",
       "       'item_block_units', 'item_block_median', 'item_block_mean',\n",
       "       'item_block_max', 'item_block_min', 'item_block_std',\n",
       "       'shop_block_units', 'shop_block_median', 'shop_block_mean',\n",
       "       'shop_block_max', 'shop_block_min', 'shop_block_std',\n",
       "       'cat_block_units', 'cat_block_median', 'cat_block_mean',\n",
       "       'cat_block_max', 'cat_block_min', 'cat_block_std',\n",
       "       'shop_cat_block_units', 'shop_cat_block_median',\n",
       "       'shop_cat_block_mean', 'shop_cat_block_max', 'shop_cat_block_min',\n",
       "       'shop_cat_block_std', 'shop_item_block_units',\n",
       "       'shop_item_block_median', 'shop_item_block_mean',\n",
       "       'shop_item_block_max', 'shop_item_block_min',\n",
       "       'shop_item_block_std', 'item_units', 'cat_units', 'shop_units',\n",
       "       'item_share_of_total_units', 'category_share_of_total_units',\n",
       "       'shop_share_of_units', 'shop_item_units',\n",
       "       'shop_item_share_of_total_units', 'shop_item_share_of_shop_units',\n",
       "       'item_share_of_shop_units', 'shop_item_share_of_shop_units_mean',\n",
       "       'item_max_units_block', 'item_min_units_block',\n",
       "       'item_minmax_q0.25', 'item_minmax_q0.5', 'item_minmax_q0.75',\n",
       "       'shop_max_units_block', 'shop_min_units_block',\n",
       "       'shop_minmax_q0.25', 'shop_minmax_q0.5', 'shop_minmax_q0.75',\n",
       "       'cat_max_units_block', 'cat_min_units_block', 'cat_minmax_q0.25',\n",
       "       'cat_minmax_q0.5', 'cat_minmax_q0.75', 'shop_cat_units',\n",
       "       'shop_cat_max_units_block', 'shop_cat_min_units_block',\n",
       "       'shop_cat_minmax_q0.25', 'shop_cat_minmax_q0.5',\n",
       "       'shop_cat_minmax_q0.75', 'shop_item_max_units_block',\n",
       "       'shop_item_min_units_block', 'shop_item_minmax_q0.25',\n",
       "       'shop_item_minmax_q0.5', 'shop_item_minmax_q0.75',\n",
       "       'item_block_units_rolling_3', 'item_block_mean_rolling_3',\n",
       "       'item_block_median_rolling_3', 'item_block_min_rolling_3',\n",
       "       'item_block_max_rolling_3', 'item_block_std_rolling_3',\n",
       "       'shop_block_units_rolling_3', 'shop_block_mean_rolling_3',\n",
       "       'shop_block_median_rolling_3', 'shop_block_min_rolling_3',\n",
       "       'shop_block_max_rolling_3', 'shop_block_std_rolling_3',\n",
       "       'cat_block_units_rolling_3', 'cat_block_mean_rolling_3',\n",
       "       'cat_block_median_rolling_3', 'cat_block_min_rolling_3',\n",
       "       'cat_block_max_rolling_3', 'cat_block_std_rolling_3',\n",
       "       'shop_cat_block_units_rolling_3', 'shop_cat_block_mean_rolling_3',\n",
       "       'shop_cat_block_median_rolling_3', 'shop_cat_block_min_rolling_3',\n",
       "       'shop_cat_block_max_rolling_3', 'shop_cat_block_std_rolling_3',\n",
       "       'shop_item_block_mean_rolling_3', 'block_total',\n",
       "       'item_share_block', 'shop_share_block', 'comp2',\n",
       "       'item_block_units_lag_1', 'item_block_mean_lag_1',\n",
       "       'item_block_median_lag_1', 'item_block_min_lag_1',\n",
       "       'item_block_max_lag_1', 'item_block_std_lag_1',\n",
       "       'shop_block_units_lag_1', 'shop_block_mean_lag_1',\n",
       "       'shop_block_median_lag_1', 'shop_block_min_lag_1',\n",
       "       'shop_block_max_lag_1', 'shop_block_std_lag_1',\n",
       "       'cat_block_units_lag_1', 'cat_block_mean_lag_1',\n",
       "       'cat_block_median_lag_1', 'cat_block_min_lag_1',\n",
       "       'cat_block_max_lag_1', 'cat_block_std_lag_1',\n",
       "       'shop_cat_block_units_lag_1', 'shop_cat_block_mean_lag_1',\n",
       "       'shop_cat_block_median_lag_1', 'shop_cat_block_min_lag_1',\n",
       "       'shop_cat_block_max_lag_1', 'shop_cat_block_std_lag_1',\n",
       "       'shop_item_block_units_lag_1', 'shop_item_block_mean_lag_1',\n",
       "       'shop_item_block_median_lag_1', 'shop_item_block_min_lag_1',\n",
       "       'shop_item_block_max_lag_1', 'shop_item_block_std_lag_1',\n",
       "       'item_share_block_lag_1', 'shop_share_block_lag_1', 'comp2_lag_1',\n",
       "       'shop_share', 'item_share', 'comp1', 'shop_block_units_lag_comp1',\n",
       "       'item_block_units_lag_comp1', 'blocks_without_sales',\n",
       "       'item_mean_day_between_activity', 'shop_cat_pred', 'item_pred'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_val_len 29202\n",
      "zeros_keep_indices_val 146010\n",
      "non_zeros_val_indices 29202\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "ZEROS_KEEP=0.2\n",
    "\n",
    "\n",
    "#x_train = training[(training['date_block_num'] < 33) & (training['val_ignore'] == False)]\n",
    "x_train = training[(training['date_block_num'] < 33)]\n",
    "y_train = x_train['item_cnt_block']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_val = training[training['date_block_num'] == 33]\n",
    "y_val = x_val['item_cnt_block']\n",
    "\n",
    "pos_val_len = len(y_val[y_val != 0])\n",
    "print(\"pos_val_len\", pos_val_len)\n",
    "\n",
    "zeros_keep_indices_val = y_val[y_val == 0].sample(int(pos_val_len/ZEROS_KEEP)).index\n",
    "print(\"zeros_keep_indices_val\", len(zeros_keep_indices_val))\n",
    "non_zeros_val_indices = y_val[y_val != 0].index\n",
    "print(\"non_zeros_val_indices\", len(non_zeros_val_indices))\n",
    "\n",
    "val_indices = np.append(np.array(zeros_keep_indices_val), np.array(non_zeros_val_indices))\n",
    "\n",
    "y_val = y_val.loc[val_indices]\n",
    "x_val = x_val.loc[val_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\n",
    "    \n",
    "    \n",
    "        'item_category_id',\n",
    "       'item_block_mean_rolling_3',\n",
    "\n",
    "       'shop_block_mean_rolling_3',\n",
    "\n",
    "           'shop_cat_block_mean_rolling_3',\n",
    "               'shop_cat_block_median_rolling_3',\n",
    "\n",
    "      'item_block_mean_lag_1',\n",
    "\n",
    "        'shop_block_mean_lag_1',\n",
    "\n",
    "            'shop_cat_block_mean_lag_1',\n",
    "               # 'shop_cat_block_median_lag_1',\n",
    "\n",
    "\n",
    "    \n",
    "    'shop_item_share_of_shop_units_mean',\n",
    "    'shop_item_block_mean_rolling_3',\n",
    "\n",
    "    'shop_item_block_mean_lag_1',\n",
    "\n",
    "    \n",
    "#'item_id_mean_encoding',\n",
    "       #'shop_id_mean_encoding',\n",
    "    'item_category_id_mean_encoding',  \n",
    "    #'month_mean_encoding', 'date_block_num_mean_encoding'\n",
    "    \n",
    "    'shop_share',\n",
    "    \n",
    "    #'item_mean_day_between_activity',\n",
    "    #'shop_cat_pred',\n",
    "    #'item_pred'\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.6489130\ttest: 1.3261997\tbest: 1.3261997 (0)\ttotal: 131ms\tremaining: 2m 11s\n",
      "1:\tlearn: 1.6375571\ttest: 1.3175852\tbest: 1.3175852 (1)\ttotal: 215ms\tremaining: 1m 47s\n",
      "2:\tlearn: 1.6269528\ttest: 1.3102201\tbest: 1.3102201 (2)\ttotal: 308ms\tremaining: 1m 42s\n",
      "3:\tlearn: 1.6130762\ttest: 1.3015639\tbest: 1.3015639 (3)\ttotal: 390ms\tremaining: 1m 37s\n",
      "4:\tlearn: 1.5992097\ttest: 1.2923679\tbest: 1.2923679 (4)\ttotal: 463ms\tremaining: 1m 32s\n",
      "5:\tlearn: 1.5873579\ttest: 1.2851452\tbest: 1.2851452 (5)\ttotal: 555ms\tremaining: 1m 31s\n",
      "6:\tlearn: 1.5719692\ttest: 1.2759251\tbest: 1.2759251 (6)\ttotal: 642ms\tremaining: 1m 31s\n",
      "7:\tlearn: 1.5589368\ttest: 1.2682952\tbest: 1.2682952 (7)\ttotal: 715ms\tremaining: 1m 28s\n",
      "8:\tlearn: 1.5463396\ttest: 1.2610204\tbest: 1.2610204 (8)\ttotal: 792ms\tremaining: 1m 27s\n",
      "9:\tlearn: 1.5328381\ttest: 1.2529191\tbest: 1.2529191 (9)\ttotal: 868ms\tremaining: 1m 25s\n",
      "10:\tlearn: 1.5238571\ttest: 1.2482715\tbest: 1.2482715 (10)\ttotal: 944ms\tremaining: 1m 24s\n",
      "11:\tlearn: 1.5125054\ttest: 1.2398723\tbest: 1.2398723 (11)\ttotal: 1.03s\tremaining: 1m 24s\n",
      "12:\tlearn: 1.5030437\ttest: 1.2341385\tbest: 1.2341385 (12)\ttotal: 1.12s\tremaining: 1m 25s\n",
      "13:\tlearn: 1.4908394\ttest: 1.2263864\tbest: 1.2263864 (13)\ttotal: 1.19s\tremaining: 1m 23s\n",
      "14:\tlearn: 1.4825842\ttest: 1.2207441\tbest: 1.2207441 (14)\ttotal: 1.27s\tremaining: 1m 23s\n",
      "15:\tlearn: 1.4746054\ttest: 1.2155571\tbest: 1.2155571 (15)\ttotal: 1.36s\tremaining: 1m 23s\n",
      "16:\tlearn: 1.4677182\ttest: 1.2115621\tbest: 1.2115621 (16)\ttotal: 1.44s\tremaining: 1m 23s\n",
      "17:\tlearn: 1.4573233\ttest: 1.2050781\tbest: 1.2050781 (17)\ttotal: 1.51s\tremaining: 1m 22s\n",
      "18:\tlearn: 1.4461740\ttest: 1.1983013\tbest: 1.1983013 (18)\ttotal: 1.6s\tremaining: 1m 22s\n",
      "19:\tlearn: 1.4379144\ttest: 1.1936294\tbest: 1.1936294 (19)\ttotal: 1.67s\tremaining: 1m 21s\n",
      "20:\tlearn: 1.4277338\ttest: 1.1873932\tbest: 1.1873932 (20)\ttotal: 1.75s\tremaining: 1m 21s\n",
      "21:\tlearn: 1.4186154\ttest: 1.1821026\tbest: 1.1821026 (21)\ttotal: 1.82s\tremaining: 1m 21s\n",
      "22:\tlearn: 1.4111389\ttest: 1.1778138\tbest: 1.1778138 (22)\ttotal: 1.9s\tremaining: 1m 20s\n",
      "23:\tlearn: 1.4067501\ttest: 1.1752367\tbest: 1.1752367 (23)\ttotal: 1.98s\tremaining: 1m 20s\n",
      "24:\tlearn: 1.4017750\ttest: 1.1720659\tbest: 1.1720659 (24)\ttotal: 2.17s\tremaining: 1m 24s\n",
      "25:\tlearn: 1.3934395\ttest: 1.1673831\tbest: 1.1673831 (25)\ttotal: 2.25s\tremaining: 1m 24s\n",
      "26:\tlearn: 1.3857169\ttest: 1.1628324\tbest: 1.1628324 (26)\ttotal: 2.32s\tremaining: 1m 23s\n",
      "27:\tlearn: 1.3794843\ttest: 1.1592609\tbest: 1.1592609 (27)\ttotal: 2.4s\tremaining: 1m 23s\n",
      "28:\tlearn: 1.3751361\ttest: 1.1568494\tbest: 1.1568494 (28)\ttotal: 2.48s\tremaining: 1m 23s\n",
      "29:\tlearn: 1.3697005\ttest: 1.1543682\tbest: 1.1543682 (29)\ttotal: 2.56s\tremaining: 1m 22s\n",
      "30:\tlearn: 1.3643415\ttest: 1.1517573\tbest: 1.1517573 (30)\ttotal: 2.65s\tremaining: 1m 22s\n",
      "31:\tlearn: 1.3613559\ttest: 1.1500681\tbest: 1.1500681 (31)\ttotal: 2.73s\tremaining: 1m 22s\n",
      "32:\tlearn: 1.3555961\ttest: 1.1472702\tbest: 1.1472702 (32)\ttotal: 2.81s\tremaining: 1m 22s\n",
      "33:\tlearn: 1.3519154\ttest: 1.1449165\tbest: 1.1449165 (33)\ttotal: 2.89s\tremaining: 1m 22s\n",
      "34:\tlearn: 1.3460774\ttest: 1.1417332\tbest: 1.1417332 (34)\ttotal: 2.96s\tremaining: 1m 21s\n",
      "35:\tlearn: 1.3423763\ttest: 1.1402355\tbest: 1.1402355 (35)\ttotal: 3.05s\tremaining: 1m 21s\n",
      "36:\tlearn: 1.3391916\ttest: 1.1373097\tbest: 1.1373097 (36)\ttotal: 3.13s\tremaining: 1m 21s\n",
      "37:\tlearn: 1.3342666\ttest: 1.1345981\tbest: 1.1345981 (37)\ttotal: 3.21s\tremaining: 1m 21s\n",
      "38:\tlearn: 1.3313950\ttest: 1.1334277\tbest: 1.1334277 (38)\ttotal: 3.29s\tremaining: 1m 21s\n",
      "39:\tlearn: 1.3261998\ttest: 1.1306645\tbest: 1.1306645 (39)\ttotal: 3.37s\tremaining: 1m 20s\n",
      "40:\tlearn: 1.3224130\ttest: 1.1282520\tbest: 1.1282520 (40)\ttotal: 3.44s\tremaining: 1m 20s\n",
      "41:\tlearn: 1.3172122\ttest: 1.1253421\tbest: 1.1253421 (41)\ttotal: 3.53s\tremaining: 1m 20s\n",
      "42:\tlearn: 1.3121955\ttest: 1.1213723\tbest: 1.1213723 (42)\ttotal: 3.61s\tremaining: 1m 20s\n",
      "43:\tlearn: 1.3069284\ttest: 1.1184187\tbest: 1.1184187 (43)\ttotal: 3.68s\tremaining: 1m 19s\n",
      "44:\tlearn: 1.3027793\ttest: 1.1161913\tbest: 1.1161913 (44)\ttotal: 3.75s\tremaining: 1m 19s\n",
      "45:\tlearn: 1.2995385\ttest: 1.1144240\tbest: 1.1144240 (45)\ttotal: 3.9s\tremaining: 1m 20s\n",
      "46:\tlearn: 1.2966558\ttest: 1.1131472\tbest: 1.1131472 (46)\ttotal: 3.98s\tremaining: 1m 20s\n",
      "47:\tlearn: 1.2945410\ttest: 1.1119965\tbest: 1.1119965 (47)\ttotal: 4.06s\tremaining: 1m 20s\n",
      "48:\tlearn: 1.2933422\ttest: 1.1106940\tbest: 1.1106940 (48)\ttotal: 4.15s\tremaining: 1m 20s\n",
      "49:\tlearn: 1.2907515\ttest: 1.1089617\tbest: 1.1089617 (49)\ttotal: 4.22s\tremaining: 1m 20s\n",
      "50:\tlearn: 1.2879841\ttest: 1.1073054\tbest: 1.1073054 (50)\ttotal: 4.29s\tremaining: 1m 19s\n",
      "51:\tlearn: 1.2854237\ttest: 1.1062076\tbest: 1.1062076 (51)\ttotal: 4.37s\tremaining: 1m 19s\n",
      "52:\tlearn: 1.2833644\ttest: 1.1050720\tbest: 1.1050720 (52)\ttotal: 4.46s\tremaining: 1m 19s\n",
      "53:\tlearn: 1.2802411\ttest: 1.1034617\tbest: 1.1034617 (53)\ttotal: 4.61s\tremaining: 1m 20s\n",
      "54:\tlearn: 1.2780280\ttest: 1.1019192\tbest: 1.1019192 (54)\ttotal: 4.71s\tremaining: 1m 20s\n",
      "55:\tlearn: 1.2763614\ttest: 1.1010632\tbest: 1.1010632 (55)\ttotal: 4.79s\tremaining: 1m 20s\n",
      "56:\tlearn: 1.2741714\ttest: 1.0997995\tbest: 1.0997995 (56)\ttotal: 4.87s\tremaining: 1m 20s\n",
      "57:\tlearn: 1.2720432\ttest: 1.0987903\tbest: 1.0987903 (57)\ttotal: 4.95s\tremaining: 1m 20s\n",
      "58:\tlearn: 1.2692002\ttest: 1.0974691\tbest: 1.0974691 (58)\ttotal: 5.02s\tremaining: 1m 20s\n",
      "59:\tlearn: 1.2658516\ttest: 1.0955414\tbest: 1.0955414 (59)\ttotal: 5.13s\tremaining: 1m 20s\n",
      "60:\tlearn: 1.2621036\ttest: 1.0932554\tbest: 1.0932554 (60)\ttotal: 5.21s\tremaining: 1m 20s\n",
      "61:\tlearn: 1.2597447\ttest: 1.0918461\tbest: 1.0918461 (61)\ttotal: 5.29s\tremaining: 1m 20s\n",
      "62:\tlearn: 1.2570696\ttest: 1.0904270\tbest: 1.0904270 (62)\ttotal: 5.38s\tremaining: 1m 19s\n",
      "63:\tlearn: 1.2547534\ttest: 1.0892996\tbest: 1.0892996 (63)\ttotal: 5.45s\tremaining: 1m 19s\n",
      "64:\tlearn: 1.2537902\ttest: 1.0883074\tbest: 1.0883074 (64)\ttotal: 5.54s\tremaining: 1m 19s\n",
      "65:\tlearn: 1.2511941\ttest: 1.0870015\tbest: 1.0870015 (65)\ttotal: 5.61s\tremaining: 1m 19s\n",
      "66:\tlearn: 1.2501167\ttest: 1.0861151\tbest: 1.0861151 (66)\ttotal: 5.69s\tremaining: 1m 19s\n",
      "67:\tlearn: 1.2490716\ttest: 1.0855993\tbest: 1.0855993 (67)\ttotal: 5.78s\tremaining: 1m 19s\n",
      "68:\tlearn: 1.2463045\ttest: 1.0838401\tbest: 1.0838401 (68)\ttotal: 5.87s\tremaining: 1m 19s\n",
      "69:\tlearn: 1.2449729\ttest: 1.0832947\tbest: 1.0832947 (69)\ttotal: 5.96s\tremaining: 1m 19s\n",
      "70:\tlearn: 1.2435316\ttest: 1.0828400\tbest: 1.0828400 (70)\ttotal: 6.04s\tremaining: 1m 19s\n",
      "71:\tlearn: 1.2419392\ttest: 1.0821165\tbest: 1.0821165 (71)\ttotal: 6.11s\tremaining: 1m 18s\n",
      "72:\tlearn: 1.2405230\ttest: 1.0810789\tbest: 1.0810789 (72)\ttotal: 6.19s\tremaining: 1m 18s\n",
      "73:\tlearn: 1.2394027\ttest: 1.0806665\tbest: 1.0806665 (73)\ttotal: 6.26s\tremaining: 1m 18s\n",
      "74:\tlearn: 1.2386437\ttest: 1.0799457\tbest: 1.0799457 (74)\ttotal: 6.35s\tremaining: 1m 18s\n",
      "75:\tlearn: 1.2370575\ttest: 1.0789970\tbest: 1.0789970 (75)\ttotal: 6.43s\tremaining: 1m 18s\n",
      "76:\tlearn: 1.2356532\ttest: 1.0782368\tbest: 1.0782368 (76)\ttotal: 6.52s\tremaining: 1m 18s\n",
      "77:\tlearn: 1.2349599\ttest: 1.0778467\tbest: 1.0778467 (77)\ttotal: 6.6s\tremaining: 1m 18s\n",
      "78:\tlearn: 1.2345806\ttest: 1.0776704\tbest: 1.0776704 (78)\ttotal: 6.68s\tremaining: 1m 17s\n",
      "79:\tlearn: 1.2338346\ttest: 1.0775054\tbest: 1.0775054 (79)\ttotal: 6.76s\tremaining: 1m 17s\n",
      "80:\tlearn: 1.2320946\ttest: 1.0765894\tbest: 1.0765894 (80)\ttotal: 6.83s\tremaining: 1m 17s\n",
      "81:\tlearn: 1.2308385\ttest: 1.0756388\tbest: 1.0756388 (81)\ttotal: 6.91s\tremaining: 1m 17s\n",
      "82:\tlearn: 1.2295664\ttest: 1.0749112\tbest: 1.0749112 (82)\ttotal: 6.98s\tremaining: 1m 17s\n",
      "83:\tlearn: 1.2282995\ttest: 1.0741692\tbest: 1.0741692 (83)\ttotal: 7.05s\tremaining: 1m 16s\n",
      "84:\tlearn: 1.2265788\ttest: 1.0732891\tbest: 1.0732891 (84)\ttotal: 7.12s\tremaining: 1m 16s\n",
      "85:\tlearn: 1.2258289\ttest: 1.0731096\tbest: 1.0731096 (85)\ttotal: 7.21s\tremaining: 1m 16s\n",
      "86:\tlearn: 1.2240152\ttest: 1.0716612\tbest: 1.0716612 (86)\ttotal: 7.29s\tremaining: 1m 16s\n",
      "87:\tlearn: 1.2234677\ttest: 1.0711006\tbest: 1.0711006 (87)\ttotal: 7.36s\tremaining: 1m 16s\n",
      "88:\tlearn: 1.2229555\ttest: 1.0708421\tbest: 1.0708421 (88)\ttotal: 7.44s\tremaining: 1m 16s\n",
      "89:\tlearn: 1.2215355\ttest: 1.0699576\tbest: 1.0699576 (89)\ttotal: 7.51s\tremaining: 1m 15s\n",
      "90:\tlearn: 1.2209457\ttest: 1.0697473\tbest: 1.0697473 (90)\ttotal: 7.59s\tremaining: 1m 15s\n",
      "91:\tlearn: 1.2199808\ttest: 1.0692149\tbest: 1.0692149 (91)\ttotal: 7.68s\tremaining: 1m 15s\n",
      "92:\tlearn: 1.2192458\ttest: 1.0689367\tbest: 1.0689367 (92)\ttotal: 7.76s\tremaining: 1m 15s\n",
      "93:\tlearn: 1.2183930\ttest: 1.0684593\tbest: 1.0684593 (93)\ttotal: 7.85s\tremaining: 1m 15s\n",
      "94:\tlearn: 1.2176260\ttest: 1.0681355\tbest: 1.0681355 (94)\ttotal: 7.93s\tremaining: 1m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95:\tlearn: 1.2170354\ttest: 1.0673959\tbest: 1.0673959 (95)\ttotal: 8.01s\tremaining: 1m 15s\n",
      "96:\tlearn: 1.2160230\ttest: 1.0669040\tbest: 1.0669040 (96)\ttotal: 8.09s\tremaining: 1m 15s\n",
      "97:\tlearn: 1.2141725\ttest: 1.0655634\tbest: 1.0655634 (97)\ttotal: 8.17s\tremaining: 1m 15s\n",
      "98:\tlearn: 1.2126361\ttest: 1.0646517\tbest: 1.0646517 (98)\ttotal: 8.26s\tremaining: 1m 15s\n",
      "99:\tlearn: 1.2121369\ttest: 1.0644549\tbest: 1.0644549 (99)\ttotal: 8.33s\tremaining: 1m 14s\n",
      "100:\tlearn: 1.2115187\ttest: 1.0642922\tbest: 1.0642922 (100)\ttotal: 8.41s\tremaining: 1m 14s\n",
      "101:\tlearn: 1.2105985\ttest: 1.0638167\tbest: 1.0638167 (101)\ttotal: 8.5s\tremaining: 1m 14s\n",
      "102:\tlearn: 1.2094013\ttest: 1.0631433\tbest: 1.0631433 (102)\ttotal: 8.58s\tremaining: 1m 14s\n",
      "103:\tlearn: 1.2085075\ttest: 1.0626859\tbest: 1.0626859 (103)\ttotal: 8.66s\tremaining: 1m 14s\n",
      "104:\tlearn: 1.2064357\ttest: 1.0616012\tbest: 1.0616012 (104)\ttotal: 8.74s\tremaining: 1m 14s\n",
      "105:\tlearn: 1.2061504\ttest: 1.0615691\tbest: 1.0615691 (105)\ttotal: 8.82s\tremaining: 1m 14s\n",
      "106:\tlearn: 1.2054478\ttest: 1.0611998\tbest: 1.0611998 (106)\ttotal: 8.9s\tremaining: 1m 14s\n",
      "107:\tlearn: 1.2043823\ttest: 1.0607316\tbest: 1.0607316 (107)\ttotal: 8.98s\tremaining: 1m 14s\n",
      "108:\tlearn: 1.2036765\ttest: 1.0602167\tbest: 1.0602167 (108)\ttotal: 9.06s\tremaining: 1m 14s\n",
      "109:\tlearn: 1.2030140\ttest: 1.0597983\tbest: 1.0597983 (109)\ttotal: 9.15s\tremaining: 1m 14s\n",
      "110:\tlearn: 1.2024035\ttest: 1.0595270\tbest: 1.0595270 (110)\ttotal: 9.23s\tremaining: 1m 13s\n",
      "111:\tlearn: 1.2020307\ttest: 1.0593339\tbest: 1.0593339 (111)\ttotal: 9.31s\tremaining: 1m 13s\n",
      "112:\tlearn: 1.2014008\ttest: 1.0590028\tbest: 1.0590028 (112)\ttotal: 9.38s\tremaining: 1m 13s\n",
      "113:\tlearn: 1.2004077\ttest: 1.0586176\tbest: 1.0586176 (113)\ttotal: 9.57s\tremaining: 1m 14s\n",
      "114:\tlearn: 1.1993403\ttest: 1.0578682\tbest: 1.0578682 (114)\ttotal: 9.65s\tremaining: 1m 14s\n",
      "115:\tlearn: 1.1990170\ttest: 1.0578582\tbest: 1.0578582 (115)\ttotal: 9.8s\tremaining: 1m 14s\n",
      "116:\tlearn: 1.1984843\ttest: 1.0574841\tbest: 1.0574841 (116)\ttotal: 9.88s\tremaining: 1m 14s\n",
      "117:\tlearn: 1.1981872\ttest: 1.0570992\tbest: 1.0570992 (117)\ttotal: 9.95s\tremaining: 1m 14s\n",
      "118:\tlearn: 1.1973627\ttest: 1.0566459\tbest: 1.0566459 (118)\ttotal: 10s\tremaining: 1m 14s\n",
      "119:\tlearn: 1.1972008\ttest: 1.0566471\tbest: 1.0566459 (118)\ttotal: 10.1s\tremaining: 1m 14s\n",
      "120:\tlearn: 1.1968100\ttest: 1.0564061\tbest: 1.0564061 (120)\ttotal: 10.2s\tremaining: 1m 14s\n",
      "121:\tlearn: 1.1962567\ttest: 1.0560494\tbest: 1.0560494 (121)\ttotal: 10.3s\tremaining: 1m 13s\n",
      "122:\tlearn: 1.1958268\ttest: 1.0558217\tbest: 1.0558217 (122)\ttotal: 10.4s\tremaining: 1m 13s\n",
      "123:\tlearn: 1.1948681\ttest: 1.0554146\tbest: 1.0554146 (123)\ttotal: 10.4s\tremaining: 1m 13s\n",
      "124:\tlearn: 1.1946892\ttest: 1.0549267\tbest: 1.0549267 (124)\ttotal: 10.5s\tremaining: 1m 13s\n",
      "125:\tlearn: 1.1940941\ttest: 1.0546975\tbest: 1.0546975 (125)\ttotal: 10.6s\tremaining: 1m 13s\n",
      "126:\tlearn: 1.1936390\ttest: 1.0544653\tbest: 1.0544653 (126)\ttotal: 10.7s\tremaining: 1m 13s\n",
      "127:\tlearn: 1.1932447\ttest: 1.0541963\tbest: 1.0541963 (127)\ttotal: 10.7s\tremaining: 1m 13s\n",
      "128:\tlearn: 1.1929901\ttest: 1.0540120\tbest: 1.0540120 (128)\ttotal: 10.8s\tremaining: 1m 12s\n",
      "129:\tlearn: 1.1922753\ttest: 1.0536018\tbest: 1.0536018 (129)\ttotal: 10.9s\tremaining: 1m 12s\n",
      "130:\tlearn: 1.1911943\ttest: 1.0527808\tbest: 1.0527808 (130)\ttotal: 11s\tremaining: 1m 12s\n",
      "131:\tlearn: 1.1909860\ttest: 1.0527091\tbest: 1.0527091 (131)\ttotal: 11s\tremaining: 1m 12s\n",
      "132:\tlearn: 1.1907129\ttest: 1.0526832\tbest: 1.0526832 (132)\ttotal: 11.1s\tremaining: 1m 12s\n",
      "133:\tlearn: 1.1901625\ttest: 1.0524431\tbest: 1.0524431 (133)\ttotal: 11.2s\tremaining: 1m 12s\n",
      "134:\tlearn: 1.1896273\ttest: 1.0521475\tbest: 1.0521475 (134)\ttotal: 11.3s\tremaining: 1m 12s\n",
      "135:\tlearn: 1.1893058\ttest: 1.0520401\tbest: 1.0520401 (135)\ttotal: 11.4s\tremaining: 1m 12s\n",
      "136:\tlearn: 1.1885784\ttest: 1.0517151\tbest: 1.0517151 (136)\ttotal: 11.4s\tremaining: 1m 12s\n",
      "137:\tlearn: 1.1884220\ttest: 1.0516056\tbest: 1.0516056 (137)\ttotal: 11.5s\tremaining: 1m 11s\n",
      "138:\tlearn: 1.1873899\ttest: 1.0512005\tbest: 1.0512005 (138)\ttotal: 11.6s\tremaining: 1m 11s\n",
      "139:\tlearn: 1.1869784\ttest: 1.0511175\tbest: 1.0511175 (139)\ttotal: 11.7s\tremaining: 1m 11s\n",
      "140:\tlearn: 1.1864351\ttest: 1.0509750\tbest: 1.0509750 (140)\ttotal: 11.9s\tremaining: 1m 12s\n",
      "141:\tlearn: 1.1861960\ttest: 1.0508124\tbest: 1.0508124 (141)\ttotal: 11.9s\tremaining: 1m 12s\n",
      "142:\tlearn: 1.1857112\ttest: 1.0505336\tbest: 1.0505336 (142)\ttotal: 12s\tremaining: 1m 11s\n",
      "143:\tlearn: 1.1850187\ttest: 1.0501553\tbest: 1.0501553 (143)\ttotal: 12.1s\tremaining: 1m 11s\n",
      "144:\tlearn: 1.1845578\ttest: 1.0498625\tbest: 1.0498625 (144)\ttotal: 12.2s\tremaining: 1m 11s\n",
      "145:\tlearn: 1.1841779\ttest: 1.0496855\tbest: 1.0496855 (145)\ttotal: 12.3s\tremaining: 1m 11s\n",
      "146:\tlearn: 1.1838289\ttest: 1.0495258\tbest: 1.0495258 (146)\ttotal: 12.4s\tremaining: 1m 11s\n",
      "147:\tlearn: 1.1835252\ttest: 1.0494197\tbest: 1.0494197 (147)\ttotal: 12.5s\tremaining: 1m 11s\n",
      "148:\tlearn: 1.1825784\ttest: 1.0487640\tbest: 1.0487640 (148)\ttotal: 12.6s\tremaining: 1m 11s\n",
      "149:\tlearn: 1.1823607\ttest: 1.0486419\tbest: 1.0486419 (149)\ttotal: 12.6s\tremaining: 1m 11s\n",
      "150:\tlearn: 1.1820812\ttest: 1.0483616\tbest: 1.0483616 (150)\ttotal: 12.7s\tremaining: 1m 11s\n",
      "151:\tlearn: 1.1816432\ttest: 1.0480008\tbest: 1.0480008 (151)\ttotal: 12.8s\tremaining: 1m 11s\n",
      "152:\tlearn: 1.1814954\ttest: 1.0479606\tbest: 1.0479606 (152)\ttotal: 12.9s\tremaining: 1m 11s\n",
      "153:\tlearn: 1.1810597\ttest: 1.0478833\tbest: 1.0478833 (153)\ttotal: 13s\tremaining: 1m 11s\n",
      "154:\tlearn: 1.1807701\ttest: 1.0477366\tbest: 1.0477366 (154)\ttotal: 13s\tremaining: 1m 11s\n",
      "155:\tlearn: 1.1805301\ttest: 1.0476382\tbest: 1.0476382 (155)\ttotal: 13.1s\tremaining: 1m 10s\n",
      "156:\tlearn: 1.1803950\ttest: 1.0475670\tbest: 1.0475670 (156)\ttotal: 13.2s\tremaining: 1m 10s\n",
      "157:\tlearn: 1.1796161\ttest: 1.0471659\tbest: 1.0471659 (157)\ttotal: 13.3s\tremaining: 1m 10s\n",
      "158:\tlearn: 1.1793623\ttest: 1.0470351\tbest: 1.0470351 (158)\ttotal: 13.4s\tremaining: 1m 10s\n",
      "159:\tlearn: 1.1792550\ttest: 1.0469956\tbest: 1.0469956 (159)\ttotal: 13.4s\tremaining: 1m 10s\n",
      "160:\tlearn: 1.1790199\ttest: 1.0470037\tbest: 1.0469956 (159)\ttotal: 13.5s\tremaining: 1m 10s\n",
      "161:\tlearn: 1.1786236\ttest: 1.0467260\tbest: 1.0467260 (161)\ttotal: 13.6s\tremaining: 1m 10s\n",
      "162:\tlearn: 1.1784441\ttest: 1.0465669\tbest: 1.0465669 (162)\ttotal: 13.7s\tremaining: 1m 10s\n",
      "163:\tlearn: 1.1782326\ttest: 1.0463096\tbest: 1.0463096 (163)\ttotal: 13.8s\tremaining: 1m 10s\n",
      "164:\tlearn: 1.1779490\ttest: 1.0462373\tbest: 1.0462373 (164)\ttotal: 13.9s\tremaining: 1m 10s\n",
      "165:\tlearn: 1.1778351\ttest: 1.0461931\tbest: 1.0461931 (165)\ttotal: 13.9s\tremaining: 1m 10s\n",
      "166:\tlearn: 1.1777178\ttest: 1.0460945\tbest: 1.0460945 (166)\ttotal: 14s\tremaining: 1m 9s\n",
      "167:\tlearn: 1.1772734\ttest: 1.0459105\tbest: 1.0459105 (167)\ttotal: 14.1s\tremaining: 1m 9s\n",
      "168:\tlearn: 1.1771549\ttest: 1.0458064\tbest: 1.0458064 (168)\ttotal: 14.3s\tremaining: 1m 10s\n",
      "169:\tlearn: 1.1768030\ttest: 1.0454836\tbest: 1.0454836 (169)\ttotal: 14.3s\tremaining: 1m 9s\n",
      "170:\tlearn: 1.1759578\ttest: 1.0451648\tbest: 1.0451648 (170)\ttotal: 14.4s\tremaining: 1m 9s\n",
      "171:\tlearn: 1.1753594\ttest: 1.0449107\tbest: 1.0449107 (171)\ttotal: 14.5s\tremaining: 1m 9s\n",
      "172:\tlearn: 1.1752603\ttest: 1.0448792\tbest: 1.0448792 (172)\ttotal: 14.6s\tremaining: 1m 9s\n",
      "173:\tlearn: 1.1743998\ttest: 1.0444222\tbest: 1.0444222 (173)\ttotal: 14.6s\tremaining: 1m 9s\n",
      "174:\tlearn: 1.1740064\ttest: 1.0442623\tbest: 1.0442623 (174)\ttotal: 14.7s\tremaining: 1m 9s\n",
      "175:\tlearn: 1.1738100\ttest: 1.0441744\tbest: 1.0441744 (175)\ttotal: 14.8s\tremaining: 1m 9s\n",
      "176:\tlearn: 1.1735322\ttest: 1.0438707\tbest: 1.0438707 (176)\ttotal: 14.9s\tremaining: 1m 9s\n",
      "177:\tlearn: 1.1732991\ttest: 1.0436969\tbest: 1.0436969 (177)\ttotal: 15s\tremaining: 1m 9s\n",
      "178:\tlearn: 1.1730137\ttest: 1.0435500\tbest: 1.0435500 (178)\ttotal: 15.1s\tremaining: 1m 9s\n",
      "179:\tlearn: 1.1729302\ttest: 1.0435615\tbest: 1.0435500 (178)\ttotal: 15.1s\tremaining: 1m 8s\n",
      "180:\tlearn: 1.1727915\ttest: 1.0435089\tbest: 1.0435089 (180)\ttotal: 15.2s\tremaining: 1m 8s\n",
      "181:\tlearn: 1.1726551\ttest: 1.0434921\tbest: 1.0434921 (181)\ttotal: 15.3s\tremaining: 1m 8s\n",
      "182:\tlearn: 1.1725031\ttest: 1.0435056\tbest: 1.0434921 (181)\ttotal: 15.4s\tremaining: 1m 8s\n",
      "183:\tlearn: 1.1724249\ttest: 1.0434543\tbest: 1.0434543 (183)\ttotal: 15.5s\tremaining: 1m 8s\n",
      "184:\tlearn: 1.1718323\ttest: 1.0431884\tbest: 1.0431884 (184)\ttotal: 15.5s\tremaining: 1m 8s\n",
      "185:\tlearn: 1.1717316\ttest: 1.0431689\tbest: 1.0431689 (185)\ttotal: 15.6s\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186:\tlearn: 1.1716807\ttest: 1.0431423\tbest: 1.0431423 (186)\ttotal: 15.7s\tremaining: 1m 8s\n",
      "187:\tlearn: 1.1714338\ttest: 1.0429940\tbest: 1.0429940 (187)\ttotal: 15.8s\tremaining: 1m 8s\n",
      "188:\tlearn: 1.1711036\ttest: 1.0428048\tbest: 1.0428048 (188)\ttotal: 15.8s\tremaining: 1m 7s\n",
      "189:\tlearn: 1.1708982\ttest: 1.0426084\tbest: 1.0426084 (189)\ttotal: 15.9s\tremaining: 1m 7s\n",
      "190:\tlearn: 1.1703309\ttest: 1.0422133\tbest: 1.0422133 (190)\ttotal: 16s\tremaining: 1m 7s\n",
      "191:\tlearn: 1.1700984\ttest: 1.0420034\tbest: 1.0420034 (191)\ttotal: 16.1s\tremaining: 1m 7s\n",
      "192:\tlearn: 1.1699501\ttest: 1.0420016\tbest: 1.0420016 (192)\ttotal: 16.2s\tremaining: 1m 7s\n",
      "193:\tlearn: 1.1699136\ttest: 1.0420503\tbest: 1.0420016 (192)\ttotal: 16.2s\tremaining: 1m 7s\n",
      "194:\tlearn: 1.1697016\ttest: 1.0418629\tbest: 1.0418629 (194)\ttotal: 16.3s\tremaining: 1m 7s\n",
      "195:\tlearn: 1.1694771\ttest: 1.0418460\tbest: 1.0418460 (195)\ttotal: 16.4s\tremaining: 1m 7s\n",
      "196:\tlearn: 1.1692857\ttest: 1.0417423\tbest: 1.0417423 (196)\ttotal: 16.5s\tremaining: 1m 7s\n",
      "197:\tlearn: 1.1691481\ttest: 1.0417057\tbest: 1.0417057 (197)\ttotal: 16.6s\tremaining: 1m 7s\n",
      "198:\tlearn: 1.1687779\ttest: 1.0413744\tbest: 1.0413744 (198)\ttotal: 16.7s\tremaining: 1m 7s\n",
      "199:\tlearn: 1.1684665\ttest: 1.0412259\tbest: 1.0412259 (199)\ttotal: 16.7s\tremaining: 1m 6s\n",
      "200:\tlearn: 1.1681362\ttest: 1.0411467\tbest: 1.0411467 (200)\ttotal: 16.8s\tremaining: 1m 6s\n",
      "201:\tlearn: 1.1679422\ttest: 1.0410255\tbest: 1.0410255 (201)\ttotal: 16.9s\tremaining: 1m 6s\n",
      "202:\tlearn: 1.1675308\ttest: 1.0408402\tbest: 1.0408402 (202)\ttotal: 17s\tremaining: 1m 6s\n",
      "203:\tlearn: 1.1670841\ttest: 1.0406944\tbest: 1.0406944 (203)\ttotal: 17.1s\tremaining: 1m 6s\n",
      "204:\tlearn: 1.1669651\ttest: 1.0406199\tbest: 1.0406199 (204)\ttotal: 17.2s\tremaining: 1m 6s\n",
      "205:\tlearn: 1.1664468\ttest: 1.0403863\tbest: 1.0403863 (205)\ttotal: 17.3s\tremaining: 1m 6s\n",
      "206:\tlearn: 1.1660071\ttest: 1.0400743\tbest: 1.0400743 (206)\ttotal: 17.4s\tremaining: 1m 6s\n",
      "207:\tlearn: 1.1658831\ttest: 1.0400185\tbest: 1.0400185 (207)\ttotal: 17.4s\tremaining: 1m 6s\n",
      "208:\tlearn: 1.1657818\ttest: 1.0399497\tbest: 1.0399497 (208)\ttotal: 17.5s\tremaining: 1m 6s\n",
      "209:\tlearn: 1.1656520\ttest: 1.0399375\tbest: 1.0399375 (209)\ttotal: 17.6s\tremaining: 1m 6s\n",
      "210:\tlearn: 1.1651260\ttest: 1.0396799\tbest: 1.0396799 (210)\ttotal: 17.7s\tremaining: 1m 6s\n",
      "211:\tlearn: 1.1650395\ttest: 1.0395682\tbest: 1.0395682 (211)\ttotal: 17.8s\tremaining: 1m 6s\n",
      "212:\tlearn: 1.1644993\ttest: 1.0393110\tbest: 1.0393110 (212)\ttotal: 17.9s\tremaining: 1m 5s\n",
      "213:\tlearn: 1.1643929\ttest: 1.0392850\tbest: 1.0392850 (213)\ttotal: 17.9s\tremaining: 1m 5s\n",
      "214:\tlearn: 1.1642824\ttest: 1.0392879\tbest: 1.0392850 (213)\ttotal: 18s\tremaining: 1m 5s\n",
      "215:\tlearn: 1.1641513\ttest: 1.0392521\tbest: 1.0392521 (215)\ttotal: 18.1s\tremaining: 1m 5s\n",
      "216:\tlearn: 1.1640673\ttest: 1.0391185\tbest: 1.0391185 (216)\ttotal: 18.2s\tremaining: 1m 5s\n",
      "217:\tlearn: 1.1640129\ttest: 1.0391286\tbest: 1.0391185 (216)\ttotal: 18.3s\tremaining: 1m 5s\n",
      "218:\tlearn: 1.1638837\ttest: 1.0390677\tbest: 1.0390677 (218)\ttotal: 18.3s\tremaining: 1m 5s\n",
      "219:\tlearn: 1.1635689\ttest: 1.0390024\tbest: 1.0390024 (219)\ttotal: 18.4s\tremaining: 1m 5s\n",
      "220:\tlearn: 1.1634964\ttest: 1.0389669\tbest: 1.0389669 (220)\ttotal: 18.5s\tremaining: 1m 5s\n",
      "221:\tlearn: 1.1631727\ttest: 1.0388914\tbest: 1.0388914 (221)\ttotal: 18.6s\tremaining: 1m 5s\n",
      "222:\tlearn: 1.1631203\ttest: 1.0388798\tbest: 1.0388798 (222)\ttotal: 18.7s\tremaining: 1m 5s\n",
      "223:\tlearn: 1.1630339\ttest: 1.0388358\tbest: 1.0388358 (223)\ttotal: 18.8s\tremaining: 1m 5s\n",
      "224:\tlearn: 1.1628780\ttest: 1.0388539\tbest: 1.0388358 (223)\ttotal: 18.9s\tremaining: 1m 4s\n",
      "225:\tlearn: 1.1628122\ttest: 1.0387664\tbest: 1.0387664 (225)\ttotal: 18.9s\tremaining: 1m 4s\n",
      "226:\tlearn: 1.1627346\ttest: 1.0386940\tbest: 1.0386940 (226)\ttotal: 19s\tremaining: 1m 4s\n",
      "227:\tlearn: 1.1626232\ttest: 1.0387274\tbest: 1.0386940 (226)\ttotal: 19.1s\tremaining: 1m 4s\n",
      "228:\tlearn: 1.1624362\ttest: 1.0386756\tbest: 1.0386756 (228)\ttotal: 19.2s\tremaining: 1m 4s\n",
      "229:\tlearn: 1.1622087\ttest: 1.0386288\tbest: 1.0386288 (229)\ttotal: 19.3s\tremaining: 1m 4s\n",
      "230:\tlearn: 1.1621342\ttest: 1.0386014\tbest: 1.0386014 (230)\ttotal: 19.4s\tremaining: 1m 4s\n",
      "231:\tlearn: 1.1617300\ttest: 1.0384345\tbest: 1.0384345 (231)\ttotal: 19.5s\tremaining: 1m 4s\n",
      "232:\tlearn: 1.1616571\ttest: 1.0384059\tbest: 1.0384059 (232)\ttotal: 19.6s\tremaining: 1m 4s\n",
      "233:\tlearn: 1.1616216\ttest: 1.0383842\tbest: 1.0383842 (233)\ttotal: 19.6s\tremaining: 1m 4s\n",
      "234:\tlearn: 1.1610301\ttest: 1.0379852\tbest: 1.0379852 (234)\ttotal: 19.7s\tremaining: 1m 4s\n",
      "235:\tlearn: 1.1609205\ttest: 1.0379893\tbest: 1.0379852 (234)\ttotal: 19.8s\tremaining: 1m 4s\n",
      "236:\tlearn: 1.1608395\ttest: 1.0379823\tbest: 1.0379823 (236)\ttotal: 19.9s\tremaining: 1m 4s\n",
      "237:\tlearn: 1.1607424\ttest: 1.0378990\tbest: 1.0378990 (237)\ttotal: 20s\tremaining: 1m 3s\n",
      "238:\tlearn: 1.1606168\ttest: 1.0377991\tbest: 1.0377991 (238)\ttotal: 20s\tremaining: 1m 3s\n",
      "239:\tlearn: 1.1605200\ttest: 1.0376972\tbest: 1.0376972 (239)\ttotal: 20.1s\tremaining: 1m 3s\n",
      "240:\tlearn: 1.1601350\ttest: 1.0375845\tbest: 1.0375845 (240)\ttotal: 20.2s\tremaining: 1m 3s\n",
      "241:\tlearn: 1.1600986\ttest: 1.0375945\tbest: 1.0375845 (240)\ttotal: 20.3s\tremaining: 1m 3s\n",
      "242:\tlearn: 1.1599663\ttest: 1.0375090\tbest: 1.0375090 (242)\ttotal: 20.4s\tremaining: 1m 3s\n",
      "243:\tlearn: 1.1597403\ttest: 1.0374772\tbest: 1.0374772 (243)\ttotal: 20.4s\tremaining: 1m 3s\n",
      "244:\tlearn: 1.1595942\ttest: 1.0373714\tbest: 1.0373714 (244)\ttotal: 20.5s\tremaining: 1m 3s\n",
      "245:\tlearn: 1.1592217\ttest: 1.0372833\tbest: 1.0372833 (245)\ttotal: 20.6s\tremaining: 1m 3s\n",
      "246:\tlearn: 1.1591043\ttest: 1.0372317\tbest: 1.0372317 (246)\ttotal: 20.7s\tremaining: 1m 2s\n",
      "247:\tlearn: 1.1589688\ttest: 1.0371160\tbest: 1.0371160 (247)\ttotal: 20.7s\tremaining: 1m 2s\n",
      "248:\tlearn: 1.1588035\ttest: 1.0370434\tbest: 1.0370434 (248)\ttotal: 20.8s\tremaining: 1m 2s\n",
      "249:\tlearn: 1.1587316\ttest: 1.0369496\tbest: 1.0369496 (249)\ttotal: 20.9s\tremaining: 1m 2s\n",
      "250:\tlearn: 1.1586403\ttest: 1.0368212\tbest: 1.0368212 (250)\ttotal: 21s\tremaining: 1m 2s\n",
      "251:\tlearn: 1.1585562\ttest: 1.0367075\tbest: 1.0367075 (251)\ttotal: 21.1s\tremaining: 1m 2s\n",
      "252:\tlearn: 1.1584429\ttest: 1.0366931\tbest: 1.0366931 (252)\ttotal: 21.1s\tremaining: 1m 2s\n",
      "253:\tlearn: 1.1581733\ttest: 1.0364384\tbest: 1.0364384 (253)\ttotal: 21.2s\tremaining: 1m 2s\n",
      "254:\tlearn: 1.1577897\ttest: 1.0362564\tbest: 1.0362564 (254)\ttotal: 21.3s\tremaining: 1m 2s\n",
      "255:\tlearn: 1.1577197\ttest: 1.0361554\tbest: 1.0361554 (255)\ttotal: 21.4s\tremaining: 1m 2s\n",
      "256:\tlearn: 1.1575659\ttest: 1.0360965\tbest: 1.0360965 (256)\ttotal: 21.5s\tremaining: 1m 2s\n",
      "257:\tlearn: 1.1575346\ttest: 1.0361205\tbest: 1.0360965 (256)\ttotal: 21.5s\tremaining: 1m 1s\n",
      "258:\tlearn: 1.1574853\ttest: 1.0361014\tbest: 1.0360965 (256)\ttotal: 21.6s\tremaining: 1m 1s\n",
      "259:\tlearn: 1.1572794\ttest: 1.0360088\tbest: 1.0360088 (259)\ttotal: 21.7s\tremaining: 1m 1s\n",
      "260:\tlearn: 1.1567823\ttest: 1.0357760\tbest: 1.0357760 (260)\ttotal: 21.8s\tremaining: 1m 1s\n",
      "261:\tlearn: 1.1565929\ttest: 1.0356499\tbest: 1.0356499 (261)\ttotal: 21.9s\tremaining: 1m 1s\n",
      "262:\tlearn: 1.1565448\ttest: 1.0356546\tbest: 1.0356499 (261)\ttotal: 22s\tremaining: 1m 1s\n",
      "263:\tlearn: 1.1564242\ttest: 1.0356778\tbest: 1.0356499 (261)\ttotal: 22.1s\tremaining: 1m 1s\n",
      "264:\tlearn: 1.1563538\ttest: 1.0356344\tbest: 1.0356344 (264)\ttotal: 22.1s\tremaining: 1m 1s\n",
      "265:\tlearn: 1.1560282\ttest: 1.0355451\tbest: 1.0355451 (265)\ttotal: 22.2s\tremaining: 1m 1s\n",
      "266:\tlearn: 1.1559372\ttest: 1.0355914\tbest: 1.0355451 (265)\ttotal: 22.3s\tremaining: 1m 1s\n",
      "267:\tlearn: 1.1558963\ttest: 1.0355819\tbest: 1.0355451 (265)\ttotal: 22.4s\tremaining: 1m 1s\n",
      "268:\tlearn: 1.1557637\ttest: 1.0355156\tbest: 1.0355156 (268)\ttotal: 22.5s\tremaining: 1m 1s\n",
      "269:\tlearn: 1.1556413\ttest: 1.0354417\tbest: 1.0354417 (269)\ttotal: 22.6s\tremaining: 1m 1s\n",
      "270:\tlearn: 1.1554311\ttest: 1.0353815\tbest: 1.0353815 (270)\ttotal: 22.7s\tremaining: 1m 1s\n",
      "271:\tlearn: 1.1553256\ttest: 1.0354133\tbest: 1.0353815 (270)\ttotal: 22.8s\tremaining: 1m 1s\n",
      "272:\tlearn: 1.1551145\ttest: 1.0354176\tbest: 1.0353815 (270)\ttotal: 22.9s\tremaining: 1m\n",
      "273:\tlearn: 1.1550357\ttest: 1.0353589\tbest: 1.0353589 (273)\ttotal: 23s\tremaining: 1m\n",
      "274:\tlearn: 1.1549656\ttest: 1.0353612\tbest: 1.0353589 (273)\ttotal: 23.1s\tremaining: 1m\n",
      "275:\tlearn: 1.1548010\ttest: 1.0353205\tbest: 1.0353205 (275)\ttotal: 23.1s\tremaining: 1m\n",
      "276:\tlearn: 1.1546744\ttest: 1.0352539\tbest: 1.0352539 (276)\ttotal: 23.2s\tremaining: 1m\n",
      "277:\tlearn: 1.1544649\ttest: 1.0351306\tbest: 1.0351306 (277)\ttotal: 23.3s\tremaining: 1m\n",
      "278:\tlearn: 1.1544450\ttest: 1.0351195\tbest: 1.0351195 (278)\ttotal: 23.4s\tremaining: 1m\n",
      "279:\tlearn: 1.1543800\ttest: 1.0351075\tbest: 1.0351075 (279)\ttotal: 23.5s\tremaining: 1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280:\tlearn: 1.1542697\ttest: 1.0350202\tbest: 1.0350202 (280)\ttotal: 23.6s\tremaining: 1m\n",
      "281:\tlearn: 1.1541283\ttest: 1.0349875\tbest: 1.0349875 (281)\ttotal: 23.7s\tremaining: 1m\n",
      "282:\tlearn: 1.1540902\ttest: 1.0349910\tbest: 1.0349875 (281)\ttotal: 23.7s\tremaining: 1m\n",
      "283:\tlearn: 1.1540529\ttest: 1.0349627\tbest: 1.0349627 (283)\ttotal: 23.8s\tremaining: 1m\n",
      "284:\tlearn: 1.1539605\ttest: 1.0349049\tbest: 1.0349049 (284)\ttotal: 23.9s\tremaining: 60s\n",
      "285:\tlearn: 1.1538720\ttest: 1.0348507\tbest: 1.0348507 (285)\ttotal: 24s\tremaining: 59.9s\n",
      "286:\tlearn: 1.1535094\ttest: 1.0348119\tbest: 1.0348119 (286)\ttotal: 24.1s\tremaining: 59.8s\n",
      "287:\tlearn: 1.1534811\ttest: 1.0347840\tbest: 1.0347840 (287)\ttotal: 24.2s\tremaining: 59.7s\n",
      "288:\tlearn: 1.1532322\ttest: 1.0346763\tbest: 1.0346763 (288)\ttotal: 24.2s\tremaining: 59.7s\n",
      "289:\tlearn: 1.1529666\ttest: 1.0346124\tbest: 1.0346124 (289)\ttotal: 24.3s\tremaining: 59.6s\n",
      "290:\tlearn: 1.1528997\ttest: 1.0345801\tbest: 1.0345801 (290)\ttotal: 24.4s\tremaining: 59.4s\n",
      "291:\tlearn: 1.1528138\ttest: 1.0345724\tbest: 1.0345724 (291)\ttotal: 24.5s\tremaining: 59.4s\n",
      "292:\tlearn: 1.1527307\ttest: 1.0345228\tbest: 1.0345228 (292)\ttotal: 24.6s\tremaining: 59.3s\n",
      "293:\tlearn: 1.1527034\ttest: 1.0345218\tbest: 1.0345218 (293)\ttotal: 24.7s\tremaining: 59.2s\n",
      "294:\tlearn: 1.1526358\ttest: 1.0344841\tbest: 1.0344841 (294)\ttotal: 24.7s\tremaining: 59.1s\n",
      "295:\tlearn: 1.1524471\ttest: 1.0344652\tbest: 1.0344652 (295)\ttotal: 24.8s\tremaining: 59s\n",
      "296:\tlearn: 1.1523929\ttest: 1.0344126\tbest: 1.0344126 (296)\ttotal: 24.9s\tremaining: 59s\n",
      "297:\tlearn: 1.1523358\ttest: 1.0344786\tbest: 1.0344126 (296)\ttotal: 25s\tremaining: 58.9s\n",
      "298:\tlearn: 1.1522552\ttest: 1.0344563\tbest: 1.0344126 (296)\ttotal: 25.1s\tremaining: 58.8s\n",
      "299:\tlearn: 1.1521501\ttest: 1.0344178\tbest: 1.0344126 (296)\ttotal: 25.2s\tremaining: 58.7s\n",
      "300:\tlearn: 1.1519013\ttest: 1.0343026\tbest: 1.0343026 (300)\ttotal: 25.2s\tremaining: 58.6s\n",
      "301:\tlearn: 1.1518673\ttest: 1.0342670\tbest: 1.0342670 (301)\ttotal: 25.3s\tremaining: 58.5s\n",
      "302:\tlearn: 1.1517827\ttest: 1.0342798\tbest: 1.0342670 (301)\ttotal: 25.4s\tremaining: 58.4s\n",
      "303:\tlearn: 1.1517565\ttest: 1.0342792\tbest: 1.0342670 (301)\ttotal: 25.5s\tremaining: 58.3s\n",
      "304:\tlearn: 1.1516416\ttest: 1.0342147\tbest: 1.0342147 (304)\ttotal: 25.6s\tremaining: 58.2s\n",
      "305:\tlearn: 1.1513050\ttest: 1.0341127\tbest: 1.0341127 (305)\ttotal: 25.7s\tremaining: 58.2s\n",
      "306:\tlearn: 1.1512424\ttest: 1.0341171\tbest: 1.0341127 (305)\ttotal: 25.7s\tremaining: 58.1s\n",
      "307:\tlearn: 1.1511661\ttest: 1.0340854\tbest: 1.0340854 (307)\ttotal: 25.8s\tremaining: 58s\n",
      "308:\tlearn: 1.1511254\ttest: 1.0340772\tbest: 1.0340772 (308)\ttotal: 25.9s\tremaining: 57.9s\n",
      "309:\tlearn: 1.1510565\ttest: 1.0340536\tbest: 1.0340536 (309)\ttotal: 26s\tremaining: 57.8s\n",
      "310:\tlearn: 1.1509393\ttest: 1.0340434\tbest: 1.0340434 (310)\ttotal: 26.1s\tremaining: 57.7s\n",
      "311:\tlearn: 1.1507391\ttest: 1.0338958\tbest: 1.0338958 (311)\ttotal: 26.1s\tremaining: 57.7s\n",
      "312:\tlearn: 1.1506876\ttest: 1.0338108\tbest: 1.0338108 (312)\ttotal: 26.2s\tremaining: 57.6s\n",
      "313:\tlearn: 1.1505581\ttest: 1.0337692\tbest: 1.0337692 (313)\ttotal: 26.3s\tremaining: 57.5s\n",
      "314:\tlearn: 1.1505149\ttest: 1.0337881\tbest: 1.0337692 (313)\ttotal: 26.4s\tremaining: 57.4s\n",
      "315:\tlearn: 1.1503020\ttest: 1.0337454\tbest: 1.0337454 (315)\ttotal: 26.5s\tremaining: 57.4s\n",
      "316:\tlearn: 1.1502806\ttest: 1.0337246\tbest: 1.0337246 (316)\ttotal: 26.6s\tremaining: 57.3s\n",
      "317:\tlearn: 1.1502307\ttest: 1.0337029\tbest: 1.0337029 (317)\ttotal: 26.7s\tremaining: 57.2s\n",
      "318:\tlearn: 1.1501858\ttest: 1.0336366\tbest: 1.0336366 (318)\ttotal: 26.7s\tremaining: 57.1s\n",
      "319:\tlearn: 1.1500425\ttest: 1.0335633\tbest: 1.0335633 (319)\ttotal: 26.8s\tremaining: 57s\n",
      "320:\tlearn: 1.1499765\ttest: 1.0335205\tbest: 1.0335205 (320)\ttotal: 26.9s\tremaining: 56.9s\n",
      "321:\tlearn: 1.1498711\ttest: 1.0334346\tbest: 1.0334346 (321)\ttotal: 27s\tremaining: 56.8s\n",
      "322:\tlearn: 1.1498115\ttest: 1.0333612\tbest: 1.0333612 (322)\ttotal: 27s\tremaining: 56.7s\n",
      "323:\tlearn: 1.1497816\ttest: 1.0333470\tbest: 1.0333470 (323)\ttotal: 27.1s\tremaining: 56.6s\n",
      "324:\tlearn: 1.1497487\ttest: 1.0332993\tbest: 1.0332993 (324)\ttotal: 27.2s\tremaining: 56.5s\n",
      "325:\tlearn: 1.1497106\ttest: 1.0333060\tbest: 1.0332993 (324)\ttotal: 27.3s\tremaining: 56.4s\n",
      "326:\tlearn: 1.1495427\ttest: 1.0333091\tbest: 1.0332993 (324)\ttotal: 27.4s\tremaining: 56.3s\n",
      "327:\tlearn: 1.1495273\ttest: 1.0333387\tbest: 1.0332993 (324)\ttotal: 27.4s\tremaining: 56.2s\n",
      "328:\tlearn: 1.1494902\ttest: 1.0333824\tbest: 1.0332993 (324)\ttotal: 27.5s\tremaining: 56.2s\n",
      "329:\tlearn: 1.1494607\ttest: 1.0333621\tbest: 1.0332993 (324)\ttotal: 27.6s\tremaining: 56.1s\n",
      "330:\tlearn: 1.1493611\ttest: 1.0332961\tbest: 1.0332961 (330)\ttotal: 27.7s\tremaining: 56.1s\n",
      "331:\tlearn: 1.1492874\ttest: 1.0334326\tbest: 1.0332961 (330)\ttotal: 27.9s\tremaining: 56.1s\n",
      "332:\tlearn: 1.1492173\ttest: 1.0333714\tbest: 1.0332961 (330)\ttotal: 28s\tremaining: 56s\n",
      "333:\tlearn: 1.1489574\ttest: 1.0333458\tbest: 1.0332961 (330)\ttotal: 28.1s\tremaining: 56s\n",
      "334:\tlearn: 1.1488363\ttest: 1.0333432\tbest: 1.0332961 (330)\ttotal: 28.1s\tremaining: 55.9s\n",
      "335:\tlearn: 1.1487968\ttest: 1.0332833\tbest: 1.0332833 (335)\ttotal: 28.3s\tremaining: 55.9s\n",
      "336:\tlearn: 1.1487057\ttest: 1.0332441\tbest: 1.0332441 (336)\ttotal: 28.4s\tremaining: 55.8s\n",
      "337:\tlearn: 1.1485973\ttest: 1.0331815\tbest: 1.0331815 (337)\ttotal: 28.5s\tremaining: 55.8s\n",
      "338:\tlearn: 1.1485550\ttest: 1.0331541\tbest: 1.0331541 (338)\ttotal: 28.5s\tremaining: 55.7s\n",
      "339:\tlearn: 1.1484380\ttest: 1.0331259\tbest: 1.0331259 (339)\ttotal: 28.6s\tremaining: 55.6s\n",
      "340:\tlearn: 1.1481932\ttest: 1.0329988\tbest: 1.0329988 (340)\ttotal: 28.7s\tremaining: 55.5s\n",
      "341:\tlearn: 1.1480766\ttest: 1.0330474\tbest: 1.0329988 (340)\ttotal: 28.8s\tremaining: 55.4s\n",
      "342:\tlearn: 1.1480430\ttest: 1.0330283\tbest: 1.0329988 (340)\ttotal: 28.9s\tremaining: 55.3s\n",
      "343:\tlearn: 1.1480176\ttest: 1.0330047\tbest: 1.0329988 (340)\ttotal: 29s\tremaining: 55.2s\n",
      "344:\tlearn: 1.1479895\ttest: 1.0329823\tbest: 1.0329823 (344)\ttotal: 29s\tremaining: 55.1s\n",
      "345:\tlearn: 1.1478701\ttest: 1.0329361\tbest: 1.0329361 (345)\ttotal: 29.1s\tremaining: 55.1s\n",
      "346:\tlearn: 1.1475673\ttest: 1.0327713\tbest: 1.0327713 (346)\ttotal: 29.2s\tremaining: 54.9s\n",
      "347:\tlearn: 1.1474830\ttest: 1.0327096\tbest: 1.0327096 (347)\ttotal: 29.3s\tremaining: 54.9s\n",
      "348:\tlearn: 1.1474387\ttest: 1.0327130\tbest: 1.0327096 (347)\ttotal: 29.4s\tremaining: 54.8s\n",
      "349:\tlearn: 1.1473761\ttest: 1.0326832\tbest: 1.0326832 (349)\ttotal: 29.5s\tremaining: 54.7s\n",
      "350:\tlearn: 1.1472978\ttest: 1.0326578\tbest: 1.0326578 (350)\ttotal: 29.5s\tremaining: 54.6s\n",
      "351:\tlearn: 1.1471184\ttest: 1.0326779\tbest: 1.0326578 (350)\ttotal: 29.6s\tremaining: 54.5s\n",
      "352:\tlearn: 1.1470572\ttest: 1.0325683\tbest: 1.0325683 (352)\ttotal: 29.7s\tremaining: 54.5s\n",
      "353:\tlearn: 1.1470069\ttest: 1.0325581\tbest: 1.0325581 (353)\ttotal: 29.8s\tremaining: 54.4s\n",
      "354:\tlearn: 1.1469844\ttest: 1.0325417\tbest: 1.0325417 (354)\ttotal: 29.9s\tremaining: 54.3s\n",
      "355:\tlearn: 1.1469203\ttest: 1.0325379\tbest: 1.0325379 (355)\ttotal: 30s\tremaining: 54.2s\n",
      "356:\tlearn: 1.1468249\ttest: 1.0325107\tbest: 1.0325107 (356)\ttotal: 30.1s\tremaining: 54.1s\n",
      "357:\tlearn: 1.1467926\ttest: 1.0325266\tbest: 1.0325107 (356)\ttotal: 30.1s\tremaining: 54s\n",
      "358:\tlearn: 1.1467300\ttest: 1.0324788\tbest: 1.0324788 (358)\ttotal: 30.2s\tremaining: 53.9s\n",
      "359:\tlearn: 1.1466809\ttest: 1.0326380\tbest: 1.0324788 (358)\ttotal: 30.3s\tremaining: 53.8s\n",
      "360:\tlearn: 1.1465772\ttest: 1.0326424\tbest: 1.0324788 (358)\ttotal: 30.3s\tremaining: 53.7s\n",
      "361:\tlearn: 1.1465199\ttest: 1.0326177\tbest: 1.0324788 (358)\ttotal: 30.4s\tremaining: 53.6s\n",
      "362:\tlearn: 1.1464635\ttest: 1.0326082\tbest: 1.0324788 (358)\ttotal: 30.5s\tremaining: 53.5s\n",
      "363:\tlearn: 1.1463768\ttest: 1.0325056\tbest: 1.0324788 (358)\ttotal: 30.6s\tremaining: 53.5s\n",
      "364:\tlearn: 1.1462968\ttest: 1.0324755\tbest: 1.0324755 (364)\ttotal: 30.7s\tremaining: 53.4s\n",
      "365:\tlearn: 1.1460763\ttest: 1.0323087\tbest: 1.0323087 (365)\ttotal: 30.8s\tremaining: 53.3s\n",
      "366:\tlearn: 1.1460187\ttest: 1.0322715\tbest: 1.0322715 (366)\ttotal: 30.9s\tremaining: 53.2s\n",
      "367:\tlearn: 1.1459409\ttest: 1.0321808\tbest: 1.0321808 (367)\ttotal: 30.9s\tremaining: 53.1s\n",
      "368:\tlearn: 1.1459160\ttest: 1.0321548\tbest: 1.0321548 (368)\ttotal: 31s\tremaining: 53s\n",
      "369:\tlearn: 1.1456792\ttest: 1.0319611\tbest: 1.0319611 (369)\ttotal: 31.1s\tremaining: 53s\n",
      "370:\tlearn: 1.1456497\ttest: 1.0320639\tbest: 1.0319611 (369)\ttotal: 31.2s\tremaining: 52.9s\n",
      "371:\tlearn: 1.1454382\ttest: 1.0320757\tbest: 1.0319611 (369)\ttotal: 31.3s\tremaining: 52.9s\n",
      "372:\tlearn: 1.1454008\ttest: 1.0320620\tbest: 1.0319611 (369)\ttotal: 31.4s\tremaining: 52.8s\n",
      "373:\tlearn: 1.1452826\ttest: 1.0320763\tbest: 1.0319611 (369)\ttotal: 31.5s\tremaining: 52.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374:\tlearn: 1.1452432\ttest: 1.0320016\tbest: 1.0319611 (369)\ttotal: 31.6s\tremaining: 52.7s\n",
      "375:\tlearn: 1.1451142\ttest: 1.0320519\tbest: 1.0319611 (369)\ttotal: 31.7s\tremaining: 52.6s\n",
      "376:\tlearn: 1.1450596\ttest: 1.0320006\tbest: 1.0319611 (369)\ttotal: 31.8s\tremaining: 52.5s\n",
      "377:\tlearn: 1.1450189\ttest: 1.0318950\tbest: 1.0318950 (377)\ttotal: 31.9s\tremaining: 52.5s\n",
      "378:\tlearn: 1.1448048\ttest: 1.0318031\tbest: 1.0318031 (378)\ttotal: 32s\tremaining: 52.4s\n",
      "379:\tlearn: 1.1447887\ttest: 1.0317934\tbest: 1.0317934 (379)\ttotal: 32s\tremaining: 52.3s\n",
      "380:\tlearn: 1.1446324\ttest: 1.0317635\tbest: 1.0317635 (380)\ttotal: 32.1s\tremaining: 52.2s\n",
      "381:\tlearn: 1.1445776\ttest: 1.0318444\tbest: 1.0317635 (380)\ttotal: 32.3s\tremaining: 52.3s\n",
      "382:\tlearn: 1.1445310\ttest: 1.0319093\tbest: 1.0317635 (380)\ttotal: 32.4s\tremaining: 52.2s\n",
      "383:\tlearn: 1.1445128\ttest: 1.0319436\tbest: 1.0317635 (380)\ttotal: 32.5s\tremaining: 52.1s\n",
      "384:\tlearn: 1.1444493\ttest: 1.0318628\tbest: 1.0317635 (380)\ttotal: 32.6s\tremaining: 52s\n",
      "385:\tlearn: 1.1444284\ttest: 1.0318381\tbest: 1.0317635 (380)\ttotal: 32.6s\tremaining: 51.9s\n",
      "386:\tlearn: 1.1443821\ttest: 1.0318277\tbest: 1.0317635 (380)\ttotal: 32.7s\tremaining: 51.8s\n",
      "387:\tlearn: 1.1443336\ttest: 1.0318335\tbest: 1.0317635 (380)\ttotal: 32.8s\tremaining: 51.7s\n",
      "388:\tlearn: 1.1443023\ttest: 1.0317653\tbest: 1.0317635 (380)\ttotal: 32.9s\tremaining: 51.6s\n",
      "389:\tlearn: 1.1442774\ttest: 1.0317192\tbest: 1.0317192 (389)\ttotal: 33s\tremaining: 51.5s\n",
      "390:\tlearn: 1.1442274\ttest: 1.0316606\tbest: 1.0316606 (390)\ttotal: 33s\tremaining: 51.5s\n",
      "391:\tlearn: 1.1441920\ttest: 1.0317095\tbest: 1.0316606 (390)\ttotal: 33.1s\tremaining: 51.4s\n",
      "392:\tlearn: 1.1439740\ttest: 1.0316729\tbest: 1.0316606 (390)\ttotal: 33.2s\tremaining: 51.3s\n",
      "393:\tlearn: 1.1438605\ttest: 1.0316759\tbest: 1.0316606 (390)\ttotal: 33.3s\tremaining: 51.2s\n",
      "394:\tlearn: 1.1438274\ttest: 1.0316624\tbest: 1.0316606 (390)\ttotal: 33.4s\tremaining: 51.1s\n",
      "395:\tlearn: 1.1437675\ttest: 1.0315547\tbest: 1.0315547 (395)\ttotal: 33.4s\tremaining: 51s\n",
      "396:\tlearn: 1.1437105\ttest: 1.0315072\tbest: 1.0315072 (396)\ttotal: 33.5s\tremaining: 50.9s\n",
      "397:\tlearn: 1.1436520\ttest: 1.0314165\tbest: 1.0314165 (397)\ttotal: 33.6s\tremaining: 50.9s\n",
      "398:\tlearn: 1.1436169\ttest: 1.0314226\tbest: 1.0314165 (397)\ttotal: 33.7s\tremaining: 50.8s\n",
      "399:\tlearn: 1.1435748\ttest: 1.0314118\tbest: 1.0314118 (399)\ttotal: 33.8s\tremaining: 50.6s\n",
      "400:\tlearn: 1.1435038\ttest: 1.0313461\tbest: 1.0313461 (400)\ttotal: 33.8s\tremaining: 50.5s\n",
      "401:\tlearn: 1.1434644\ttest: 1.0313478\tbest: 1.0313461 (400)\ttotal: 33.9s\tremaining: 50.4s\n",
      "402:\tlearn: 1.1433771\ttest: 1.0313238\tbest: 1.0313238 (402)\ttotal: 34s\tremaining: 50.4s\n",
      "403:\tlearn: 1.1433194\ttest: 1.0313233\tbest: 1.0313233 (403)\ttotal: 34.1s\tremaining: 50.3s\n",
      "404:\tlearn: 1.1432533\ttest: 1.0312913\tbest: 1.0312913 (404)\ttotal: 34.1s\tremaining: 50.2s\n",
      "405:\tlearn: 1.1432326\ttest: 1.0312821\tbest: 1.0312821 (405)\ttotal: 34.2s\tremaining: 50.1s\n",
      "406:\tlearn: 1.1431768\ttest: 1.0312911\tbest: 1.0312821 (405)\ttotal: 34.3s\tremaining: 50s\n",
      "407:\tlearn: 1.1431434\ttest: 1.0312703\tbest: 1.0312703 (407)\ttotal: 34.4s\tremaining: 49.9s\n",
      "408:\tlearn: 1.1429227\ttest: 1.0312514\tbest: 1.0312514 (408)\ttotal: 34.5s\tremaining: 49.8s\n",
      "409:\tlearn: 1.1428913\ttest: 1.0312430\tbest: 1.0312430 (409)\ttotal: 34.6s\tremaining: 49.7s\n",
      "410:\tlearn: 1.1428412\ttest: 1.0312778\tbest: 1.0312430 (409)\ttotal: 34.6s\tremaining: 49.6s\n",
      "411:\tlearn: 1.1428142\ttest: 1.0312640\tbest: 1.0312430 (409)\ttotal: 34.7s\tremaining: 49.5s\n",
      "412:\tlearn: 1.1427874\ttest: 1.0312043\tbest: 1.0312043 (412)\ttotal: 34.8s\tremaining: 49.5s\n",
      "413:\tlearn: 1.1427295\ttest: 1.0311138\tbest: 1.0311138 (413)\ttotal: 34.9s\tremaining: 49.4s\n",
      "414:\tlearn: 1.1426947\ttest: 1.0311236\tbest: 1.0311138 (413)\ttotal: 35s\tremaining: 49.3s\n",
      "415:\tlearn: 1.1425809\ttest: 1.0311393\tbest: 1.0311138 (413)\ttotal: 35s\tremaining: 49.2s\n",
      "416:\tlearn: 1.1425444\ttest: 1.0310942\tbest: 1.0310942 (416)\ttotal: 35.1s\tremaining: 49.1s\n",
      "417:\tlearn: 1.1425123\ttest: 1.0310860\tbest: 1.0310860 (417)\ttotal: 35.2s\tremaining: 49s\n",
      "418:\tlearn: 1.1424270\ttest: 1.0310318\tbest: 1.0310318 (418)\ttotal: 35.3s\tremaining: 48.9s\n",
      "419:\tlearn: 1.1423601\ttest: 1.0310607\tbest: 1.0310318 (418)\ttotal: 35.4s\tremaining: 48.8s\n",
      "420:\tlearn: 1.1422216\ttest: 1.0310819\tbest: 1.0310318 (418)\ttotal: 35.4s\tremaining: 48.7s\n",
      "421:\tlearn: 1.1421386\ttest: 1.0310512\tbest: 1.0310318 (418)\ttotal: 35.5s\tremaining: 48.7s\n",
      "422:\tlearn: 1.1421192\ttest: 1.0310181\tbest: 1.0310181 (422)\ttotal: 35.6s\tremaining: 48.6s\n",
      "423:\tlearn: 1.1420805\ttest: 1.0309566\tbest: 1.0309566 (423)\ttotal: 35.7s\tremaining: 48.5s\n",
      "424:\tlearn: 1.1419423\ttest: 1.0309178\tbest: 1.0309178 (424)\ttotal: 35.8s\tremaining: 48.4s\n",
      "425:\tlearn: 1.1418751\ttest: 1.0308680\tbest: 1.0308680 (425)\ttotal: 35.8s\tremaining: 48.3s\n",
      "426:\tlearn: 1.1418334\ttest: 1.0308327\tbest: 1.0308327 (426)\ttotal: 35.9s\tremaining: 48.2s\n",
      "427:\tlearn: 1.1418125\ttest: 1.0308364\tbest: 1.0308327 (426)\ttotal: 36s\tremaining: 48.1s\n",
      "428:\tlearn: 1.1417782\ttest: 1.0308091\tbest: 1.0308091 (428)\ttotal: 36.1s\tremaining: 48s\n",
      "429:\tlearn: 1.1417629\ttest: 1.0308006\tbest: 1.0308006 (429)\ttotal: 36.2s\tremaining: 47.9s\n",
      "430:\tlearn: 1.1417408\ttest: 1.0308147\tbest: 1.0308006 (429)\ttotal: 36.2s\tremaining: 47.8s\n",
      "431:\tlearn: 1.1416401\ttest: 1.0308168\tbest: 1.0308006 (429)\ttotal: 36.3s\tremaining: 47.7s\n",
      "432:\tlearn: 1.1416146\ttest: 1.0307996\tbest: 1.0307996 (432)\ttotal: 36.4s\tremaining: 47.7s\n",
      "433:\tlearn: 1.1415414\ttest: 1.0307319\tbest: 1.0307319 (433)\ttotal: 36.5s\tremaining: 47.6s\n",
      "434:\tlearn: 1.1414958\ttest: 1.0307683\tbest: 1.0307319 (433)\ttotal: 36.6s\tremaining: 47.5s\n",
      "435:\tlearn: 1.1414497\ttest: 1.0307643\tbest: 1.0307319 (433)\ttotal: 36.7s\tremaining: 47.4s\n",
      "436:\tlearn: 1.1414081\ttest: 1.0307669\tbest: 1.0307319 (433)\ttotal: 36.7s\tremaining: 47.3s\n",
      "437:\tlearn: 1.1413886\ttest: 1.0307402\tbest: 1.0307319 (433)\ttotal: 36.8s\tremaining: 47.3s\n",
      "438:\tlearn: 1.1413642\ttest: 1.0307120\tbest: 1.0307120 (438)\ttotal: 36.9s\tremaining: 47.2s\n",
      "439:\tlearn: 1.1413124\ttest: 1.0307284\tbest: 1.0307120 (438)\ttotal: 37s\tremaining: 47.1s\n",
      "440:\tlearn: 1.1412380\ttest: 1.0307309\tbest: 1.0307120 (438)\ttotal: 37.1s\tremaining: 47s\n",
      "441:\tlearn: 1.1410901\ttest: 1.0307020\tbest: 1.0307020 (441)\ttotal: 37.2s\tremaining: 46.9s\n",
      "442:\tlearn: 1.1410248\ttest: 1.0306730\tbest: 1.0306730 (442)\ttotal: 37.2s\tremaining: 46.8s\n",
      "443:\tlearn: 1.1409839\ttest: 1.0306538\tbest: 1.0306538 (443)\ttotal: 37.3s\tremaining: 46.8s\n",
      "444:\tlearn: 1.1409483\ttest: 1.0306340\tbest: 1.0306340 (444)\ttotal: 37.5s\tremaining: 46.7s\n",
      "445:\tlearn: 1.1409242\ttest: 1.0306551\tbest: 1.0306340 (444)\ttotal: 37.5s\tremaining: 46.6s\n",
      "446:\tlearn: 1.1408740\ttest: 1.0305976\tbest: 1.0305976 (446)\ttotal: 37.6s\tremaining: 46.5s\n",
      "447:\tlearn: 1.1408635\ttest: 1.0305684\tbest: 1.0305684 (447)\ttotal: 37.7s\tremaining: 46.4s\n",
      "448:\tlearn: 1.1408163\ttest: 1.0305511\tbest: 1.0305511 (448)\ttotal: 37.8s\tremaining: 46.3s\n",
      "449:\tlearn: 1.1407857\ttest: 1.0305284\tbest: 1.0305284 (449)\ttotal: 37.9s\tremaining: 46.3s\n",
      "450:\tlearn: 1.1407402\ttest: 1.0304876\tbest: 1.0304876 (450)\ttotal: 38s\tremaining: 46.2s\n",
      "451:\tlearn: 1.1406056\ttest: 1.0304403\tbest: 1.0304403 (451)\ttotal: 38s\tremaining: 46.1s\n",
      "452:\tlearn: 1.1405847\ttest: 1.0304722\tbest: 1.0304403 (451)\ttotal: 38.1s\tremaining: 46s\n",
      "453:\tlearn: 1.1405758\ttest: 1.0304588\tbest: 1.0304403 (451)\ttotal: 38.2s\tremaining: 45.9s\n",
      "454:\tlearn: 1.1403425\ttest: 1.0304299\tbest: 1.0304299 (454)\ttotal: 38.3s\tremaining: 45.9s\n",
      "455:\tlearn: 1.1401863\ttest: 1.0303978\tbest: 1.0303978 (455)\ttotal: 38.4s\tremaining: 45.8s\n",
      "456:\tlearn: 1.1401664\ttest: 1.0303771\tbest: 1.0303771 (456)\ttotal: 38.5s\tremaining: 45.7s\n",
      "457:\tlearn: 1.1401531\ttest: 1.0303978\tbest: 1.0303771 (456)\ttotal: 38.5s\tremaining: 45.6s\n",
      "458:\tlearn: 1.1401352\ttest: 1.0303942\tbest: 1.0303771 (456)\ttotal: 38.7s\tremaining: 45.6s\n",
      "459:\tlearn: 1.1400772\ttest: 1.0304087\tbest: 1.0303771 (456)\ttotal: 38.7s\tremaining: 45.5s\n",
      "460:\tlearn: 1.1400493\ttest: 1.0303716\tbest: 1.0303716 (460)\ttotal: 38.8s\tremaining: 45.4s\n",
      "461:\tlearn: 1.1400122\ttest: 1.0303373\tbest: 1.0303373 (461)\ttotal: 38.9s\tremaining: 45.3s\n",
      "462:\tlearn: 1.1399802\ttest: 1.0303176\tbest: 1.0303176 (462)\ttotal: 39s\tremaining: 45.2s\n",
      "463:\tlearn: 1.1399332\ttest: 1.0303064\tbest: 1.0303064 (463)\ttotal: 39s\tremaining: 45.1s\n",
      "464:\tlearn: 1.1399071\ttest: 1.0303133\tbest: 1.0303064 (463)\ttotal: 39.1s\tremaining: 45s\n",
      "465:\tlearn: 1.1398947\ttest: 1.0303823\tbest: 1.0303064 (463)\ttotal: 39.2s\tremaining: 44.9s\n",
      "466:\tlearn: 1.1398704\ttest: 1.0303784\tbest: 1.0303064 (463)\ttotal: 39.3s\tremaining: 44.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467:\tlearn: 1.1398514\ttest: 1.0303507\tbest: 1.0303064 (463)\ttotal: 39.4s\tremaining: 44.8s\n",
      "468:\tlearn: 1.1398421\ttest: 1.0303429\tbest: 1.0303064 (463)\ttotal: 39.5s\tremaining: 44.7s\n",
      "469:\tlearn: 1.1397852\ttest: 1.0303079\tbest: 1.0303064 (463)\ttotal: 39.6s\tremaining: 44.6s\n",
      "470:\tlearn: 1.1397419\ttest: 1.0302577\tbest: 1.0302577 (470)\ttotal: 39.6s\tremaining: 44.5s\n",
      "471:\tlearn: 1.1396962\ttest: 1.0302180\tbest: 1.0302180 (471)\ttotal: 39.7s\tremaining: 44.5s\n",
      "472:\tlearn: 1.1396329\ttest: 1.0302084\tbest: 1.0302084 (472)\ttotal: 39.8s\tremaining: 44.4s\n",
      "473:\tlearn: 1.1395927\ttest: 1.0301689\tbest: 1.0301689 (473)\ttotal: 39.9s\tremaining: 44.3s\n",
      "474:\tlearn: 1.1395400\ttest: 1.0301596\tbest: 1.0301596 (474)\ttotal: 40s\tremaining: 44.2s\n",
      "475:\tlearn: 1.1395062\ttest: 1.0300954\tbest: 1.0300954 (475)\ttotal: 40.1s\tremaining: 44.2s\n",
      "476:\tlearn: 1.1394321\ttest: 1.0301012\tbest: 1.0300954 (475)\ttotal: 40.2s\tremaining: 44.1s\n",
      "477:\tlearn: 1.1394137\ttest: 1.0301089\tbest: 1.0300954 (475)\ttotal: 40.3s\tremaining: 44s\n",
      "478:\tlearn: 1.1392784\ttest: 1.0301099\tbest: 1.0300954 (475)\ttotal: 40.4s\tremaining: 43.9s\n",
      "479:\tlearn: 1.1392014\ttest: 1.0300413\tbest: 1.0300413 (479)\ttotal: 40.4s\tremaining: 43.8s\n",
      "480:\tlearn: 1.1391494\ttest: 1.0300275\tbest: 1.0300275 (480)\ttotal: 40.5s\tremaining: 43.7s\n",
      "481:\tlearn: 1.1390764\ttest: 1.0299927\tbest: 1.0299927 (481)\ttotal: 40.6s\tremaining: 43.6s\n",
      "482:\tlearn: 1.1390596\ttest: 1.0299459\tbest: 1.0299459 (482)\ttotal: 40.7s\tremaining: 43.6s\n",
      "483:\tlearn: 1.1389283\ttest: 1.0298947\tbest: 1.0298947 (483)\ttotal: 40.8s\tremaining: 43.5s\n",
      "484:\tlearn: 1.1388974\ttest: 1.0299007\tbest: 1.0298947 (483)\ttotal: 40.9s\tremaining: 43.4s\n",
      "485:\tlearn: 1.1388419\ttest: 1.0299010\tbest: 1.0298947 (483)\ttotal: 41s\tremaining: 43.3s\n",
      "486:\tlearn: 1.1388253\ttest: 1.0298930\tbest: 1.0298930 (486)\ttotal: 41.1s\tremaining: 43.2s\n",
      "487:\tlearn: 1.1387857\ttest: 1.0298699\tbest: 1.0298699 (487)\ttotal: 41.1s\tremaining: 43.2s\n",
      "488:\tlearn: 1.1387593\ttest: 1.0298157\tbest: 1.0298157 (488)\ttotal: 41.2s\tremaining: 43.1s\n",
      "489:\tlearn: 1.1387126\ttest: 1.0297752\tbest: 1.0297752 (489)\ttotal: 41.3s\tremaining: 43s\n",
      "490:\tlearn: 1.1386960\ttest: 1.0297979\tbest: 1.0297752 (489)\ttotal: 41.4s\tremaining: 42.9s\n",
      "491:\tlearn: 1.1385746\ttest: 1.0297544\tbest: 1.0297544 (491)\ttotal: 41.5s\tremaining: 42.8s\n",
      "492:\tlearn: 1.1385194\ttest: 1.0297567\tbest: 1.0297544 (491)\ttotal: 41.6s\tremaining: 42.8s\n",
      "493:\tlearn: 1.1384983\ttest: 1.0297571\tbest: 1.0297544 (491)\ttotal: 41.7s\tremaining: 42.7s\n",
      "494:\tlearn: 1.1384632\ttest: 1.0297788\tbest: 1.0297544 (491)\ttotal: 41.7s\tremaining: 42.6s\n",
      "495:\tlearn: 1.1384341\ttest: 1.0297847\tbest: 1.0297544 (491)\ttotal: 41.8s\tremaining: 42.5s\n",
      "496:\tlearn: 1.1383814\ttest: 1.0298059\tbest: 1.0297544 (491)\ttotal: 41.9s\tremaining: 42.4s\n",
      "497:\tlearn: 1.1383479\ttest: 1.0295914\tbest: 1.0295914 (497)\ttotal: 42s\tremaining: 42.3s\n",
      "498:\tlearn: 1.1383312\ttest: 1.0296153\tbest: 1.0295914 (497)\ttotal: 42.1s\tremaining: 42.3s\n",
      "499:\tlearn: 1.1383133\ttest: 1.0296048\tbest: 1.0295914 (497)\ttotal: 42.2s\tremaining: 42.2s\n",
      "500:\tlearn: 1.1382167\ttest: 1.0295864\tbest: 1.0295864 (500)\ttotal: 42.2s\tremaining: 42.1s\n",
      "501:\tlearn: 1.1380935\ttest: 1.0295378\tbest: 1.0295378 (501)\ttotal: 42.3s\tremaining: 42s\n",
      "502:\tlearn: 1.1380743\ttest: 1.0295505\tbest: 1.0295378 (501)\ttotal: 42.4s\tremaining: 41.9s\n",
      "503:\tlearn: 1.1380436\ttest: 1.0295500\tbest: 1.0295378 (501)\ttotal: 42.5s\tremaining: 41.8s\n",
      "504:\tlearn: 1.1380004\ttest: 1.0295513\tbest: 1.0295378 (501)\ttotal: 42.5s\tremaining: 41.7s\n",
      "505:\tlearn: 1.1379797\ttest: 1.0296714\tbest: 1.0295378 (501)\ttotal: 42.6s\tremaining: 41.6s\n",
      "506:\tlearn: 1.1379412\ttest: 1.0296750\tbest: 1.0295378 (501)\ttotal: 42.7s\tremaining: 41.5s\n",
      "507:\tlearn: 1.1378875\ttest: 1.0296640\tbest: 1.0295378 (501)\ttotal: 42.8s\tremaining: 41.4s\n",
      "508:\tlearn: 1.1378552\ttest: 1.0296142\tbest: 1.0295378 (501)\ttotal: 42.9s\tremaining: 41.4s\n",
      "509:\tlearn: 1.1377630\ttest: 1.0295889\tbest: 1.0295378 (501)\ttotal: 43.1s\tremaining: 41.4s\n",
      "510:\tlearn: 1.1377370\ttest: 1.0296370\tbest: 1.0295378 (501)\ttotal: 43.2s\tremaining: 41.3s\n",
      "511:\tlearn: 1.1376392\ttest: 1.0296202\tbest: 1.0295378 (501)\ttotal: 43.2s\tremaining: 41.2s\n",
      "512:\tlearn: 1.1376195\ttest: 1.0296482\tbest: 1.0295378 (501)\ttotal: 43.3s\tremaining: 41.1s\n",
      "513:\tlearn: 1.1375885\ttest: 1.0296533\tbest: 1.0295378 (501)\ttotal: 43.4s\tremaining: 41s\n",
      "514:\tlearn: 1.1375462\ttest: 1.0296088\tbest: 1.0295378 (501)\ttotal: 43.5s\tremaining: 41s\n",
      "515:\tlearn: 1.1373538\ttest: 1.0295988\tbest: 1.0295378 (501)\ttotal: 43.6s\tremaining: 40.9s\n",
      "516:\tlearn: 1.1373172\ttest: 1.0295558\tbest: 1.0295378 (501)\ttotal: 43.7s\tremaining: 40.8s\n",
      "517:\tlearn: 1.1372487\ttest: 1.0295235\tbest: 1.0295235 (517)\ttotal: 43.8s\tremaining: 40.8s\n",
      "518:\tlearn: 1.1372287\ttest: 1.0294654\tbest: 1.0294654 (518)\ttotal: 43.9s\tremaining: 40.7s\n",
      "519:\tlearn: 1.1372105\ttest: 1.0294686\tbest: 1.0294654 (518)\ttotal: 44s\tremaining: 40.6s\n",
      "520:\tlearn: 1.1371829\ttest: 1.0294999\tbest: 1.0294654 (518)\ttotal: 44s\tremaining: 40.5s\n",
      "521:\tlearn: 1.1371602\ttest: 1.0294681\tbest: 1.0294654 (518)\ttotal: 44.1s\tremaining: 40.4s\n",
      "522:\tlearn: 1.1371408\ttest: 1.0294473\tbest: 1.0294473 (522)\ttotal: 44.2s\tremaining: 40.3s\n",
      "523:\tlearn: 1.1371006\ttest: 1.0294284\tbest: 1.0294284 (523)\ttotal: 44.3s\tremaining: 40.3s\n",
      "524:\tlearn: 1.1370722\ttest: 1.0294016\tbest: 1.0294016 (524)\ttotal: 44.4s\tremaining: 40.2s\n",
      "525:\tlearn: 1.1370270\ttest: 1.0294501\tbest: 1.0294016 (524)\ttotal: 44.5s\tremaining: 40.1s\n",
      "526:\tlearn: 1.1369937\ttest: 1.0294242\tbest: 1.0294016 (524)\ttotal: 44.6s\tremaining: 40s\n",
      "527:\tlearn: 1.1369578\ttest: 1.0294422\tbest: 1.0294016 (524)\ttotal: 44.7s\tremaining: 39.9s\n",
      "528:\tlearn: 1.1369293\ttest: 1.0294718\tbest: 1.0294016 (524)\ttotal: 44.8s\tremaining: 39.9s\n",
      "529:\tlearn: 1.1369161\ttest: 1.0294994\tbest: 1.0294016 (524)\ttotal: 44.8s\tremaining: 39.8s\n",
      "530:\tlearn: 1.1368030\ttest: 1.0295062\tbest: 1.0294016 (524)\ttotal: 44.9s\tremaining: 39.7s\n",
      "531:\tlearn: 1.1367711\ttest: 1.0294970\tbest: 1.0294016 (524)\ttotal: 45s\tremaining: 39.6s\n",
      "532:\tlearn: 1.1366949\ttest: 1.0294509\tbest: 1.0294016 (524)\ttotal: 45.1s\tremaining: 39.5s\n",
      "533:\tlearn: 1.1366651\ttest: 1.0294126\tbest: 1.0294016 (524)\ttotal: 45.2s\tremaining: 39.4s\n",
      "534:\tlearn: 1.1366400\ttest: 1.0294918\tbest: 1.0294016 (524)\ttotal: 45.2s\tremaining: 39.3s\n",
      "535:\tlearn: 1.1366151\ttest: 1.0294834\tbest: 1.0294016 (524)\ttotal: 45.3s\tremaining: 39.2s\n",
      "536:\tlearn: 1.1365838\ttest: 1.0294673\tbest: 1.0294016 (524)\ttotal: 45.4s\tremaining: 39.1s\n",
      "537:\tlearn: 1.1365276\ttest: 1.0294963\tbest: 1.0294016 (524)\ttotal: 45.5s\tremaining: 39s\n",
      "538:\tlearn: 1.1364993\ttest: 1.0294699\tbest: 1.0294016 (524)\ttotal: 45.5s\tremaining: 39s\n",
      "539:\tlearn: 1.1364792\ttest: 1.0294828\tbest: 1.0294016 (524)\ttotal: 45.6s\tremaining: 38.9s\n",
      "540:\tlearn: 1.1364549\ttest: 1.0295004\tbest: 1.0294016 (524)\ttotal: 45.7s\tremaining: 38.8s\n",
      "541:\tlearn: 1.1364276\ttest: 1.0294859\tbest: 1.0294016 (524)\ttotal: 45.8s\tremaining: 38.7s\n",
      "542:\tlearn: 1.1364065\ttest: 1.0294958\tbest: 1.0294016 (524)\ttotal: 45.9s\tremaining: 38.6s\n",
      "543:\tlearn: 1.1363903\ttest: 1.0294963\tbest: 1.0294016 (524)\ttotal: 46s\tremaining: 38.6s\n",
      "544:\tlearn: 1.1363751\ttest: 1.0295042\tbest: 1.0294016 (524)\ttotal: 46.1s\tremaining: 38.5s\n",
      "545:\tlearn: 1.1363002\ttest: 1.0294799\tbest: 1.0294016 (524)\ttotal: 46.2s\tremaining: 38.4s\n",
      "546:\tlearn: 1.1362733\ttest: 1.0295041\tbest: 1.0294016 (524)\ttotal: 46.3s\tremaining: 38.3s\n",
      "547:\tlearn: 1.1362442\ttest: 1.0295510\tbest: 1.0294016 (524)\ttotal: 46.4s\tremaining: 38.2s\n",
      "548:\tlearn: 1.1361905\ttest: 1.0295645\tbest: 1.0294016 (524)\ttotal: 46.4s\tremaining: 38.1s\n",
      "549:\tlearn: 1.1361700\ttest: 1.0295988\tbest: 1.0294016 (524)\ttotal: 46.5s\tremaining: 38.1s\n",
      "550:\tlearn: 1.1361409\ttest: 1.0295536\tbest: 1.0294016 (524)\ttotal: 46.6s\tremaining: 38s\n",
      "551:\tlearn: 1.1361028\ttest: 1.0295721\tbest: 1.0294016 (524)\ttotal: 46.7s\tremaining: 37.9s\n",
      "552:\tlearn: 1.1360971\ttest: 1.0295658\tbest: 1.0294016 (524)\ttotal: 46.8s\tremaining: 37.8s\n",
      "553:\tlearn: 1.1360512\ttest: 1.0296141\tbest: 1.0294016 (524)\ttotal: 46.8s\tremaining: 37.7s\n",
      "554:\tlearn: 1.1360270\ttest: 1.0295996\tbest: 1.0294016 (524)\ttotal: 46.9s\tremaining: 37.6s\n",
      "bestTest = 1.029401587\n",
      "bestIteration = 524\n",
      "Shrink model to first 525 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('shop_item_block_mean_lag_1', 23.380706715125925),\n",
       " ('item_block_mean_lag_1', 20.921305217958974),\n",
       " ('shop_item_block_mean_rolling_3', 9.807794253938711),\n",
       " ('shop_cat_block_mean_lag_1', 7.9618903386755795),\n",
       " ('item_block_mean_rolling_3', 7.795561500799492),\n",
       " ('item_category_id_mean_encoding', 6.424601943558458),\n",
       " ('item_category_id', 4.90508953283266),\n",
       " ('shop_share', 3.8512566375667836),\n",
       " ('shop_item_share_of_shop_units_mean', 3.8139328513966593),\n",
       " ('shop_cat_block_mean_rolling_3', 3.7108971879214594),\n",
       " ('shop_cat_block_median_rolling_3', 2.9219683251331574),\n",
       " ('shop_block_mean_lag_1', 2.7293899004699123),\n",
       " ('shop_block_mean_rolling_3', 1.775605594622237)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model = CatBoostRegressor(iterations=1000,\n",
    "                             #learning_rate=0.05,\n",
    "                             eval_metric='RMSE',\n",
    "                             task_type = \"GPU\",\n",
    "                             use_best_model=True,\n",
    "                             od_type = \"Iter\",\n",
    "                             od_wait = 30,\n",
    "                             bagging_temperature = 20,\n",
    "                             random_strength = 30,\n",
    "                             cat_features=[0],\n",
    "                             random_seed = 42)\n",
    "\n",
    "#drops = ['subcategory','area']\n",
    "#x_train = x_train.drop(columns=drops)\n",
    "#x_val = x_val.drop(columns=drops)\n",
    "\n",
    "\n",
    "cb_model.fit(x_train[features], y_train, #cat_features=categorical_features_indices,\n",
    "             eval_set=(x_val[features],y_val),\n",
    "             #cat_features=categorical_features_pos,         \n",
    "             verbose=True)\n",
    "\n",
    "scores = {}\n",
    "for i,score in enumerate(cb_model.get_feature_importance()):\n",
    "    scores[features[i]] = score\n",
    "\n",
    "sorted(scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [item[0] for item in scores.items() if item[1] > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test            = pd.read_csv('test.csv.gz')\n",
    "test = test.set_index('item_id').join(items.set_index('item_id'))\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = [ \n",
    "    'shop_item_share_of_shop_units_mean','item_id_mean_encoding'\n",
    "                ]\n",
    "\n",
    "merge_col = ['item_id']\n",
    "cols=item_features+merge_col\n",
    "\n",
    "test = test.merge(training.drop_duplicates('item_id')[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_features = [\n",
    "        'shop_id_mean_encoding','shop_share'\n",
    "]\n",
    "\n",
    "merge_col = ['shop_id']\n",
    "cols=shop_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "        'item_category_id_mean_encoding'#,'cat_me_real'\n",
    "]\n",
    "\n",
    "merge_col = ['item_category_id']\n",
    "cols=cat_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_item_features = [\n",
    "        'shop_item_share_of_shop_units_mean'#,'cat_me_real'\n",
    "]\n",
    "\n",
    "merge_col = ['shop_id','item_id']\n",
    "cols=shop_item_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_mean 3\n",
      "[['item_id', 'item_block_mean_rolling_3']]\n",
      "shop_block_mean 3\n",
      "[['shop_id', 'shop_block_mean_rolling_3']]\n",
      "shop_cat_block_mean 3\n",
      "[['shop_id', 'item_category_id', 'shop_cat_block_mean_rolling_3']]\n",
      "shop_cat_block_median 3\n",
      "[['shop_id', 'item_category_id', 'shop_cat_block_median_rolling_3']]\n"
     ]
    }
   ],
   "source": [
    "def add_rolls_test(df, cols, name, rolls = [3]):\n",
    "    for roll in rolls:\n",
    "        print(name, roll)\n",
    "        roll_name = name+\"_rolling_\" + str(roll)\n",
    "        roll_name_tmp = roll_name + \"_tmp\"\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[roll_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "    \n",
    "        block_units_rolling_temp = training\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].rolling(roll,min_periods=2).mean().reset_index()\\\n",
    "            .rename(columns={name:roll_name})\\\n",
    "            [cols+[roll_name]]\n",
    "        \n",
    "        print([cols[0:len(cols)-1]+[roll_name]])\n",
    "        thirty_three = block_units_rolling_temp[block_units_rolling_temp['date_block_num'] == 33].drop_duplicates(cols)\\\n",
    "                [cols[0:len(cols)-1]+[roll_name]]\n",
    "        df = df.merge(thirty_three, on=cols[0:len(cols)-1], how='left')\n",
    "    \n",
    "\n",
    "        del block_units_rolling_temp\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "test = add_rolls_test(test, ['item_id','date_block_num'], 'item_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 3\n",
      "[['shop_id', 'item_id', 'shop_item_block_mean_rolling_3']]\n"
     ]
    }
   ],
   "source": [
    "test = add_rolls_test(test, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_mean 1\n",
      "shop_block_mean 1\n",
      "shop_cat_block_mean 1\n"
     ]
    }
   ],
   "source": [
    "def add_lags_test(df, cols, name, lags = [1]):\n",
    "    \n",
    "    for lag in lags:\n",
    "        print(name, lag)\n",
    "        lag_name = name + \"_lag_\" + str(lag)\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[lag_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "        result = training\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].shift(lag)\\\n",
    "            .rename(columns={name:lag_name}).reset_index()\n",
    "        \n",
    "        thirty_three = result[result['date_block_num'] == 33].drop_duplicates(cols)\\\n",
    "                [cols[0:len(cols)-1] + [lag_name]]\n",
    "        df = df.merge(thirty_three, on=cols[0:len(cols)-1], how='left')\n",
    "\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "                                         \n",
    "\n",
    "                                        \n",
    "test = add_lags_test(test, ['item_id','date_block_num'], 'item_block_mean')\n",
    "test = add_lags_test(test, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "test = add_lags_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 1\n"
     ]
    }
   ],
   "source": [
    "test = add_lags_test(test, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(shop_id, cat_id):\n",
    "    if shop_id in shop_cat_models and cat_id in shop_cat_models[shop_id]:\n",
    "        return shop_cat_models[shop_id][cat_id].predict([[34]])[0][0]\n",
    "\n",
    "test['shop_cat_pred'] = test.apply(lambda row: predict(row['shop_id'],row['item_category_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(item_id):\n",
    "    if item_id in item_models:\n",
    "        return item_models[item_id].predict([[34]])[0][0]\n",
    "\n",
    "test['item_pred'] = test.apply(lambda row: predict(row['item_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10410043, 0.03894061, 0.26731994, ..., 0.14508408, 0.18311304,\n",
       "       0.14675301])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_preds = cb_model.predict(test[features])\n",
    "cb_preds.clip(0,20,out=cb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38870223108779917\n",
      "17.942064465265958\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cb_preds))\n",
    "print(np.max(cb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = cb_preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_me_real']= training.groupby('shop_id')['shop_me'].transform(np.mean)\n",
    "training['item_me_real']= training.groupby('item_id')['item_me'].transform(np.mean)\n",
    "training['cat_me_real']= training.groupby('item_category_id')['item_me'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.groupby('item_id')['shop_item_share_of_shop_units'].transform(np.mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
