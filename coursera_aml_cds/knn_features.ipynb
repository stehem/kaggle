{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.3\n",
      "pandas 0.23.4\n",
      "sklearn 0.19.2\n",
      "scipy 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "\n",
    "for p in [np, pd, sklearn, scipy]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'X.npz'\n",
    "train_labels = 'Y.npy'\n",
    "\n",
    "test_path = 'X_test.npz'\n",
    "test_labels = 'Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_seed = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-83393ad31170>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-83393ad31170>\"\u001b[0;36m, line \u001b[0;32m132\u001b[0m\n\u001b[0;31m    feats = # YOUR CODE GOES HERE\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction \n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set's up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            '''\n",
    "                 *Make it parallel*\n",
    "                     Number of threads should be controlled by `self.n_jobs`  \n",
    "                     \n",
    "                     \n",
    "                     You can use whatever you want to do it\n",
    "                     For Python 3 the simplest option would be to use \n",
    "                     `multiprocessing.Pool` (but don't use `multiprocessing.dummy.Pool` here)\n",
    "                     You may try use `joblib` but you will most likely encounter an error, \n",
    "                     that you will need to google up (and eventually it will work slowly)\n",
    "                     \n",
    "                     For Python 2 I also suggest using `multiprocessing.Pool` \n",
    "                     You will need to use a hint from this blog \n",
    "                     http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "                     I could not get `joblib` working at all for this code \n",
    "                     (but in general `joblib` is very convenient)\n",
    "                     \n",
    "            '''\n",
    "            \n",
    "            # YOUR CODE GOES HERE\n",
    "            # test_feats =  # YOUR CODE GOES HERE\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            assert False, 'You need to implement it for n_jobs > 1'\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.vstack(test_feats)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single object `x`\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of objects of every class.\n",
    "               It is basically a KNNÐ¡lassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label.\n",
    "               \n",
    "               What can help you: `np.where`\n",
    "        '''\n",
    "        \n",
    "        feats = # YOUR CODE GOES HERE\n",
    "        \n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            3. Minimum distance to objects of each class\n",
    "               Find the first instance of a class and take its distance as features.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "\n",
    "               `np.where` might be helpful\n",
    "        '''\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "        \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "        \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "               \n",
    "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "               should be scalars\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = # YOUR CODE GOES HERE\n",
    "            feat_52 = # YOUR CODE GOES HERE\n",
    "            \n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "                   For each class select the neighbors of that class among K nearest neighbors \n",
    "                   and compute the average distance to those objects\n",
    "                   \n",
    "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "                   \n",
    "               You can use `np.bincount` with appropriate weights\n",
    "               Don't forget, that if you divide by something, \n",
    "               You need to add `self.eps` to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            # YOUR CODE GOES IN HERE\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        \n",
    "        assert knn_feats.shape == (239,) or knn_feats.shape == (239, 1)\n",
    "        return knn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of K in KNN, starts with one \n",
    "k_list = [3, 8, 32]\n",
    "\n",
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('../readonly/KNN_features_data/knn_feats_test_first50.npy')\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X, Y)\n",
    "\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "\n",
    "# This should be zero\n",
    "print ('Deviation from ground thruth features: %f' % np.abs(test_knn_feats - true_knn_feats_first50).sum())\n",
    "\n",
    "deviation =np.abs(test_knn_feats - true_knn_feats_first50).sum(0)\n",
    "for m in np.where(deviation > 1e-3)[0]: \n",
    "    p = np.where(np.array([87, 88, 117, 146, 152, 239]) > m)[0][0]\n",
    "    print ('There is a problem in feature %d, which is a part of section %d.' % (m, p + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
