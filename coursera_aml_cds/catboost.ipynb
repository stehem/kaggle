{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an older notebook, it's a bit ugly in part but it achieved 1.02 and is half of the submission that passed the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "sales_train = sales_train[sales_train['year'] != 2013]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comes from kaggle, seems some shops are duplicated\n",
    "\n",
    "# Якутск Орджоникидзе, 56\n",
    "sales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "sales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "sales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#remove outliers\n",
    "ids_reject = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < 1000)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "#same as other notebooks\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "#add th target\n",
    "training['item_cnt_block'] = training['item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as other notebooks\n",
    "\n",
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "#same as other notebooks\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\", \"shop_cat\", \"shop_item\", \"date_block_num\"]\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\", \"month\",  \"date_block_num\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:946: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  'representation', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_block\n",
      "cat_block\n",
      "shop_cat_block\n",
      "shop_item_block\n"
     ]
    }
   ],
   "source": [
    "#this is the same as the other but uglier, was refactored in the more recent models, this basically creates the data\n",
    "#based on sales volume for each date block for various metrics shop/item etc....\n",
    "\n",
    "def add_block_units_stats(df, cols, name):\n",
    "    print(name)\n",
    "    name_units = name + '_units'\n",
    "    name_mean = name + '_mean'\n",
    "    name_median = name + '_median'\n",
    "    name_max = name + '_max'\n",
    "    name_min = name + '_min'\n",
    "    name_std = name + '_std'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        df.drop(columns=[name_units, name_mean, name_median],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    block_units = df.groupby(cols,as_index=False)['item_cnt_block'].sum()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_units})\n",
    "    df = df.merge(block_units, on=cols, how='left')\n",
    "    df[name_units].fillna(0,inplace=True)\n",
    "    df[name_units] = pd.to_numeric(df[name_units].astype(int),downcast='unsigned')\n",
    "    del block_units\n",
    "    \n",
    "    block_units_med = df.groupby(cols,as_index=False)['item_cnt_block'].median()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_median})\n",
    "    df = df.merge(block_units_med, on=cols, how='left')\n",
    "    df[name_median].fillna(0,inplace=True)\n",
    "    df[name_median] = pd.to_numeric(df[name_median].astype(int),downcast='unsigned')\n",
    "    del block_units_med\n",
    "    \n",
    "    block_means = df.groupby(cols,as_index=False)['item_cnt_block'].mean()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_mean})\n",
    "    df = df.merge(block_means, on=cols, how='left')\n",
    "    df[name_mean].fillna(0,inplace=True)\n",
    "    df[name_mean] = pd.to_numeric(df[name_mean],downcast='float')\n",
    "    del block_means\n",
    "    \n",
    "    block_max = df.groupby(cols,as_index=False)['item_cnt_block'].max()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_max})\n",
    "    df = df.merge(block_max, on=cols, how='left')\n",
    "    df[name_max].fillna(0,inplace=True)\n",
    "    df[name_max] = pd.to_numeric(df[name_max],downcast='float')\n",
    "    del block_max\n",
    "    \n",
    "    block_min = df.groupby(cols,as_index=False)['item_cnt_block'].min()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_min})\n",
    "    df = df.merge(block_min, on=cols, how='left')\n",
    "    df[name_min].fillna(0,inplace=True)\n",
    "    df[name_min] = pd.to_numeric(df[name_min],downcast='float')\n",
    "    del block_min\n",
    "    \n",
    "    block_std = df.groupby(cols,as_index=False)['item_cnt_block'].std()\\\n",
    "                        .drop_duplicates(cols)\\\n",
    "                        .rename(columns={'item_cnt_block':name_std})\n",
    "    df = df.merge(block_std, on=cols, how='left')\n",
    "    df[name_std].fillna(0,inplace=True)\n",
    "    df[name_std] = pd.to_numeric(df[name_std],downcast='float')\n",
    "    del block_std\n",
    "    \n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "training = add_block_units_stats(training, ['item_id','date_block_num'], 'item_block')\n",
    "training = add_block_units_stats(training, ['shop_id','date_block_num'], 'shop_block')\n",
    "training = add_block_units_stats(training, ['item_category_id','date_block_num'], 'cat_block')\n",
    "training = add_block_units_stats(training, ['shop_id', 'item_category_id','date_block_num'], 'shop_cat_block')\n",
    "training = add_block_units_stats(training, ['shop_id', 'item_id','date_block_num'], 'shop_item_block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_items: 17054\n",
      "number_of_categories: 79\n",
      "number_of_shops: 54\n",
      "number_of_days: 669\n",
      "number_of_blocks: 22\n",
      "total_sales: 2085473.0\n",
      "average_price: 1015.5023073772021\n"
     ]
    }
   ],
   "source": [
    "#some feature engineering, adds share data, time data, the names are self explanatory\n",
    "\n",
    "number_of_items = sales_train['item_id'].nunique()\n",
    "print(\"number_of_items:\", number_of_items)\n",
    "number_of_categories = sales_train['item_category_id'].nunique()\n",
    "print(\"number_of_categories:\", number_of_categories)\n",
    "number_of_shops = sales_train['shop_id'].nunique()\n",
    "print(\"number_of_shops:\", number_of_shops)\n",
    "number_of_days = 365 + 365 - 30 - 31\n",
    "print(\"number_of_days:\", number_of_days)\n",
    "number_of_blocks = sales_train['date_block_num'].nunique()\n",
    "print(\"number_of_blocks:\", number_of_blocks)\n",
    "total_sales = sales_train['item_cnt_day'].sum()\n",
    "print(\"total_sales:\", total_sales)\n",
    "average_price = sales_train['item_price'].mean()\n",
    "print(\"average_price:\", average_price)\n",
    "\n",
    "training['item_units'] = pd.to_numeric(training.groupby(['date_block_num'])['item_block_units'].transform(np.sum),downcast='unsigned')\n",
    "training['cat_units'] = pd.to_numeric(training.groupby(['date_block_num'])['cat_block_units'].transform(np.sum),downcast='unsigned')\n",
    "training['shop_units'] = pd.to_numeric(training.groupby(['date_block_num'])['shop_block_units'].transform(np.sum),downcast='unsigned')\n",
    "\n",
    "training['item_share_of_total_units'] = pd.to_numeric(training['item_units'] * 100 / total_sales,downcast='float')\n",
    "training['category_share_of_total_units'] = pd.to_numeric(training['cat_units'] * 100 / total_sales,downcast='float')\n",
    "training['shop_share_of_units'] = pd.to_numeric(training['shop_units'] * 100 / total_sales,downcast='float')\n",
    "training['shop_item_units'] = pd.to_numeric(training.groupby(['date_block_num'])\\\n",
    "                                            ['shop_item_block_units'].transform(np.sum),downcast='unsigned')\n",
    "\n",
    "training['shop_item_share_of_total_units'] = pd.to_numeric(training['shop_item_units'] * 100\\\n",
    "                        / total_sales,downcast='float')\n",
    "training['shop_item_share_of_shop_units'] = pd.to_numeric(training['shop_item_units'] * 100\\\n",
    "                        / training['shop_units'],downcast='float')\n",
    "\n",
    "\n",
    "training['item_share_of_shop_units'] = pd.to_numeric(training['shop_item_units'] * 100 / training['shop_units'],downcast='float')\n",
    "\n",
    "training['shop_item_share_of_shop_units_mean'] = training.groupby('item_id')['shop_item_share_of_shop_units'].transform(np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "shop\n",
      "cat\n",
      "shop_cat\n",
      "shop_item\n"
     ]
    }
   ],
   "source": [
    "#this adds some quantile based features, this led to overfitting\n",
    "\n",
    "def add_min_max_quantiles(df, cols, name):\n",
    "    print(name)\n",
    "\n",
    "    block_name = name+'_block_units'\n",
    "    units_name = name+'_units'\n",
    "    max_name = name+'_max_units_block'\n",
    "    min_name = name+'_min_units_block'\n",
    "    \n",
    "    try:\n",
    "        df.drop(columns=[units_name, max_name, min_name, min_max_name],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    df[units_name] = pd.to_numeric(df.groupby(['date_block_num'])[block_name].transform(np.sum), downcast='unsigned')\n",
    "    df[max_name] = pd.to_numeric(df.groupby(cols)[block_name].transform(np.max), downcast='unsigned')\n",
    "    df[min_name] = pd.to_numeric(df.groupby(cols)[block_name].transform(np.min), downcast='unsigned')\n",
    "    \n",
    "\n",
    "\n",
    "    for q in [0.25,0.50,0.75]:\n",
    "        qname = name+'_minmax_q' + str(q)\n",
    "        try:\n",
    "            df.drop(columns=[qname],inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        df[qname] =  pd.to_numeric(df[[min_name,max_name]].quantile(q,axis=1), downcast='unsigned')\n",
    "        \n",
    "    return df\n",
    "\n",
    "training = add_min_max_quantiles(training, ['item_id'], 'item')\n",
    "training = add_min_max_quantiles(training, ['shop_id'], 'shop')\n",
    "training = add_min_max_quantiles(training, ['item_category_id'], 'cat')\n",
    "training = add_min_max_quantiles(training, ['shop_id','item_category_id'], 'shop_cat')\n",
    "training = add_min_max_quantiles(training, ['shop_id','item_id'], 'shop_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_units 3\n",
      "item_block_mean 3\n",
      "item_block_median 3\n",
      "item_block_min 3\n",
      "item_block_max 3\n",
      "item_block_std 3\n",
      "shop_block_units 3\n",
      "shop_block_mean 3\n",
      "shop_block_median 3\n",
      "shop_block_min 3\n",
      "shop_block_max 3\n",
      "shop_block_std 3\n",
      "cat_block_units 3\n",
      "cat_block_mean 3\n",
      "cat_block_median 3\n",
      "cat_block_min 3\n",
      "cat_block_max 3\n",
      "cat_block_std 3\n",
      "shop_cat_block_units 3\n",
      "shop_cat_block_mean 3\n",
      "shop_cat_block_median 3\n",
      "shop_cat_block_min 3\n",
      "shop_cat_block_max 3\n",
      "shop_cat_block_std 3\n"
     ]
    }
   ],
   "source": [
    "#this adds rolling averages, the rolls argument is the size of the window so 3 for example means\n",
    "#rolling average for the 3 previous months, this worked well as an alternative to lags but is more\n",
    "#expensive/slower to compute, it's a convenience method around the panda .rolling() method\n",
    "\n",
    "def add_rolls(df, cols, name, rolls = [3]):\n",
    "    for roll in rolls:\n",
    "        print(name, roll)\n",
    "        roll_name = name+\"_rolling_\" + str(roll)\n",
    "        roll_name_tmp = roll_name + \"_tmp\"\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[roll_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "    \n",
    "        block_units_rolling_temp = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].rolling(roll,min_periods=2).mean().reset_index()\\\n",
    "            .rename(columns={name:roll_name_tmp})\\\n",
    "            [cols+[roll_name_tmp]]\n",
    "        \n",
    "    \n",
    "        df = df.merge(block_units_rolling_temp, on=cols, how='left')\n",
    "        #print(df.columns.values)\n",
    "        del block_units_rolling_temp\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "        block_units_rolling = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [roll_name_tmp].shift(1)\\\n",
    "            .rename(columns={roll_name_tmp:roll_name}).reset_index()\n",
    "\n",
    "        df = df.merge(block_units_rolling, on=cols, how='left')\n",
    "        df[roll_name].fillna(0,inplace=True)\n",
    "        df[roll_name] = pd.to_numeric(df[roll_name], downcast='float')\n",
    "        df.drop(columns=[roll_name_tmp], inplace=True)\n",
    "        del block_units_rolling\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_units')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_mean')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_median')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_min')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_max')\n",
    "training = add_rolls(training, ['item_id','date_block_num'], 'item_block_std')\n",
    "\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_units')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_median')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_min')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_max')\n",
    "training = add_rolls(training, ['shop_id','date_block_num'], 'shop_block_std')\n",
    "\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_units')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_mean')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_median')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_min')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_max')\n",
    "training = add_rolls(training, ['item_category_id','date_block_num'], 'cat_block_std')\n",
    "\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_units')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_min')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_max')\n",
    "training = add_rolls(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_std')\n",
    "#training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 3\n"
     ]
    }
   ],
   "source": [
    "training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = add_rolls(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n",
    "\n",
    "training['block_total'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.sum)\n",
    "\n",
    "training['item_share_block'] = training['item_block_units'] * 100 / training['block_total']\n",
    "training['shop_share_block'] = training['shop_block_units'] * 100 / training['block_total']\n",
    "training['comp2'] = training['item_share_block'] * training['shop_share_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_units 1\n",
      "item_block_mean 1\n",
      "item_block_median 1\n",
      "item_block_min 1\n",
      "item_block_max 1\n",
      "item_block_std 1\n",
      "shop_block_units 1\n",
      "shop_block_mean 1\n",
      "shop_block_median 1\n",
      "shop_block_min 1\n",
      "shop_block_max 1\n",
      "shop_block_std 1\n",
      "cat_block_units 1\n",
      "cat_block_mean 1\n",
      "cat_block_median 1\n",
      "cat_block_min 1\n",
      "cat_block_max 1\n",
      "cat_block_std 1\n",
      "shop_cat_block_units 1\n",
      "shop_cat_block_mean 1\n",
      "shop_cat_block_median 1\n",
      "shop_cat_block_min 1\n",
      "shop_cat_block_max 1\n",
      "shop_cat_block_std 1\n",
      "shop_item_block_units 1\n",
      "shop_item_block_mean 1\n",
      "shop_item_block_median 1\n",
      "shop_item_block_min 1\n",
      "shop_item_block_max 1\n",
      "shop_item_block_std 1\n"
     ]
    }
   ],
   "source": [
    "#same as other notebooks\n",
    "\n",
    "def add_lags(df, cols, name, lags = [1]):\n",
    "    \n",
    "    for lag in lags:\n",
    "        print(name, lag)\n",
    "        lag_name = name + \"_lag_\" + str(lag)\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[lag_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "        result = df\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].shift(lag)\\\n",
    "            .rename(columns={name:lag_name}).reset_index()\n",
    "\n",
    "        df = df.merge(result, on=cols, how='left')\n",
    "        df[lag_name].fillna(0,inplace=True)\n",
    "        if \"mean\" in name:\n",
    "            df[lag_name] = pd.to_numeric(df[lag_name], downcast='float')\n",
    "        else:\n",
    "            df[lag_name] = pd.to_numeric(df[lag_name].astype(int), downcast='unsigned')\n",
    "        del result\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "                                         \n",
    "\n",
    "                                        \n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_units')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_mean')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_median')                                        \n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_min')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_max')\n",
    "training = add_lags(training, ['item_id','date_block_num'], 'item_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_units')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_median')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_min')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_max')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_block_std')\n",
    "\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_units')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_mean')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_median')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_min')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_max')\n",
    "training = add_lags(training, ['item_category_id','date_block_num'], 'cat_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_units')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_min')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_max')\n",
    "training = add_lags(training, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_std')\n",
    "\n",
    "training = add_lags(training, ['shop_id','item_id','date_blocbk_num'], 'shop_item_block_units')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_median')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_min')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_max')\n",
    "training = add_lags(training, ['shop_id','item_id','date_block_num'], 'shop_item_block_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_share_block 1\n",
      "shop_share_block 1\n",
      "comp2 1\n"
     ]
    }
   ],
   "source": [
    "training = add_lags(training, ['item_id','date_block_num'], 'item_share_block')\n",
    "training = add_lags(training, ['shop_id','date_block_num'], 'shop_share_block')\n",
    "training = add_lags(training, ['shop_id', 'item_id', 'date_block_num'], 'comp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_shops = training.groupby('shop_id')['item_cnt_block'].sum().sum()\n",
    "training['shop_share'] = training.groupby('shop_id')['item_cnt_block'].transform(np.sum) *100 / total_sum_shops\n",
    "\n",
    "total_sum_items = training.groupby('item_id')['item_cnt_block'].sum().sum()\n",
    "training['item_share'] = training.groupby('item_id')['item_cnt_block'].transform(np.sum) *100 / total_sum_items\n",
    "\n",
    "training['comp1'] = training['shop_share'] * training['item_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_block_units_lag_comp1'] = pd.to_numeric(training['shop_block_units_lag_1'] * training['item_share_of_shop_units'],downcast='unsigned')\n",
    "\n",
    "#training['shop_share_item_units_comp'] = training['item_units'] * training['shop_share_of_units']\n",
    "training['item_block_units_lag_comp1'] = pd.to_numeric(training['item_block_units_lag_1'] * training['item_share_of_shop_units'],downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['blocks_without_sales'] = training['item_id'].map(training[training['item_cnt_block'] == 0].groupby(['item_id'])['date_block_num'].unique().apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some more feature engineering based on days since/between sales\n",
    "\n",
    "sales_train['item_days_of_activity'] = pd.to_numeric(sales_train.groupby(['item_id'])['date'].transform(\"nunique\"), downcast='unsigned') \n",
    "sales_train['item_blocks_of_activity'] = pd.to_numeric(sales_train.groupby(['item_id'])['date_block_num'].transform(\"nunique\"), downcast='unsigned') \n",
    "\n",
    "def get_number_of_days_since_start(day,month, year):\n",
    "    days = 0\n",
    "    if year == 2015:\n",
    "        days = 365\n",
    "    def is_even(num):\n",
    "        return num % 2 == 0\n",
    "    half_of_month = int(month/2)\n",
    "    even = (30*half_of_month) + (31*half_of_month)\n",
    "    if is_even(month):\n",
    "        days = days + even - 30 - day\n",
    "    else:\n",
    "        days = days + even + day\n",
    "    return days\n",
    "\n",
    "sales_train['item_days_since_start'] = pd.to_numeric(sales_train.apply(lambda row: get_number_of_days_since_start(row['day'],row['month'], row['year']),axis=1), downcast='unsigned') \n",
    "\n",
    "def get_average_days_between_sales(days):\n",
    "    days = sorted(np.unique(days))\n",
    "    if len(days) == 0:\n",
    "        return 9999\n",
    "    if len(days) == 1:\n",
    "        return 999\n",
    "    return np.mean(np.ediff1d(days)) / len(days)\n",
    "\n",
    "average_days_between_sales = sales_train.groupby(['item_id'])['item_days_since_start'].apply(list).apply(lambda x: get_average_days_between_sales(x))\n",
    "\n",
    "sales_train['item_mean_day_between_activity'] = pd.to_numeric(sales_train['item_id'].map(average_days_between_sales), downcast='unsigned')\n",
    "\n",
    "training['item_mean_day_between_activity'] = training['item_id'].map(sales_train.drop_duplicates('item_id').set_index('item_id')['item_mean_day_between_activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "      <th>month_mean_encoding</th>\n",
       "      <th>date_block_num_mean_encoding</th>\n",
       "      <th>item_block_units</th>\n",
       "      <th>item_block_mean</th>\n",
       "      <th>shop_block_units</th>\n",
       "      <th>shop_block_mean</th>\n",
       "      <th>cat_block_units</th>\n",
       "      <th>cat_block_mean</th>\n",
       "      <th>shop_cat_block_units</th>\n",
       "      <th>shop_cat_block_mean</th>\n",
       "      <th>shop_item_block_units</th>\n",
       "      <th>shop_item_block_mean</th>\n",
       "      <th>item_units</th>\n",
       "      <th>cat_units</th>\n",
       "      <th>shop_units</th>\n",
       "      <th>item_share_of_total_units</th>\n",
       "      <th>category_share_of_total_units</th>\n",
       "      <th>shop_share_of_units</th>\n",
       "      <th>shop_item_units</th>\n",
       "      <th>shop_item_share_of_total_units</th>\n",
       "      <th>shop_item_share_of_shop_units</th>\n",
       "      <th>item_share_of_shop_units</th>\n",
       "      <th>shop_item_share_of_shop_units_mean</th>\n",
       "      <th>item_max_units_block</th>\n",
       "      <th>item_min_units_block</th>\n",
       "      <th>item_minmax_q0.25</th>\n",
       "      <th>item_minmax_q0.5</th>\n",
       "      <th>item_minmax_q0.75</th>\n",
       "      <th>shop_max_units_block</th>\n",
       "      <th>shop_min_units_block</th>\n",
       "      <th>shop_minmax_q0.25</th>\n",
       "      <th>shop_minmax_q0.5</th>\n",
       "      <th>shop_minmax_q0.75</th>\n",
       "      <th>cat_max_units_block</th>\n",
       "      <th>cat_min_units_block</th>\n",
       "      <th>cat_minmax_q0.25</th>\n",
       "      <th>cat_minmax_q0.5</th>\n",
       "      <th>cat_minmax_q0.75</th>\n",
       "      <th>shop_cat_units</th>\n",
       "      <th>shop_cat_max_units_block</th>\n",
       "      <th>shop_cat_min_units_block</th>\n",
       "      <th>shop_cat_minmax_q0.25</th>\n",
       "      <th>shop_cat_minmax_q0.5</th>\n",
       "      <th>shop_cat_minmax_q0.75</th>\n",
       "      <th>shop_item_max_units_block</th>\n",
       "      <th>shop_item_min_units_block</th>\n",
       "      <th>shop_item_minmax_q0.25</th>\n",
       "      <th>shop_item_minmax_q0.5</th>\n",
       "      <th>shop_item_minmax_q0.75</th>\n",
       "      <th>item_block_units_rolling_3</th>\n",
       "      <th>item_block_mean_rolling_3</th>\n",
       "      <th>shop_block_units_rolling_3</th>\n",
       "      <th>shop_block_mean_rolling_3</th>\n",
       "      <th>cat_block_units_rolling_3</th>\n",
       "      <th>cat_block_mean_rolling_3</th>\n",
       "      <th>shop_cat_block_units_rolling_3</th>\n",
       "      <th>shop_cat_block_mean_rolling_3</th>\n",
       "      <th>shop_item_block_mean_rolling_3</th>\n",
       "      <th>item_block_units_lag_1</th>\n",
       "      <th>item_block_mean_lag_1</th>\n",
       "      <th>shop_block_units_lag_1</th>\n",
       "      <th>shop_block_mean_lag_1</th>\n",
       "      <th>cat_block_units_lag_1</th>\n",
       "      <th>cat_block_mean_lag_1</th>\n",
       "      <th>shop_cat_block_units_lag_1</th>\n",
       "      <th>shop_cat_block_mean_lag_1</th>\n",
       "      <th>shop_item_block_units_lag_1</th>\n",
       "      <th>shop_item_block_mean_lag_1</th>\n",
       "      <th>shop_block_units_lag_comp1</th>\n",
       "      <th>item_block_units_lag_comp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1738857</th>\n",
       "      <td>14627</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.293685</td>\n",
       "      <td>0.313755</td>\n",
       "      <td>0.405477</td>\n",
       "      <td>0.472121</td>\n",
       "      <td>9</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>413</td>\n",
       "      <td>0.242798</td>\n",
       "      <td>5821</td>\n",
       "      <td>0.327261</td>\n",
       "      <td>113</td>\n",
       "      <td>0.311295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1935990</td>\n",
       "      <td>218971298</td>\n",
       "      <td>67206510</td>\n",
       "      <td>92.832176</td>\n",
       "      <td>202.492828</td>\n",
       "      <td>1163.133545</td>\n",
       "      <td>39510</td>\n",
       "      <td>1.894534</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15.75</td>\n",
       "      <td>1356</td>\n",
       "      <td>413</td>\n",
       "      <td>648.75</td>\n",
       "      <td>884.5</td>\n",
       "      <td>1120.25</td>\n",
       "      <td>11613</td>\n",
       "      <td>4757</td>\n",
       "      <td>6471.00</td>\n",
       "      <td>8185.0</td>\n",
       "      <td>9899.00</td>\n",
       "      <td>4468802</td>\n",
       "      <td>252</td>\n",
       "      <td>88</td>\n",
       "      <td>129.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>211.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.200181</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>0.344254</td>\n",
       "      <td>5858.333496</td>\n",
       "      <td>0.360054</td>\n",
       "      <td>113.333336</td>\n",
       "      <td>0.324800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>602</td>\n",
       "      <td>0.371376</td>\n",
       "      <td>6710</td>\n",
       "      <td>0.388310</td>\n",
       "      <td>143</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.390945</td>\n",
       "      <td>0.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529662</th>\n",
       "      <td>21623</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136442</td>\n",
       "      <td>0.375315</td>\n",
       "      <td>0.224130</td>\n",
       "      <td>0.436372</td>\n",
       "      <td>0.374310</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>925</td>\n",
       "      <td>0.294680</td>\n",
       "      <td>508</td>\n",
       "      <td>0.137372</td>\n",
       "      <td>11</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2177047</td>\n",
       "      <td>378130476</td>\n",
       "      <td>158924431</td>\n",
       "      <td>104.391045</td>\n",
       "      <td>1655.887817</td>\n",
       "      <td>1442.138672</td>\n",
       "      <td>50629</td>\n",
       "      <td>2.427699</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.046519</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1823</td>\n",
       "      <td>536</td>\n",
       "      <td>857.75</td>\n",
       "      <td>1179.5</td>\n",
       "      <td>1501.25</td>\n",
       "      <td>1891</td>\n",
       "      <td>374</td>\n",
       "      <td>753.25</td>\n",
       "      <td>1132.5</td>\n",
       "      <td>1511.75</td>\n",
       "      <td>8793732</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>901.666687</td>\n",
       "      <td>0.303593</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>0.250158</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.106647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>933</td>\n",
       "      <td>0.306807</td>\n",
       "      <td>739</td>\n",
       "      <td>0.195296</td>\n",
       "      <td>9</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.722841</td>\n",
       "      <td>0.031857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098437</th>\n",
       "      <td>17448</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069091</td>\n",
       "      <td>0.167488</td>\n",
       "      <td>0.404183</td>\n",
       "      <td>0.513463</td>\n",
       "      <td>0.616950</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>399</td>\n",
       "      <td>0.253978</td>\n",
       "      <td>3834</td>\n",
       "      <td>0.490281</td>\n",
       "      <td>28</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2049254</td>\n",
       "      <td>175652748</td>\n",
       "      <td>69986479</td>\n",
       "      <td>98.263275</td>\n",
       "      <td>184.804901</td>\n",
       "      <td>1296.435181</td>\n",
       "      <td>44549</td>\n",
       "      <td>2.136158</td>\n",
       "      <td>0.063654</td>\n",
       "      <td>0.063654</td>\n",
       "      <td>0.058954</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>734</td>\n",
       "      <td>311</td>\n",
       "      <td>416.75</td>\n",
       "      <td>522.5</td>\n",
       "      <td>628.25</td>\n",
       "      <td>9071</td>\n",
       "      <td>3834</td>\n",
       "      <td>5143.25</td>\n",
       "      <td>6452.5</td>\n",
       "      <td>7761.75</td>\n",
       "      <td>3818538</td>\n",
       "      <td>68</td>\n",
       "      <td>21</td>\n",
       "      <td>32.75</td>\n",
       "      <td>44.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>323</td>\n",
       "      <td>0.211664</td>\n",
       "      <td>4900</td>\n",
       "      <td>0.700801</td>\n",
       "      <td>21</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.560152</td>\n",
       "      <td>0.381922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176476</th>\n",
       "      <td>1725</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.268486</td>\n",
       "      <td>0.314711</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.368951</td>\n",
       "      <td>33</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>636</td>\n",
       "      <td>0.209142</td>\n",
       "      <td>5793</td>\n",
       "      <td>0.246553</td>\n",
       "      <td>89</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2188736</td>\n",
       "      <td>371728324</td>\n",
       "      <td>151271504</td>\n",
       "      <td>104.951538</td>\n",
       "      <td>1348.899780</td>\n",
       "      <td>1075.175049</td>\n",
       "      <td>49744</td>\n",
       "      <td>2.385262</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>18.25</td>\n",
       "      <td>27.5</td>\n",
       "      <td>36.75</td>\n",
       "      <td>1106</td>\n",
       "      <td>539</td>\n",
       "      <td>680.75</td>\n",
       "      <td>822.5</td>\n",
       "      <td>964.25</td>\n",
       "      <td>11613</td>\n",
       "      <td>4757</td>\n",
       "      <td>6471.00</td>\n",
       "      <td>8185.0</td>\n",
       "      <td>9899.00</td>\n",
       "      <td>8448371</td>\n",
       "      <td>158</td>\n",
       "      <td>73</td>\n",
       "      <td>94.25</td>\n",
       "      <td>115.5</td>\n",
       "      <td>136.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>683.666687</td>\n",
       "      <td>0.238088</td>\n",
       "      <td>6997.000000</td>\n",
       "      <td>0.297533</td>\n",
       "      <td>113.666664</td>\n",
       "      <td>0.224893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>677</td>\n",
       "      <td>0.228331</td>\n",
       "      <td>6365</td>\n",
       "      <td>0.262962</td>\n",
       "      <td>122</td>\n",
       "      <td>0.236893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.262413</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583019</th>\n",
       "      <td>4679</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.327244</td>\n",
       "      <td>0.313755</td>\n",
       "      <td>0.405477</td>\n",
       "      <td>0.472121</td>\n",
       "      <td>15</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>587</td>\n",
       "      <td>0.345091</td>\n",
       "      <td>5821</td>\n",
       "      <td>0.327261</td>\n",
       "      <td>76</td>\n",
       "      <td>0.209366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1935990</td>\n",
       "      <td>218971298</td>\n",
       "      <td>67206510</td>\n",
       "      <td>92.832176</td>\n",
       "      <td>202.492828</td>\n",
       "      <td>1163.133545</td>\n",
       "      <td>39510</td>\n",
       "      <td>1.894534</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>12.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>24.25</td>\n",
       "      <td>1600</td>\n",
       "      <td>587</td>\n",
       "      <td>840.25</td>\n",
       "      <td>1093.5</td>\n",
       "      <td>1346.75</td>\n",
       "      <td>11613</td>\n",
       "      <td>4757</td>\n",
       "      <td>6471.00</td>\n",
       "      <td>8185.0</td>\n",
       "      <td>9899.00</td>\n",
       "      <td>4468802</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>93.75</td>\n",
       "      <td>123.5</td>\n",
       "      <td>153.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24.333334</td>\n",
       "      <td>0.521437</td>\n",
       "      <td>720.333313</td>\n",
       "      <td>0.457591</td>\n",
       "      <td>5858.333496</td>\n",
       "      <td>0.360054</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.260325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>789</td>\n",
       "      <td>0.486737</td>\n",
       "      <td>6710</td>\n",
       "      <td>0.388310</td>\n",
       "      <td>119</td>\n",
       "      <td>0.330556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.384480</td>\n",
       "      <td>1.469724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556786</th>\n",
       "      <td>4548</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>0.159367</td>\n",
       "      <td>0.958422</td>\n",
       "      <td>0.673090</td>\n",
       "      <td>0.412353</td>\n",
       "      <td>0.489785</td>\n",
       "      <td>14</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1978</td>\n",
       "      <td>1.026466</td>\n",
       "      <td>764</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2371450</td>\n",
       "      <td>309332150</td>\n",
       "      <td>91395683</td>\n",
       "      <td>113.712814</td>\n",
       "      <td>416.425415</td>\n",
       "      <td>263.553497</td>\n",
       "      <td>47429</td>\n",
       "      <td>2.274256</td>\n",
       "      <td>0.051894</td>\n",
       "      <td>0.051894</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5.75</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.25</td>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "      <td>1154.25</td>\n",
       "      <td>2308.5</td>\n",
       "      <td>3462.75</td>\n",
       "      <td>1382</td>\n",
       "      <td>539</td>\n",
       "      <td>749.75</td>\n",
       "      <td>960.5</td>\n",
       "      <td>1171.25</td>\n",
       "      <td>6186643</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>15.75</td>\n",
       "      <td>31.5</td>\n",
       "      <td>47.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>1871.333374</td>\n",
       "      <td>1.062448</td>\n",
       "      <td>796.666687</td>\n",
       "      <td>0.686693</td>\n",
       "      <td>24.666666</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>1992</td>\n",
       "      <td>1.090312</td>\n",
       "      <td>751</td>\n",
       "      <td>0.666371</td>\n",
       "      <td>26</td>\n",
       "      <td>1.130435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.373116</td>\n",
       "      <td>0.467047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029821</th>\n",
       "      <td>16556</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.484569</td>\n",
       "      <td>0.280191</td>\n",
       "      <td>0.400715</td>\n",
       "      <td>0.501584</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>2423</td>\n",
       "      <td>0.279019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3112980</td>\n",
       "      <td>382022004</td>\n",
       "      <td>137928960</td>\n",
       "      <td>149.269730</td>\n",
       "      <td>1842.489502</td>\n",
       "      <td>435.390015</td>\n",
       "      <td>59865</td>\n",
       "      <td>2.870572</td>\n",
       "      <td>0.043403</td>\n",
       "      <td>0.043403</td>\n",
       "      <td>0.042499</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>24.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>1851</td>\n",
       "      <td>1287</td>\n",
       "      <td>1428.00</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1710.00</td>\n",
       "      <td>3796</td>\n",
       "      <td>1376</td>\n",
       "      <td>1981.00</td>\n",
       "      <td>2586.0</td>\n",
       "      <td>3191.00</td>\n",
       "      <td>7346577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.158562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2232.333252</td>\n",
       "      <td>0.260857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2161</td>\n",
       "      <td>0.252749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016587</th>\n",
       "      <td>16362</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.220940</td>\n",
       "      <td>0.111541</td>\n",
       "      <td>0.458883</td>\n",
       "      <td>0.555135</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>615</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>590</td>\n",
       "      <td>0.137722</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2909805</td>\n",
       "      <td>378932448</td>\n",
       "      <td>114680550</td>\n",
       "      <td>139.527344</td>\n",
       "      <td>1694.342896</td>\n",
       "      <td>1380.080444</td>\n",
       "      <td>57055</td>\n",
       "      <td>2.735830</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.041890</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>933</td>\n",
       "      <td>343</td>\n",
       "      <td>490.50</td>\n",
       "      <td>638.0</td>\n",
       "      <td>785.50</td>\n",
       "      <td>656</td>\n",
       "      <td>302</td>\n",
       "      <td>390.50</td>\n",
       "      <td>479.0</td>\n",
       "      <td>567.50</td>\n",
       "      <td>7430048</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.114422</td>\n",
       "      <td>461.333344</td>\n",
       "      <td>0.251649</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>0.133915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>468</td>\n",
       "      <td>0.242865</td>\n",
       "      <td>539</td>\n",
       "      <td>0.126824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.283583</td>\n",
       "      <td>0.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582259</th>\n",
       "      <td>13315</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.921651</td>\n",
       "      <td>0.363464</td>\n",
       "      <td>0.460347</td>\n",
       "      <td>0.389230</td>\n",
       "      <td>2</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>3069</td>\n",
       "      <td>0.888021</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.324042</td>\n",
       "      <td>145</td>\n",
       "      <td>1.768293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2373336</td>\n",
       "      <td>435573768</td>\n",
       "      <td>195291648</td>\n",
       "      <td>113.803246</td>\n",
       "      <td>291.398560</td>\n",
       "      <td>1126.504883</td>\n",
       "      <td>56508</td>\n",
       "      <td>2.709601</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4116</td>\n",
       "      <td>1392</td>\n",
       "      <td>2073.00</td>\n",
       "      <td>2754.0</td>\n",
       "      <td>3435.00</td>\n",
       "      <td>3049</td>\n",
       "      <td>18</td>\n",
       "      <td>775.75</td>\n",
       "      <td>1533.5</td>\n",
       "      <td>2291.25</td>\n",
       "      <td>10370804</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>55.25</td>\n",
       "      <td>110.5</td>\n",
       "      <td>165.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2624.333252</td>\n",
       "      <td>0.829777</td>\n",
       "      <td>296.666656</td>\n",
       "      <td>0.213523</td>\n",
       "      <td>32.666668</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2702</td>\n",
       "      <td>0.815821</td>\n",
       "      <td>628</td>\n",
       "      <td>0.310737</td>\n",
       "      <td>84</td>\n",
       "      <td>1.787234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.182869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921952</th>\n",
       "      <td>16020</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>0.550777</td>\n",
       "      <td>0.413160</td>\n",
       "      <td>0.774960</td>\n",
       "      <td>0.413783</td>\n",
       "      <td>0.361932</td>\n",
       "      <td>18</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>1220</td>\n",
       "      <td>0.368357</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.594049</td>\n",
       "      <td>29</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2212522</td>\n",
       "      <td>407190478</td>\n",
       "      <td>170415648</td>\n",
       "      <td>106.092094</td>\n",
       "      <td>989.867615</td>\n",
       "      <td>1993.151123</td>\n",
       "      <td>51454</td>\n",
       "      <td>2.467258</td>\n",
       "      <td>0.030193</td>\n",
       "      <td>0.030193</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>26.25</td>\n",
       "      <td>43.5</td>\n",
       "      <td>60.75</td>\n",
       "      <td>1979</td>\n",
       "      <td>597</td>\n",
       "      <td>942.50</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>1633.50</td>\n",
       "      <td>3557</td>\n",
       "      <td>882</td>\n",
       "      <td>1550.75</td>\n",
       "      <td>2219.5</td>\n",
       "      <td>2888.25</td>\n",
       "      <td>9469546</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>18.50</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.382281</td>\n",
       "      <td>1001.666687</td>\n",
       "      <td>0.328369</td>\n",
       "      <td>1540.666626</td>\n",
       "      <td>0.541828</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>1048</td>\n",
       "      <td>0.333864</td>\n",
       "      <td>1797</td>\n",
       "      <td>0.614569</td>\n",
       "      <td>36</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.642513</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  item_cnt_block  item_category_id  month  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding  month_mean_encoding  date_block_num_mean_encoding  item_block_units  item_block_mean  shop_block_units  shop_block_mean  cat_block_units  cat_block_mean  shop_cat_block_units  shop_cat_block_mean  shop_item_block_units  shop_item_block_mean  item_units  cat_units  shop_units  item_share_of_total_units  category_share_of_total_units  shop_share_of_units  shop_item_units  shop_item_share_of_total_units  shop_item_share_of_shop_units  item_share_of_shop_units  shop_item_share_of_shop_units_mean  item_max_units_block  item_min_units_block  item_minmax_q0.25  item_minmax_q0.5  item_minmax_q0.75  shop_max_units_block  shop_min_units_block  shop_minmax_q0.25  shop_minmax_q0.5  shop_minmax_q0.75  cat_max_units_block  cat_min_units_block  cat_minmax_q0.25  cat_minmax_q0.5  cat_minmax_q0.75  shop_cat_units  shop_cat_max_units_block  shop_cat_min_units_block  shop_cat_minmax_q0.25  shop_cat_minmax_q0.5  shop_cat_minmax_q0.75  shop_item_max_units_block  shop_item_min_units_block  shop_item_minmax_q0.25  shop_item_minmax_q0.5  shop_item_minmax_q0.75  item_block_units_rolling_3  item_block_mean_rolling_3  shop_block_units_rolling_3  shop_block_mean_rolling_3  cat_block_units_rolling_3  cat_block_mean_rolling_3  shop_cat_block_units_rolling_3  shop_cat_block_mean_rolling_3  shop_item_block_mean_rolling_3  item_block_units_lag_1  item_block_mean_lag_1  shop_block_units_lag_1  shop_block_mean_lag_1  cat_block_units_lag_1  cat_block_mean_lag_1  shop_cat_block_units_lag_1  shop_cat_block_mean_lag_1  shop_item_block_units_lag_1  shop_item_block_mean_lag_1  shop_block_units_lag_comp1  item_block_units_lag_comp1\n",
       "1738857  14627    37       15              1               55                4      0.192308               0.293685               0.313755                        0.405477             0.472121                      9                 0.183673         413               0.242798         5821             0.327261        113                   0.311295             1                      1                     1935990     218971298  67206510    92.832176                  202.492828                     1163.133545          39510            1.894534                        0.058789                       0.058789                  0.043519                            20                    3                     7.25               11.5              15.75              1356                  413                   648.75             884.5             1120.25            11613                4757                 6471.00           8185.0           9899.00           4468802         252                       88                        129.00                 170.0                 211.00                 1                          0                          0.25                    0.5                    0.75                    9.333333                    0.200181                   542.000000                  0.344254                   5858.333496                0.360054                  113.333336                      0.324800                       0.0                             9                       0.187500               602                     0.371376               6710                   0.388310              143                         0.397222                   0                            0.0                         35.390945                   0.529101                  \n",
       "2529662  21623    16       29              0               38                6      0.136442               0.375315               0.224130                        0.436372             0.374310                      1                 0.023256         925               0.294680         508              0.137372        11                    0.127907             0                      0                     2177047     378130476  158924431   104.391045                 1655.887817                    1442.138672          50629            2.427699                        0.031857                       0.031857                  0.046519                            29                    1                     8.00               15.0              22.00              1823                  536                   857.75             1179.5            1501.25            1891                 374                  753.25            1132.5           1511.75           8793732         23                        1                         6.50                   12.0                  17.50                  1                          0                          0.25                    0.5                    0.75                    1.000000                    0.021760                   901.666687                  0.303593                   963.000000                 0.250158                  9.000000                        0.106647                       0.0                             1                       0.022727               933                     0.306807               739                    0.195296              9                           0.104651                   0                            0.0                         29.722841                   0.031857                  \n",
       "2098437  17448    11       13              1               40                2      0.069091               0.167488               0.404183                        0.513463             0.616950                      2                 0.043478         399               0.253978         3834             0.490281        28                    0.164706             1                      1                     2049254     175652748  69986479    98.263275                  184.804901                     1296.435181          44549            2.136158                        0.063654                       0.063654                  0.058954                            6                     2                     3.00               4.0               5.00               734                   311                   416.75             522.5             628.25             9071                 3834                 5143.25           6452.5           7761.75           3818538         68                        21                        32.75                  44.5                  56.25                  1                          0                          0.25                    0.5                    0.75                    0.000000                    0.000000                   0.000000                    0.000000                   0.000000                   0.000000                  0.000000                        0.000000                       0.0                             6                       0.130435               323                     0.211664               4900                   0.700801              21                          0.138158                   0                            0.0                         20.560152                   0.381922                  \n",
       "176476   1725     44       28              2               55                5      0.539216               0.268486               0.314711                        0.426522             0.368951                      33                0.750000         636               0.209142         5793             0.246553        89                    0.166667             2                      2                     2188736     371728324  151271504   104.951538                 1348.899780                    1075.175049          49744            2.385262                        0.032884                       0.032884                  0.029407                            46                    9                     18.25              27.5              36.75              1106                  539                   680.75             822.5             964.25             11613                4757                 6471.00           8185.0           9899.00           8448371         158                       73                        94.25                  115.5                 136.75                 2                          0                          0.50                    1.0                    1.50                    0.000000                    0.000000                   683.666687                  0.238088                   6997.000000                0.297533                  113.666664                      0.224893                       0.0                             0                       0.000000               677                     0.228331               6365                   0.262962              122                         0.236893                   0                            0.0                         22.262413                   0.000000                  \n",
       "583019   4679     52       15              0               55                4      0.318996               0.327244               0.313755                        0.405477             0.472121                      15                0.306122         587               0.345091         5821             0.327261        76                    0.209366             0                      0                     1935990     218971298  67206510    92.832176                  202.492828                     1163.133545          39510            1.894534                        0.058789                       0.058789                  0.043519                            30                    7                     12.75              18.5              24.25              1600                  587                   840.25             1093.5            1346.75            11613                4757                 6471.00           8185.0           9899.00           4468802         183                       64                        93.75                  123.5                 153.25                 1                          0                          0.25                    0.5                    0.75                    24.333334                   0.521437                   720.333313                  0.457591                   5858.333496                0.360054                  91.000000                       0.260325                       0.0                             25                      0.520833               789                     0.486737               6710                   0.388310              119                         0.330556                   0                            0.0                         46.384480                   1.469724                  \n",
       "556786   4548     27       18              0               75                7      0.159367               0.958422               0.673090                        0.412353             0.489785                      14                0.280000         1978              1.026466         764              0.611200        24                    0.960000             0                      0                     2371450     309332150  91395683    113.712814                 416.425415                     263.553497           47429            2.274256                        0.051894                       0.051894                  0.043519                            14                    3                     5.75               8.5               11.25              4617                  0                     1154.25            2308.5            3462.75            1382                 539                  749.75            960.5            1171.25           6186643         63                        0                         15.75                  31.5                  47.25                  2                          0                          0.50                    1.0                    1.50                    8.666667                    0.176871                   1871.333374                 1.062448                   796.666687                 0.686693                  24.666666                       1.043478                       0.0                             9                       0.183673               1992                    1.090312               751                    0.666371              26                          1.130435                   0                            0.0                         103.373116                  0.467047                  \n",
       "2029821  16556    20       21              0               37                10     0.267677               0.484569               0.280191                        0.400715             0.501584                      2                 0.038462         1287              0.558594         2423             0.279019        0                     0.000000             0                      0                     3112980     382022004  137928960   149.269730                 1842.489502                    435.390015           59865            2.870572                        0.043403                       0.043403                  0.042499                            90                    2                     24.00              46.0              68.00              1851                  1287                  1428.00            1569.0            1710.00            3796                 1376                 1981.00           2586.0           3191.00           7346577         0                         0                         0.00                   0.0                   0.00                   0                          0                          0.00                    0.0                    0.00                    8.000000                    0.158562                   0.000000                    0.000000                   2232.333252                0.260857                  0.000000                        0.000000                       0.0                             4                       0.080000               0                       0.000000               2161                   0.252749              0                           0.000000                   0                            0.0                         0.000000                    0.173611                  \n",
       "2016587  16362    3        19              0               57                8      0.093575               0.220940               0.111541                        0.458883             0.555135                      6                 0.117647         615               0.305970         590              0.137722        0                     0.000000             0                      0                     2909805     378932448  114680550   139.527344                 1694.342896                    1380.080444          57055            2.735830                        0.049751                       0.049751                  0.041890                            9                     1                     3.00               5.0               7.00               933                   343                   490.50             638.0             785.50             656                  302                  390.50            479.0            567.50            7430048         3                         0                         0.75                   1.5                   2.25                   0                          0                          0.00                    0.0                    0.00                    5.666667                    0.114422                   461.333344                  0.251649                   541.000000                 0.133915                  0.000000                        0.000000                       0.0                             9                       0.180000               468                     0.242865               539                    0.126824              0                           0.000000                   0                            0.0                         23.283583                   0.447761                  \n",
       "1582259  13315    42       31              1               47                8      0.049020               0.921651               0.363464                        0.460347             0.389230                      2                 0.047619         3069              0.888021         1116             0.324042        145                   1.768293             1                      1                     2373336     435573768  195291648   113.803246                 291.398560                     1126.504883          56508            2.709601                        0.028935                       0.028935                  0.027142                            6                     1                     2.25               3.5               4.75               4116                  1392                  2073.00            2754.0            3435.00            3049                 18                   775.75            1533.5           2291.25           10370804        221                       0                         55.25                  110.5                 165.75                 1                          0                          0.25                    0.5                    0.75                    0.000000                    0.000000                   2624.333252                 0.829777                   296.666656                 0.213523                  32.666668                       0.855807                       0.0                             0                       0.000000               2702                    0.815821               628                    0.310737              84                          1.787234                   0                            0.0                         78.182869                   0.000000                  \n",
       "1921952  16020    38       30              0               65                7      0.550777               0.413160               0.774960                        0.413783             0.361932                      18                0.418605         1220              0.368357         1737             0.594049        29                    0.426471             0                      0                     2212522     407190478  170415648   106.092094                 989.867615                     1993.151123          51454            2.467258                        0.030193                       0.030193                  0.043519                            78                    9                     26.25              43.5              60.75              1979                  597                   942.50             1288.0            1633.50            3557                 882                  1550.75           2219.5           2888.25           9469546         56                        6                         18.50                  31.0                  43.50                  2                          0                          0.50                    1.0                    1.50                    17.000000                   0.382281                   1001.666687                 0.328369                   1540.666626                0.541828                  32.000000                       0.498428                       0.0                             18                      0.418605               1048                    0.333864               1797                   0.614569              36                          0.529412                   0                            0.0                         31.642513                   0.543478                  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'item_cnt_block',\n",
       "       'item_category_id', 'month', 'item_id_mean_encoding',\n",
       "       'shop_id_mean_encoding', 'item_category_id_mean_encoding',\n",
       "       'month_mean_encoding', 'date_block_num_mean_encoding',\n",
       "       'item_block_units', 'item_block_median', 'item_block_mean',\n",
       "       'item_block_max', 'item_block_min', 'item_block_std',\n",
       "       'shop_block_units', 'shop_block_median', 'shop_block_mean',\n",
       "       'shop_block_max', 'shop_block_min', 'shop_block_std',\n",
       "       'cat_block_units', 'cat_block_median', 'cat_block_mean',\n",
       "       'cat_block_max', 'cat_block_min', 'cat_block_std',\n",
       "       'shop_cat_block_units', 'shop_cat_block_median',\n",
       "       'shop_cat_block_mean', 'shop_cat_block_max', 'shop_cat_block_min',\n",
       "       'shop_cat_block_std', 'shop_item_block_units',\n",
       "       'shop_item_block_median', 'shop_item_block_mean',\n",
       "       'shop_item_block_max', 'shop_item_block_min',\n",
       "       'shop_item_block_std', 'item_units', 'cat_units', 'shop_units',\n",
       "       'item_share_of_total_units', 'category_share_of_total_units',\n",
       "       'shop_share_of_units', 'shop_item_units',\n",
       "       'shop_item_share_of_total_units', 'shop_item_share_of_shop_units',\n",
       "       'item_share_of_shop_units', 'shop_item_share_of_shop_units_mean',\n",
       "       'item_max_units_block', 'item_min_units_block',\n",
       "       'item_minmax_q0.25', 'item_minmax_q0.5', 'item_minmax_q0.75',\n",
       "       'shop_max_units_block', 'shop_min_units_block',\n",
       "       'shop_minmax_q0.25', 'shop_minmax_q0.5', 'shop_minmax_q0.75',\n",
       "       'cat_max_units_block', 'cat_min_units_block', 'cat_minmax_q0.25',\n",
       "       'cat_minmax_q0.5', 'cat_minmax_q0.75', 'shop_cat_units',\n",
       "       'shop_cat_max_units_block', 'shop_cat_min_units_block',\n",
       "       'shop_cat_minmax_q0.25', 'shop_cat_minmax_q0.5',\n",
       "       'shop_cat_minmax_q0.75', 'shop_item_max_units_block',\n",
       "       'shop_item_min_units_block', 'shop_item_minmax_q0.25',\n",
       "       'shop_item_minmax_q0.5', 'shop_item_minmax_q0.75',\n",
       "       'item_block_units_rolling_3', 'item_block_mean_rolling_3',\n",
       "       'item_block_median_rolling_3', 'item_block_min_rolling_3',\n",
       "       'item_block_max_rolling_3', 'item_block_std_rolling_3',\n",
       "       'shop_block_units_rolling_3', 'shop_block_mean_rolling_3',\n",
       "       'shop_block_median_rolling_3', 'shop_block_min_rolling_3',\n",
       "       'shop_block_max_rolling_3', 'shop_block_std_rolling_3',\n",
       "       'cat_block_units_rolling_3', 'cat_block_mean_rolling_3',\n",
       "       'cat_block_median_rolling_3', 'cat_block_min_rolling_3',\n",
       "       'cat_block_max_rolling_3', 'cat_block_std_rolling_3',\n",
       "       'shop_cat_block_units_rolling_3', 'shop_cat_block_mean_rolling_3',\n",
       "       'shop_cat_block_median_rolling_3', 'shop_cat_block_min_rolling_3',\n",
       "       'shop_cat_block_max_rolling_3', 'shop_cat_block_std_rolling_3',\n",
       "       'block_total', 'item_share_block', 'shop_share_block', 'comp2',\n",
       "       'item_block_units_lag_1', 'item_block_mean_lag_1',\n",
       "       'item_block_median_lag_1', 'item_block_min_lag_1',\n",
       "       'item_block_max_lag_1', 'item_block_std_lag_1',\n",
       "       'shop_block_units_lag_1', 'shop_block_mean_lag_1',\n",
       "       'shop_block_median_lag_1', 'shop_block_min_lag_1',\n",
       "       'shop_block_max_lag_1', 'shop_block_std_lag_1',\n",
       "       'cat_block_units_lag_1', 'cat_block_mean_lag_1',\n",
       "       'cat_block_median_lag_1', 'cat_block_min_lag_1',\n",
       "       'cat_block_max_lag_1', 'cat_block_std_lag_1',\n",
       "       'shop_cat_block_units_lag_1', 'shop_cat_block_mean_lag_1',\n",
       "       'shop_cat_block_median_lag_1', 'shop_cat_block_min_lag_1',\n",
       "       'shop_cat_block_max_lag_1', 'shop_cat_block_std_lag_1',\n",
       "       'shop_item_block_units_lag_1', 'shop_item_block_mean_lag_1',\n",
       "       'shop_item_block_median_lag_1', 'shop_item_block_min_lag_1',\n",
       "       'shop_item_block_max_lag_1', 'shop_item_block_std_lag_1',\n",
       "       'item_share_block_lag_1', 'shop_share_block_lag_1', 'comp2_lag_1',\n",
       "       'shop_share', 'item_share', 'comp1', 'shop_block_units_lag_comp1',\n",
       "       'item_block_units_lag_comp1', 'blocks_without_sales'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_val_len 29202\n",
      "zeros_keep_indices_val 146010\n",
      "non_zeros_val_indices 29202\n"
     ]
    }
   ],
   "source": [
    "#here is used 20% of target=0 in the validation set, trying to get reliable score compared to submissions\n",
    "#was a huge problem for me\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ZEROS_KEEP=0.2\n",
    "\n",
    "\n",
    "#x_train = training[(training['date_block_num'] < 33) & (training['val_ignore'] == False)]\n",
    "x_train = training[(training['date_block_num'] < 33)]\n",
    "y_train = x_train['item_cnt_block']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_val = training[training['date_block_num'] == 33]\n",
    "y_val = x_val['item_cnt_block']\n",
    "\n",
    "pos_val_len = len(y_val[y_val != 0])\n",
    "print(\"pos_val_len\", pos_val_len)\n",
    "\n",
    "zeros_keep_indices_val = y_val[y_val == 0].sample(int(pos_val_len/ZEROS_KEEP)).index\n",
    "print(\"zeros_keep_indices_val\", len(zeros_keep_indices_val))\n",
    "non_zeros_val_indices = y_val[y_val != 0].index\n",
    "print(\"non_zeros_val_indices\", len(non_zeros_val_indices))\n",
    "\n",
    "val_indices = np.append(np.array(zeros_keep_indices_val), np.array(non_zeros_val_indices))\n",
    "\n",
    "y_val = y_val.loc[val_indices]\n",
    "x_val = x_val.loc[val_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#those are the features i kept in the end, purely manual selection\n",
    "\n",
    "features = [\n",
    "    \n",
    "    \n",
    "        'item_category_id',\n",
    "       'item_block_mean_rolling_3',\n",
    "\n",
    "       'shop_block_mean_rolling_3',\n",
    "\n",
    "           'shop_cat_block_mean_rolling_3',\n",
    "               'shop_cat_block_median_rolling_3',\n",
    "\n",
    "      'item_block_mean_lag_1',\n",
    "\n",
    "        'shop_block_mean_lag_1',\n",
    "\n",
    "            'shop_cat_block_mean_lag_1',\n",
    "               # 'shop_cat_block_median_lag_1',\n",
    "\n",
    "\n",
    "    \n",
    "    'shop_item_share_of_shop_units_mean',\n",
    "    'shop_item_block_mean_rolling_3',\n",
    "\n",
    "    'shop_item_block_mean_lag_1',\n",
    "\n",
    "    \n",
    "#'item_id_mean_encoding',\n",
    "       #'shop_id_mean_encoding',\n",
    "    'item_category_id_mean_encoding',  \n",
    "    #'month_mean_encoding', 'date_block_num_mean_encoding'\n",
    "    \n",
    "    'shop_share',\n",
    "    \n",
    "    #'item_mean_day_between_activity',\n",
    "    #'comp1'\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.6489130\ttest: 1.3261997\tbest: 1.3261997 (0)\ttotal: 131ms\tremaining: 2m 11s\n",
      "1:\tlearn: 1.6375571\ttest: 1.3175854\tbest: 1.3175854 (1)\ttotal: 216ms\tremaining: 1m 47s\n",
      "2:\tlearn: 1.6265668\ttest: 1.3099784\tbest: 1.3099784 (2)\ttotal: 294ms\tremaining: 1m 37s\n",
      "3:\tlearn: 1.6102403\ttest: 1.3003902\tbest: 1.3003902 (3)\ttotal: 375ms\tremaining: 1m 33s\n",
      "4:\tlearn: 1.5965000\ttest: 1.2912593\tbest: 1.2912593 (4)\ttotal: 449ms\tremaining: 1m 29s\n",
      "5:\tlearn: 1.5835007\ttest: 1.2831532\tbest: 1.2831532 (5)\ttotal: 541ms\tremaining: 1m 29s\n",
      "6:\tlearn: 1.5708705\ttest: 1.2755199\tbest: 1.2755199 (6)\ttotal: 633ms\tremaining: 1m 29s\n",
      "7:\tlearn: 1.5579296\ttest: 1.2679141\tbest: 1.2679141 (7)\ttotal: 707ms\tremaining: 1m 27s\n",
      "8:\tlearn: 1.5428586\ttest: 1.2588765\tbest: 1.2588765 (8)\ttotal: 789ms\tremaining: 1m 26s\n",
      "9:\tlearn: 1.5295129\ttest: 1.2508406\tbest: 1.2508406 (9)\ttotal: 867ms\tremaining: 1m 25s\n",
      "10:\tlearn: 1.5206710\ttest: 1.2463574\tbest: 1.2463574 (10)\ttotal: 945ms\tremaining: 1m 24s\n",
      "11:\tlearn: 1.5093999\ttest: 1.2379170\tbest: 1.2379170 (11)\ttotal: 1.03s\tremaining: 1m 24s\n",
      "12:\tlearn: 1.5003018\ttest: 1.2324103\tbest: 1.2324103 (12)\ttotal: 1.12s\tremaining: 1m 25s\n",
      "13:\tlearn: 1.4882741\ttest: 1.2247569\tbest: 1.2247569 (13)\ttotal: 1.19s\tremaining: 1m 23s\n",
      "14:\tlearn: 1.4800638\ttest: 1.2191699\tbest: 1.2191699 (14)\ttotal: 1.28s\tremaining: 1m 23s\n",
      "15:\tlearn: 1.4723955\ttest: 1.2145849\tbest: 1.2145849 (15)\ttotal: 1.37s\tremaining: 1m 24s\n",
      "16:\tlearn: 1.4662205\ttest: 1.2107835\tbest: 1.2107835 (16)\ttotal: 1.45s\tremaining: 1m 23s\n",
      "17:\tlearn: 1.4560229\ttest: 1.2043950\tbest: 1.2043950 (17)\ttotal: 1.52s\tremaining: 1m 23s\n",
      "18:\tlearn: 1.4450700\ttest: 1.1980355\tbest: 1.1980355 (18)\ttotal: 1.6s\tremaining: 1m 22s\n",
      "19:\tlearn: 1.4369251\ttest: 1.1933977\tbest: 1.1933977 (19)\ttotal: 1.68s\tremaining: 1m 22s\n",
      "20:\tlearn: 1.4271470\ttest: 1.1874620\tbest: 1.1874620 (20)\ttotal: 1.76s\tremaining: 1m 21s\n",
      "21:\tlearn: 1.4182127\ttest: 1.1822391\tbest: 1.1822391 (21)\ttotal: 1.84s\tremaining: 1m 21s\n",
      "22:\tlearn: 1.4106016\ttest: 1.1779283\tbest: 1.1779283 (22)\ttotal: 1.93s\tremaining: 1m 21s\n",
      "23:\tlearn: 1.4059109\ttest: 1.1747520\tbest: 1.1747520 (23)\ttotal: 2.04s\tremaining: 1m 23s\n",
      "24:\tlearn: 1.4009945\ttest: 1.1716236\tbest: 1.1716236 (24)\ttotal: 2.23s\tremaining: 1m 27s\n",
      "25:\tlearn: 1.3924623\ttest: 1.1668488\tbest: 1.1668488 (25)\ttotal: 2.31s\tremaining: 1m 26s\n",
      "26:\tlearn: 1.3852122\ttest: 1.1625279\tbest: 1.1625279 (26)\ttotal: 2.4s\tremaining: 1m 26s\n",
      "27:\tlearn: 1.3791861\ttest: 1.1590683\tbest: 1.1590683 (27)\ttotal: 2.47s\tremaining: 1m 25s\n",
      "28:\tlearn: 1.3749988\ttest: 1.1567510\tbest: 1.1567510 (28)\ttotal: 2.56s\tremaining: 1m 25s\n",
      "29:\tlearn: 1.3695251\ttest: 1.1540512\tbest: 1.1540512 (29)\ttotal: 2.63s\tremaining: 1m 25s\n",
      "30:\tlearn: 1.3656750\ttest: 1.1516921\tbest: 1.1516921 (30)\ttotal: 2.72s\tremaining: 1m 25s\n",
      "31:\tlearn: 1.3605195\ttest: 1.1485034\tbest: 1.1485034 (31)\ttotal: 2.89s\tremaining: 1m 27s\n",
      "32:\tlearn: 1.3547049\ttest: 1.1456047\tbest: 1.1456047 (32)\ttotal: 2.99s\tremaining: 1m 27s\n",
      "33:\tlearn: 1.3490750\ttest: 1.1422969\tbest: 1.1422969 (33)\ttotal: 3.07s\tremaining: 1m 27s\n",
      "34:\tlearn: 1.3446480\ttest: 1.1395579\tbest: 1.1395579 (34)\ttotal: 3.16s\tremaining: 1m 27s\n",
      "35:\tlearn: 1.3409310\ttest: 1.1380129\tbest: 1.1380129 (35)\ttotal: 3.24s\tremaining: 1m 26s\n",
      "36:\tlearn: 1.3378634\ttest: 1.1352016\tbest: 1.1352016 (36)\ttotal: 3.33s\tremaining: 1m 26s\n",
      "37:\tlearn: 1.3329791\ttest: 1.1325038\tbest: 1.1325038 (37)\ttotal: 3.41s\tremaining: 1m 26s\n",
      "38:\tlearn: 1.3301423\ttest: 1.1313570\tbest: 1.1313570 (38)\ttotal: 3.49s\tremaining: 1m 26s\n",
      "39:\tlearn: 1.3246430\ttest: 1.1282810\tbest: 1.1282810 (39)\ttotal: 3.57s\tremaining: 1m 25s\n",
      "40:\tlearn: 1.3208859\ttest: 1.1258810\tbest: 1.1258810 (40)\ttotal: 3.65s\tremaining: 1m 25s\n",
      "41:\tlearn: 1.3155748\ttest: 1.1228176\tbest: 1.1228176 (41)\ttotal: 3.74s\tremaining: 1m 25s\n",
      "42:\tlearn: 1.3105861\ttest: 1.1189712\tbest: 1.1189712 (42)\ttotal: 3.82s\tremaining: 1m 25s\n",
      "43:\tlearn: 1.3052221\ttest: 1.1160142\tbest: 1.1160142 (43)\ttotal: 3.9s\tremaining: 1m 24s\n",
      "44:\tlearn: 1.3009255\ttest: 1.1135803\tbest: 1.1135803 (44)\ttotal: 3.97s\tremaining: 1m 24s\n",
      "45:\tlearn: 1.2977395\ttest: 1.1118447\tbest: 1.1118447 (45)\ttotal: 4.11s\tremaining: 1m 25s\n",
      "46:\tlearn: 1.2958641\ttest: 1.1107745\tbest: 1.1107745 (46)\ttotal: 4.2s\tremaining: 1m 25s\n",
      "47:\tlearn: 1.2937082\ttest: 1.1096611\tbest: 1.1096611 (47)\ttotal: 4.28s\tremaining: 1m 24s\n",
      "48:\tlearn: 1.2917293\ttest: 1.1083234\tbest: 1.1083234 (48)\ttotal: 4.37s\tremaining: 1m 24s\n",
      "49:\tlearn: 1.2885464\ttest: 1.1064356\tbest: 1.1064356 (49)\ttotal: 4.45s\tremaining: 1m 24s\n",
      "50:\tlearn: 1.2854599\ttest: 1.1047695\tbest: 1.1047695 (50)\ttotal: 4.53s\tremaining: 1m 24s\n",
      "51:\tlearn: 1.2823143\ttest: 1.1032644\tbest: 1.1032644 (51)\ttotal: 4.61s\tremaining: 1m 24s\n",
      "52:\tlearn: 1.2801514\ttest: 1.1022446\tbest: 1.1022446 (52)\ttotal: 4.7s\tremaining: 1m 24s\n",
      "53:\tlearn: 1.2770668\ttest: 1.1006606\tbest: 1.1006606 (53)\ttotal: 4.86s\tremaining: 1m 25s\n",
      "54:\tlearn: 1.2747650\ttest: 1.0991236\tbest: 1.0991236 (54)\ttotal: 4.95s\tremaining: 1m 24s\n",
      "55:\tlearn: 1.2717978\ttest: 1.0976367\tbest: 1.0976367 (55)\ttotal: 5.02s\tremaining: 1m 24s\n",
      "56:\tlearn: 1.2698097\ttest: 1.0965150\tbest: 1.0965150 (56)\ttotal: 5.11s\tremaining: 1m 24s\n",
      "57:\tlearn: 1.2675663\ttest: 1.0954704\tbest: 1.0954704 (57)\ttotal: 5.2s\tremaining: 1m 24s\n",
      "58:\tlearn: 1.2649136\ttest: 1.0941317\tbest: 1.0941317 (58)\ttotal: 5.28s\tremaining: 1m 24s\n",
      "59:\tlearn: 1.2615534\ttest: 1.0921473\tbest: 1.0921473 (59)\ttotal: 5.39s\tremaining: 1m 24s\n",
      "60:\tlearn: 1.2587747\ttest: 1.0905919\tbest: 1.0905919 (60)\ttotal: 5.5s\tremaining: 1m 24s\n",
      "61:\tlearn: 1.2565230\ttest: 1.0892418\tbest: 1.0892418 (61)\ttotal: 5.58s\tremaining: 1m 24s\n",
      "62:\tlearn: 1.2545670\ttest: 1.0883821\tbest: 1.0883821 (62)\ttotal: 5.67s\tremaining: 1m 24s\n",
      "63:\tlearn: 1.2524504\ttest: 1.0867739\tbest: 1.0867739 (63)\ttotal: 5.75s\tremaining: 1m 24s\n",
      "64:\tlearn: 1.2500856\ttest: 1.0851034\tbest: 1.0851034 (64)\ttotal: 5.83s\tremaining: 1m 23s\n",
      "65:\tlearn: 1.2475806\ttest: 1.0838707\tbest: 1.0838707 (65)\ttotal: 5.91s\tremaining: 1m 23s\n",
      "66:\tlearn: 1.2456231\ttest: 1.0829516\tbest: 1.0829516 (66)\ttotal: 6s\tremaining: 1m 23s\n",
      "67:\tlearn: 1.2446298\ttest: 1.0824689\tbest: 1.0824689 (67)\ttotal: 6.1s\tremaining: 1m 23s\n",
      "68:\tlearn: 1.2425687\ttest: 1.0812456\tbest: 1.0812456 (68)\ttotal: 6.2s\tremaining: 1m 23s\n",
      "69:\tlearn: 1.2412304\ttest: 1.0805831\tbest: 1.0805831 (69)\ttotal: 6.29s\tremaining: 1m 23s\n",
      "70:\tlearn: 1.2396675\ttest: 1.0798496\tbest: 1.0798496 (70)\ttotal: 6.38s\tremaining: 1m 23s\n",
      "71:\tlearn: 1.2386009\ttest: 1.0794680\tbest: 1.0794680 (71)\ttotal: 6.44s\tremaining: 1m 23s\n",
      "72:\tlearn: 1.2372557\ttest: 1.0785465\tbest: 1.0785465 (72)\ttotal: 6.53s\tremaining: 1m 22s\n",
      "73:\tlearn: 1.2362118\ttest: 1.0781250\tbest: 1.0781250 (73)\ttotal: 6.6s\tremaining: 1m 22s\n",
      "74:\tlearn: 1.2353441\ttest: 1.0776861\tbest: 1.0776861 (74)\ttotal: 6.68s\tremaining: 1m 22s\n",
      "75:\tlearn: 1.2337099\ttest: 1.0767664\tbest: 1.0767664 (75)\ttotal: 6.76s\tremaining: 1m 22s\n",
      "76:\tlearn: 1.2317943\ttest: 1.0756044\tbest: 1.0756044 (76)\ttotal: 6.84s\tremaining: 1m 22s\n",
      "77:\tlearn: 1.2304294\ttest: 1.0747819\tbest: 1.0747819 (77)\ttotal: 6.93s\tremaining: 1m 21s\n",
      "78:\tlearn: 1.2296382\ttest: 1.0741593\tbest: 1.0741593 (78)\ttotal: 7.01s\tremaining: 1m 21s\n",
      "79:\tlearn: 1.2289087\ttest: 1.0739891\tbest: 1.0739891 (79)\ttotal: 7.09s\tremaining: 1m 21s\n",
      "80:\tlearn: 1.2270941\ttest: 1.0730797\tbest: 1.0730797 (80)\ttotal: 7.16s\tremaining: 1m 21s\n",
      "81:\tlearn: 1.2259210\ttest: 1.0721952\tbest: 1.0721952 (81)\ttotal: 7.24s\tremaining: 1m 21s\n",
      "82:\tlearn: 1.2247151\ttest: 1.0716056\tbest: 1.0716056 (82)\ttotal: 7.32s\tremaining: 1m 20s\n",
      "83:\tlearn: 1.2234686\ttest: 1.0710032\tbest: 1.0710032 (83)\ttotal: 7.41s\tremaining: 1m 20s\n",
      "84:\tlearn: 1.2218503\ttest: 1.0701737\tbest: 1.0701737 (84)\ttotal: 7.48s\tremaining: 1m 20s\n",
      "85:\tlearn: 1.2212158\ttest: 1.0699528\tbest: 1.0699528 (85)\ttotal: 7.57s\tremaining: 1m 20s\n",
      "86:\tlearn: 1.2203814\ttest: 1.0688702\tbest: 1.0688702 (86)\ttotal: 7.65s\tremaining: 1m 20s\n",
      "87:\tlearn: 1.2193616\ttest: 1.0681814\tbest: 1.0681814 (87)\ttotal: 7.73s\tremaining: 1m 20s\n",
      "88:\tlearn: 1.2189858\ttest: 1.0678437\tbest: 1.0678437 (88)\ttotal: 7.81s\tremaining: 1m 19s\n",
      "89:\tlearn: 1.2186230\ttest: 1.0676278\tbest: 1.0676278 (89)\ttotal: 7.89s\tremaining: 1m 19s\n",
      "90:\tlearn: 1.2180736\ttest: 1.0674275\tbest: 1.0674275 (90)\ttotal: 7.99s\tremaining: 1m 19s\n",
      "91:\tlearn: 1.2170701\ttest: 1.0666984\tbest: 1.0666984 (91)\ttotal: 8.07s\tremaining: 1m 19s\n",
      "92:\tlearn: 1.2164097\ttest: 1.0664544\tbest: 1.0664544 (92)\ttotal: 8.15s\tremaining: 1m 19s\n",
      "93:\tlearn: 1.2153418\ttest: 1.0656761\tbest: 1.0656761 (93)\ttotal: 8.23s\tremaining: 1m 19s\n",
      "94:\tlearn: 1.2147047\ttest: 1.0652377\tbest: 1.0652377 (94)\ttotal: 8.31s\tremaining: 1m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95:\tlearn: 1.2139078\ttest: 1.0648540\tbest: 1.0648540 (95)\ttotal: 8.4s\tremaining: 1m 19s\n",
      "96:\tlearn: 1.2124647\ttest: 1.0640101\tbest: 1.0640101 (96)\ttotal: 8.49s\tremaining: 1m 19s\n",
      "97:\tlearn: 1.2121144\ttest: 1.0638660\tbest: 1.0638660 (97)\ttotal: 8.56s\tremaining: 1m 18s\n",
      "98:\tlearn: 1.2106518\ttest: 1.0629671\tbest: 1.0629671 (98)\ttotal: 8.65s\tremaining: 1m 18s\n",
      "99:\tlearn: 1.2101567\ttest: 1.0628503\tbest: 1.0628503 (99)\ttotal: 8.72s\tremaining: 1m 18s\n",
      "100:\tlearn: 1.2095550\ttest: 1.0627034\tbest: 1.0627034 (100)\ttotal: 8.81s\tremaining: 1m 18s\n",
      "101:\tlearn: 1.2086820\ttest: 1.0623688\tbest: 1.0623688 (101)\ttotal: 8.9s\tremaining: 1m 18s\n",
      "102:\tlearn: 1.2076055\ttest: 1.0618275\tbest: 1.0618275 (102)\ttotal: 8.98s\tremaining: 1m 18s\n",
      "103:\tlearn: 1.2069164\ttest: 1.0615551\tbest: 1.0615551 (103)\ttotal: 9.06s\tremaining: 1m 18s\n",
      "104:\tlearn: 1.2050728\ttest: 1.0605619\tbest: 1.0605619 (104)\ttotal: 9.14s\tremaining: 1m 17s\n",
      "105:\tlearn: 1.2047787\ttest: 1.0605303\tbest: 1.0605303 (105)\ttotal: 9.22s\tremaining: 1m 17s\n",
      "106:\tlearn: 1.2038586\ttest: 1.0600239\tbest: 1.0600239 (106)\ttotal: 9.3s\tremaining: 1m 17s\n",
      "107:\tlearn: 1.2027947\ttest: 1.0595955\tbest: 1.0595955 (107)\ttotal: 9.39s\tremaining: 1m 17s\n",
      "108:\tlearn: 1.2021099\ttest: 1.0590884\tbest: 1.0590884 (108)\ttotal: 9.49s\tremaining: 1m 17s\n",
      "109:\tlearn: 1.2015960\ttest: 1.0586588\tbest: 1.0586588 (109)\ttotal: 9.59s\tremaining: 1m 17s\n",
      "110:\tlearn: 1.2010658\ttest: 1.0584627\tbest: 1.0584627 (110)\ttotal: 9.68s\tremaining: 1m 17s\n",
      "111:\tlearn: 1.2007306\ttest: 1.0582932\tbest: 1.0582932 (111)\ttotal: 9.76s\tremaining: 1m 17s\n",
      "112:\tlearn: 1.2002485\ttest: 1.0581205\tbest: 1.0581205 (112)\ttotal: 9.84s\tremaining: 1m 17s\n",
      "113:\tlearn: 1.1989189\ttest: 1.0573250\tbest: 1.0573250 (113)\ttotal: 9.92s\tremaining: 1m 17s\n",
      "114:\tlearn: 1.1979662\ttest: 1.0566606\tbest: 1.0566606 (114)\ttotal: 10s\tremaining: 1m 17s\n",
      "115:\tlearn: 1.1977897\ttest: 1.0566044\tbest: 1.0566044 (115)\ttotal: 10.1s\tremaining: 1m 16s\n",
      "116:\tlearn: 1.1974072\ttest: 1.0564266\tbest: 1.0564266 (116)\ttotal: 10.2s\tremaining: 1m 16s\n",
      "117:\tlearn: 1.1971293\ttest: 1.0560465\tbest: 1.0560465 (117)\ttotal: 10.2s\tremaining: 1m 16s\n",
      "118:\tlearn: 1.1967257\ttest: 1.0558745\tbest: 1.0558745 (118)\ttotal: 10.3s\tremaining: 1m 16s\n",
      "119:\tlearn: 1.1963493\ttest: 1.0558440\tbest: 1.0558440 (119)\ttotal: 10.4s\tremaining: 1m 16s\n",
      "120:\tlearn: 1.1960087\ttest: 1.0557210\tbest: 1.0557210 (120)\ttotal: 10.5s\tremaining: 1m 16s\n",
      "121:\tlearn: 1.1954549\ttest: 1.0553654\tbest: 1.0553654 (121)\ttotal: 10.6s\tremaining: 1m 16s\n",
      "122:\tlearn: 1.1950463\ttest: 1.0551516\tbest: 1.0551516 (122)\ttotal: 10.7s\tremaining: 1m 16s\n",
      "123:\tlearn: 1.1946343\ttest: 1.0547813\tbest: 1.0547813 (123)\ttotal: 10.8s\tremaining: 1m 16s\n",
      "124:\tlearn: 1.1944712\ttest: 1.0544271\tbest: 1.0544271 (124)\ttotal: 10.8s\tremaining: 1m 15s\n",
      "125:\tlearn: 1.1938299\ttest: 1.0540685\tbest: 1.0540685 (125)\ttotal: 10.9s\tremaining: 1m 15s\n",
      "126:\tlearn: 1.1934161\ttest: 1.0538995\tbest: 1.0538995 (126)\ttotal: 11s\tremaining: 1m 15s\n",
      "127:\tlearn: 1.1930430\ttest: 1.0536468\tbest: 1.0536468 (127)\ttotal: 11.1s\tremaining: 1m 15s\n",
      "128:\tlearn: 1.1928202\ttest: 1.0534738\tbest: 1.0534738 (128)\ttotal: 11.2s\tremaining: 1m 15s\n",
      "129:\tlearn: 1.1919496\ttest: 1.0530501\tbest: 1.0530501 (129)\ttotal: 11.2s\tremaining: 1m 15s\n",
      "130:\tlearn: 1.1916956\ttest: 1.0528802\tbest: 1.0528802 (130)\ttotal: 11.3s\tremaining: 1m 15s\n",
      "131:\tlearn: 1.1915462\ttest: 1.0528237\tbest: 1.0528237 (131)\ttotal: 11.4s\tremaining: 1m 15s\n",
      "132:\tlearn: 1.1912841\ttest: 1.0527938\tbest: 1.0527938 (132)\ttotal: 11.5s\tremaining: 1m 14s\n",
      "133:\tlearn: 1.1907878\ttest: 1.0525726\tbest: 1.0525726 (133)\ttotal: 11.6s\tremaining: 1m 14s\n",
      "134:\tlearn: 1.1902593\ttest: 1.0522826\tbest: 1.0522826 (134)\ttotal: 11.7s\tremaining: 1m 14s\n",
      "135:\tlearn: 1.1899836\ttest: 1.0521913\tbest: 1.0521913 (135)\ttotal: 11.7s\tremaining: 1m 14s\n",
      "136:\tlearn: 1.1892792\ttest: 1.0518046\tbest: 1.0518046 (136)\ttotal: 11.8s\tremaining: 1m 14s\n",
      "137:\tlearn: 1.1891408\ttest: 1.0517046\tbest: 1.0517046 (137)\ttotal: 11.9s\tremaining: 1m 14s\n",
      "138:\tlearn: 1.1887371\ttest: 1.0516320\tbest: 1.0516320 (138)\ttotal: 12s\tremaining: 1m 14s\n",
      "139:\tlearn: 1.1883491\ttest: 1.0515027\tbest: 1.0515027 (139)\ttotal: 12.1s\tremaining: 1m 14s\n",
      "140:\tlearn: 1.1881794\ttest: 1.0514728\tbest: 1.0514728 (140)\ttotal: 12.2s\tremaining: 1m 14s\n",
      "141:\tlearn: 1.1878584\ttest: 1.0514264\tbest: 1.0514264 (141)\ttotal: 12.3s\tremaining: 1m 14s\n",
      "142:\tlearn: 1.1872844\ttest: 1.0511706\tbest: 1.0511706 (142)\ttotal: 12.3s\tremaining: 1m 13s\n",
      "143:\tlearn: 1.1865464\ttest: 1.0507235\tbest: 1.0507235 (143)\ttotal: 12.4s\tremaining: 1m 13s\n",
      "144:\tlearn: 1.1855887\ttest: 1.0503390\tbest: 1.0503390 (144)\ttotal: 12.5s\tremaining: 1m 13s\n",
      "145:\tlearn: 1.1850561\ttest: 1.0501394\tbest: 1.0501394 (145)\ttotal: 12.6s\tremaining: 1m 13s\n",
      "146:\tlearn: 1.1847867\ttest: 1.0500164\tbest: 1.0500164 (146)\ttotal: 12.7s\tremaining: 1m 13s\n",
      "147:\tlearn: 1.1844909\ttest: 1.0499234\tbest: 1.0499234 (147)\ttotal: 12.8s\tremaining: 1m 13s\n",
      "148:\tlearn: 1.1834238\ttest: 1.0490726\tbest: 1.0490726 (148)\ttotal: 12.9s\tremaining: 1m 13s\n",
      "149:\tlearn: 1.1831651\ttest: 1.0489483\tbest: 1.0489483 (149)\ttotal: 13s\tremaining: 1m 13s\n",
      "150:\tlearn: 1.1828965\ttest: 1.0484647\tbest: 1.0484647 (150)\ttotal: 13.1s\tremaining: 1m 13s\n",
      "151:\tlearn: 1.1826555\ttest: 1.0484304\tbest: 1.0484304 (151)\ttotal: 13.2s\tremaining: 1m 13s\n",
      "152:\tlearn: 1.1825685\ttest: 1.0484006\tbest: 1.0484006 (152)\ttotal: 13.3s\tremaining: 1m 13s\n",
      "153:\tlearn: 1.1820964\ttest: 1.0480730\tbest: 1.0480730 (153)\ttotal: 13.4s\tremaining: 1m 13s\n",
      "154:\tlearn: 1.1818647\ttest: 1.0479569\tbest: 1.0479569 (154)\ttotal: 13.5s\tremaining: 1m 13s\n",
      "155:\tlearn: 1.1817966\ttest: 1.0479233\tbest: 1.0479233 (155)\ttotal: 13.6s\tremaining: 1m 13s\n",
      "156:\tlearn: 1.1815210\ttest: 1.0478105\tbest: 1.0478105 (156)\ttotal: 13.6s\tremaining: 1m 13s\n",
      "157:\tlearn: 1.1812621\ttest: 1.0476102\tbest: 1.0476102 (157)\ttotal: 13.8s\tremaining: 1m 13s\n",
      "158:\tlearn: 1.1810880\ttest: 1.0474628\tbest: 1.0474628 (158)\ttotal: 13.9s\tremaining: 1m 13s\n",
      "159:\tlearn: 1.1809970\ttest: 1.0474294\tbest: 1.0474294 (159)\ttotal: 13.9s\tremaining: 1m 13s\n",
      "160:\tlearn: 1.1807506\ttest: 1.0473550\tbest: 1.0473550 (160)\ttotal: 14s\tremaining: 1m 13s\n",
      "161:\tlearn: 1.1803680\ttest: 1.0470848\tbest: 1.0470848 (161)\ttotal: 14.1s\tremaining: 1m 13s\n",
      "162:\tlearn: 1.1801977\ttest: 1.0469372\tbest: 1.0469372 (162)\ttotal: 14.2s\tremaining: 1m 12s\n",
      "163:\tlearn: 1.1800612\ttest: 1.0467953\tbest: 1.0467953 (163)\ttotal: 14.3s\tremaining: 1m 12s\n",
      "164:\tlearn: 1.1798722\ttest: 1.0466139\tbest: 1.0466139 (164)\ttotal: 14.4s\tremaining: 1m 12s\n",
      "165:\tlearn: 1.1797716\ttest: 1.0465963\tbest: 1.0465963 (165)\ttotal: 14.5s\tremaining: 1m 12s\n",
      "166:\tlearn: 1.1790052\ttest: 1.0463213\tbest: 1.0463213 (166)\ttotal: 14.5s\tremaining: 1m 12s\n",
      "167:\tlearn: 1.1786597\ttest: 1.0459142\tbest: 1.0459142 (167)\ttotal: 14.6s\tremaining: 1m 12s\n",
      "168:\tlearn: 1.1785556\ttest: 1.0458211\tbest: 1.0458211 (168)\ttotal: 14.8s\tremaining: 1m 12s\n",
      "169:\tlearn: 1.1781957\ttest: 1.0455039\tbest: 1.0455039 (169)\ttotal: 14.8s\tremaining: 1m 12s\n",
      "170:\tlearn: 1.1777420\ttest: 1.0452854\tbest: 1.0452854 (170)\ttotal: 14.9s\tremaining: 1m 12s\n",
      "171:\tlearn: 1.1770527\ttest: 1.0450245\tbest: 1.0450245 (171)\ttotal: 15s\tremaining: 1m 12s\n",
      "172:\tlearn: 1.1769647\ttest: 1.0450009\tbest: 1.0450009 (172)\ttotal: 15.1s\tremaining: 1m 12s\n",
      "173:\tlearn: 1.1761538\ttest: 1.0445613\tbest: 1.0445613 (173)\ttotal: 15.2s\tremaining: 1m 12s\n",
      "174:\tlearn: 1.1757984\ttest: 1.0444266\tbest: 1.0444266 (174)\ttotal: 15.3s\tremaining: 1m 12s\n",
      "175:\tlearn: 1.1756151\ttest: 1.0443483\tbest: 1.0443483 (175)\ttotal: 15.4s\tremaining: 1m 11s\n",
      "176:\tlearn: 1.1753800\ttest: 1.0441766\tbest: 1.0441766 (176)\ttotal: 15.5s\tremaining: 1m 11s\n",
      "177:\tlearn: 1.1752029\ttest: 1.0440486\tbest: 1.0440486 (177)\ttotal: 15.5s\tremaining: 1m 11s\n",
      "178:\tlearn: 1.1749149\ttest: 1.0438702\tbest: 1.0438702 (178)\ttotal: 15.6s\tremaining: 1m 11s\n",
      "179:\tlearn: 1.1748412\ttest: 1.0438053\tbest: 1.0438053 (179)\ttotal: 15.7s\tremaining: 1m 11s\n",
      "180:\tlearn: 1.1747202\ttest: 1.0437985\tbest: 1.0437985 (180)\ttotal: 15.8s\tremaining: 1m 11s\n",
      "181:\tlearn: 1.1745872\ttest: 1.0437888\tbest: 1.0437888 (181)\ttotal: 15.9s\tremaining: 1m 11s\n",
      "182:\tlearn: 1.1744722\ttest: 1.0438017\tbest: 1.0437888 (181)\ttotal: 15.9s\tremaining: 1m 11s\n",
      "183:\tlearn: 1.1743862\ttest: 1.0438334\tbest: 1.0437888 (181)\ttotal: 16s\tremaining: 1m 11s\n",
      "184:\tlearn: 1.1736636\ttest: 1.0435191\tbest: 1.0435191 (184)\ttotal: 16.1s\tremaining: 1m 10s\n",
      "185:\tlearn: 1.1734571\ttest: 1.0434055\tbest: 1.0434055 (185)\ttotal: 16.2s\tremaining: 1m 10s\n",
      "186:\tlearn: 1.1734055\ttest: 1.0433790\tbest: 1.0433790 (186)\ttotal: 16.3s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187:\tlearn: 1.1729620\ttest: 1.0431952\tbest: 1.0431952 (187)\ttotal: 16.4s\tremaining: 1m 10s\n",
      "188:\tlearn: 1.1726221\ttest: 1.0430079\tbest: 1.0430079 (188)\ttotal: 16.5s\tremaining: 1m 10s\n",
      "189:\tlearn: 1.1724521\ttest: 1.0428160\tbest: 1.0428160 (189)\ttotal: 16.5s\tremaining: 1m 10s\n",
      "190:\tlearn: 1.1723696\ttest: 1.0428379\tbest: 1.0428160 (189)\ttotal: 16.6s\tremaining: 1m 10s\n",
      "191:\tlearn: 1.1721087\ttest: 1.0426464\tbest: 1.0426464 (191)\ttotal: 16.7s\tremaining: 1m 10s\n",
      "192:\tlearn: 1.1717690\ttest: 1.0425718\tbest: 1.0425718 (192)\ttotal: 16.8s\tremaining: 1m 10s\n",
      "193:\tlearn: 1.1717297\ttest: 1.0426206\tbest: 1.0425718 (192)\ttotal: 16.9s\tremaining: 1m 10s\n",
      "194:\tlearn: 1.1715426\ttest: 1.0425216\tbest: 1.0425216 (194)\ttotal: 17s\tremaining: 1m 10s\n",
      "195:\tlearn: 1.1713488\ttest: 1.0425058\tbest: 1.0425058 (195)\ttotal: 17.1s\tremaining: 1m 9s\n",
      "196:\tlearn: 1.1711655\ttest: 1.0424130\tbest: 1.0424130 (196)\ttotal: 17.1s\tremaining: 1m 9s\n",
      "197:\tlearn: 1.1710345\ttest: 1.0423708\tbest: 1.0423708 (197)\ttotal: 17.2s\tremaining: 1m 9s\n",
      "198:\tlearn: 1.1706380\ttest: 1.0420687\tbest: 1.0420687 (198)\ttotal: 17.3s\tremaining: 1m 9s\n",
      "199:\tlearn: 1.1703080\ttest: 1.0418861\tbest: 1.0418861 (199)\ttotal: 17.4s\tremaining: 1m 9s\n",
      "200:\tlearn: 1.1698898\ttest: 1.0418372\tbest: 1.0418372 (200)\ttotal: 17.5s\tremaining: 1m 9s\n",
      "201:\tlearn: 1.1696478\ttest: 1.0416686\tbest: 1.0416686 (201)\ttotal: 17.6s\tremaining: 1m 9s\n",
      "202:\tlearn: 1.1691849\ttest: 1.0414354\tbest: 1.0414354 (202)\ttotal: 17.7s\tremaining: 1m 9s\n",
      "203:\tlearn: 1.1687511\ttest: 1.0412824\tbest: 1.0412824 (203)\ttotal: 17.7s\tremaining: 1m 9s\n",
      "204:\tlearn: 1.1686071\ttest: 1.0411659\tbest: 1.0411659 (204)\ttotal: 17.8s\tremaining: 1m 9s\n",
      "205:\tlearn: 1.1680669\ttest: 1.0409144\tbest: 1.0409144 (205)\ttotal: 17.9s\tremaining: 1m 8s\n",
      "206:\tlearn: 1.1677585\ttest: 1.0406174\tbest: 1.0406174 (206)\ttotal: 18s\tremaining: 1m 8s\n",
      "207:\tlearn: 1.1676533\ttest: 1.0405527\tbest: 1.0405527 (207)\ttotal: 18.1s\tremaining: 1m 8s\n",
      "208:\tlearn: 1.1675790\ttest: 1.0404937\tbest: 1.0404937 (208)\ttotal: 18.2s\tremaining: 1m 8s\n",
      "209:\tlearn: 1.1674419\ttest: 1.0404754\tbest: 1.0404754 (209)\ttotal: 18.2s\tremaining: 1m 8s\n",
      "210:\tlearn: 1.1673955\ttest: 1.0404044\tbest: 1.0404044 (210)\ttotal: 18.4s\tremaining: 1m 8s\n",
      "211:\tlearn: 1.1673133\ttest: 1.0402957\tbest: 1.0402957 (211)\ttotal: 18.5s\tremaining: 1m 8s\n",
      "212:\tlearn: 1.1669922\ttest: 1.0401314\tbest: 1.0401314 (212)\ttotal: 18.6s\tremaining: 1m 8s\n",
      "213:\tlearn: 1.1669639\ttest: 1.0401196\tbest: 1.0401196 (213)\ttotal: 18.7s\tremaining: 1m 8s\n",
      "214:\tlearn: 1.1668716\ttest: 1.0401244\tbest: 1.0401196 (213)\ttotal: 18.7s\tremaining: 1m 8s\n",
      "215:\tlearn: 1.1667557\ttest: 1.0400979\tbest: 1.0400979 (215)\ttotal: 18.8s\tremaining: 1m 8s\n",
      "216:\tlearn: 1.1666718\ttest: 1.0400069\tbest: 1.0400069 (216)\ttotal: 18.9s\tremaining: 1m 8s\n",
      "217:\tlearn: 1.1665933\ttest: 1.0399471\tbest: 1.0399471 (217)\ttotal: 19s\tremaining: 1m 8s\n",
      "218:\tlearn: 1.1664677\ttest: 1.0399040\tbest: 1.0399040 (218)\ttotal: 19.1s\tremaining: 1m 8s\n",
      "219:\tlearn: 1.1664250\ttest: 1.0398722\tbest: 1.0398722 (219)\ttotal: 19.2s\tremaining: 1m 7s\n",
      "220:\tlearn: 1.1663518\ttest: 1.0397874\tbest: 1.0397874 (220)\ttotal: 19.3s\tremaining: 1m 8s\n",
      "221:\tlearn: 1.1659893\ttest: 1.0396865\tbest: 1.0396865 (221)\ttotal: 19.4s\tremaining: 1m 7s\n",
      "222:\tlearn: 1.1659380\ttest: 1.0396834\tbest: 1.0396834 (222)\ttotal: 19.5s\tremaining: 1m 7s\n",
      "223:\tlearn: 1.1657731\ttest: 1.0395916\tbest: 1.0395916 (223)\ttotal: 19.6s\tremaining: 1m 7s\n",
      "224:\tlearn: 1.1656157\ttest: 1.0396935\tbest: 1.0395916 (223)\ttotal: 19.7s\tremaining: 1m 7s\n",
      "225:\tlearn: 1.1654545\ttest: 1.0396350\tbest: 1.0395916 (223)\ttotal: 19.7s\tremaining: 1m 7s\n",
      "226:\tlearn: 1.1653812\ttest: 1.0395701\tbest: 1.0395701 (226)\ttotal: 19.8s\tremaining: 1m 7s\n",
      "227:\tlearn: 1.1652577\ttest: 1.0396029\tbest: 1.0395701 (226)\ttotal: 20s\tremaining: 1m 7s\n",
      "228:\tlearn: 1.1651682\ttest: 1.0395590\tbest: 1.0395590 (228)\ttotal: 20s\tremaining: 1m 7s\n",
      "229:\tlearn: 1.1649208\ttest: 1.0394997\tbest: 1.0394997 (229)\ttotal: 20.1s\tremaining: 1m 7s\n",
      "230:\tlearn: 1.1648176\ttest: 1.0393833\tbest: 1.0393833 (230)\ttotal: 20.2s\tremaining: 1m 7s\n",
      "231:\tlearn: 1.1642157\ttest: 1.0391095\tbest: 1.0391095 (231)\ttotal: 20.3s\tremaining: 1m 7s\n",
      "232:\tlearn: 1.1641082\ttest: 1.0390717\tbest: 1.0390717 (232)\ttotal: 20.4s\tremaining: 1m 7s\n",
      "233:\tlearn: 1.1640578\ttest: 1.0390181\tbest: 1.0390181 (233)\ttotal: 20.5s\tremaining: 1m 7s\n",
      "234:\tlearn: 1.1637850\ttest: 1.0389694\tbest: 1.0389694 (234)\ttotal: 20.6s\tremaining: 1m 7s\n",
      "235:\tlearn: 1.1636789\ttest: 1.0389754\tbest: 1.0389694 (234)\ttotal: 20.7s\tremaining: 1m 6s\n",
      "236:\tlearn: 1.1636018\ttest: 1.0389674\tbest: 1.0389674 (236)\ttotal: 20.8s\tremaining: 1m 6s\n",
      "237:\tlearn: 1.1635342\ttest: 1.0389296\tbest: 1.0389296 (237)\ttotal: 20.8s\tremaining: 1m 6s\n",
      "238:\tlearn: 1.1634649\ttest: 1.0388839\tbest: 1.0388839 (238)\ttotal: 20.9s\tremaining: 1m 6s\n",
      "239:\tlearn: 1.1633664\ttest: 1.0387828\tbest: 1.0387828 (239)\ttotal: 21s\tremaining: 1m 6s\n",
      "240:\tlearn: 1.1633056\ttest: 1.0387387\tbest: 1.0387387 (240)\ttotal: 21.1s\tremaining: 1m 6s\n",
      "241:\tlearn: 1.1632682\ttest: 1.0387373\tbest: 1.0387373 (241)\ttotal: 21.2s\tremaining: 1m 6s\n",
      "242:\tlearn: 1.1631744\ttest: 1.0386622\tbest: 1.0386622 (242)\ttotal: 21.2s\tremaining: 1m 6s\n",
      "243:\tlearn: 1.1628551\ttest: 1.0385376\tbest: 1.0385376 (243)\ttotal: 21.3s\tremaining: 1m 6s\n",
      "244:\tlearn: 1.1627157\ttest: 1.0384348\tbest: 1.0384348 (244)\ttotal: 21.4s\tremaining: 1m 6s\n",
      "245:\tlearn: 1.1624274\ttest: 1.0383550\tbest: 1.0383550 (245)\ttotal: 21.5s\tremaining: 1m 5s\n",
      "246:\tlearn: 1.1623093\ttest: 1.0383090\tbest: 1.0383090 (246)\ttotal: 21.6s\tremaining: 1m 5s\n",
      "247:\tlearn: 1.1619172\ttest: 1.0380843\tbest: 1.0380843 (247)\ttotal: 21.7s\tremaining: 1m 5s\n",
      "248:\tlearn: 1.1617471\ttest: 1.0380186\tbest: 1.0380186 (248)\ttotal: 21.7s\tremaining: 1m 5s\n",
      "249:\tlearn: 1.1616557\ttest: 1.0379011\tbest: 1.0379011 (249)\ttotal: 21.8s\tremaining: 1m 5s\n",
      "250:\tlearn: 1.1615492\ttest: 1.0378035\tbest: 1.0378035 (250)\ttotal: 21.9s\tremaining: 1m 5s\n",
      "251:\tlearn: 1.1614674\ttest: 1.0376997\tbest: 1.0376997 (251)\ttotal: 22s\tremaining: 1m 5s\n",
      "252:\tlearn: 1.1613544\ttest: 1.0377403\tbest: 1.0376997 (251)\ttotal: 22.1s\tremaining: 1m 5s\n",
      "253:\tlearn: 1.1610648\ttest: 1.0374470\tbest: 1.0374470 (253)\ttotal: 22.2s\tremaining: 1m 5s\n",
      "254:\tlearn: 1.1610114\ttest: 1.0373857\tbest: 1.0373857 (254)\ttotal: 22.3s\tremaining: 1m 5s\n",
      "255:\tlearn: 1.1609778\ttest: 1.0373809\tbest: 1.0373809 (255)\ttotal: 22.3s\tremaining: 1m 4s\n",
      "256:\tlearn: 1.1608349\ttest: 1.0372882\tbest: 1.0372882 (256)\ttotal: 22.4s\tremaining: 1m 4s\n",
      "257:\tlearn: 1.1607209\ttest: 1.0373491\tbest: 1.0372882 (256)\ttotal: 22.5s\tremaining: 1m 4s\n",
      "258:\tlearn: 1.1606752\ttest: 1.0373399\tbest: 1.0372882 (256)\ttotal: 22.6s\tremaining: 1m 4s\n",
      "259:\tlearn: 1.1603256\ttest: 1.0372336\tbest: 1.0372336 (259)\ttotal: 22.7s\tremaining: 1m 4s\n",
      "260:\tlearn: 1.1597923\ttest: 1.0368954\tbest: 1.0368954 (260)\ttotal: 22.8s\tremaining: 1m 4s\n",
      "261:\tlearn: 1.1595939\ttest: 1.0367343\tbest: 1.0367343 (261)\ttotal: 22.9s\tremaining: 1m 4s\n",
      "262:\tlearn: 1.1593081\ttest: 1.0366102\tbest: 1.0366102 (262)\ttotal: 23s\tremaining: 1m 4s\n",
      "263:\tlearn: 1.1591625\ttest: 1.0365438\tbest: 1.0365438 (263)\ttotal: 23.1s\tremaining: 1m 4s\n",
      "264:\tlearn: 1.1591241\ttest: 1.0365146\tbest: 1.0365146 (264)\ttotal: 23.1s\tremaining: 1m 4s\n",
      "265:\tlearn: 1.1587766\ttest: 1.0364281\tbest: 1.0364281 (265)\ttotal: 23.2s\tremaining: 1m 4s\n",
      "266:\tlearn: 1.1587149\ttest: 1.0363928\tbest: 1.0363928 (266)\ttotal: 23.3s\tremaining: 1m 3s\n",
      "267:\tlearn: 1.1586557\ttest: 1.0363867\tbest: 1.0363867 (267)\ttotal: 23.4s\tremaining: 1m 3s\n",
      "268:\tlearn: 1.1585976\ttest: 1.0363176\tbest: 1.0363176 (268)\ttotal: 23.4s\tremaining: 1m 3s\n",
      "269:\tlearn: 1.1582979\ttest: 1.0363210\tbest: 1.0363176 (268)\ttotal: 23.6s\tremaining: 1m 3s\n",
      "270:\tlearn: 1.1580710\ttest: 1.0362615\tbest: 1.0362615 (270)\ttotal: 23.7s\tremaining: 1m 3s\n",
      "271:\tlearn: 1.1579989\ttest: 1.0362226\tbest: 1.0362226 (271)\ttotal: 23.8s\tremaining: 1m 3s\n",
      "272:\tlearn: 1.1579448\ttest: 1.0362157\tbest: 1.0362157 (272)\ttotal: 23.8s\tremaining: 1m 3s\n",
      "273:\tlearn: 1.1578712\ttest: 1.0362035\tbest: 1.0362035 (273)\ttotal: 23.9s\tremaining: 1m 3s\n",
      "274:\tlearn: 1.1578172\ttest: 1.0362099\tbest: 1.0362035 (273)\ttotal: 24s\tremaining: 1m 3s\n",
      "275:\tlearn: 1.1577376\ttest: 1.0361260\tbest: 1.0361260 (275)\ttotal: 24.1s\tremaining: 1m 3s\n",
      "276:\tlearn: 1.1576253\ttest: 1.0360700\tbest: 1.0360700 (276)\ttotal: 24.2s\tremaining: 1m 3s\n",
      "277:\tlearn: 1.1574162\ttest: 1.0360347\tbest: 1.0360347 (277)\ttotal: 24.3s\tremaining: 1m 3s\n",
      "278:\tlearn: 1.1573940\ttest: 1.0360245\tbest: 1.0360245 (278)\ttotal: 24.4s\tremaining: 1m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279:\tlearn: 1.1573176\ttest: 1.0360183\tbest: 1.0360183 (279)\ttotal: 24.5s\tremaining: 1m 2s\n",
      "280:\tlearn: 1.1572226\ttest: 1.0359202\tbest: 1.0359202 (280)\ttotal: 24.6s\tremaining: 1m 2s\n",
      "281:\tlearn: 1.1571351\ttest: 1.0358764\tbest: 1.0358764 (281)\ttotal: 24.7s\tremaining: 1m 2s\n",
      "282:\tlearn: 1.1570706\ttest: 1.0358553\tbest: 1.0358553 (282)\ttotal: 24.8s\tremaining: 1m 2s\n",
      "283:\tlearn: 1.1570157\ttest: 1.0358444\tbest: 1.0358444 (283)\ttotal: 24.9s\tremaining: 1m 2s\n",
      "284:\tlearn: 1.1569640\ttest: 1.0358274\tbest: 1.0358274 (284)\ttotal: 24.9s\tremaining: 1m 2s\n",
      "285:\tlearn: 1.1569065\ttest: 1.0358032\tbest: 1.0358032 (285)\ttotal: 25s\tremaining: 1m 2s\n",
      "286:\tlearn: 1.1568288\ttest: 1.0359998\tbest: 1.0358032 (285)\ttotal: 25.1s\tremaining: 1m 2s\n",
      "287:\tlearn: 1.1567832\ttest: 1.0359693\tbest: 1.0358032 (285)\ttotal: 25.2s\tremaining: 1m 2s\n",
      "288:\tlearn: 1.1564729\ttest: 1.0358889\tbest: 1.0358032 (285)\ttotal: 25.3s\tremaining: 1m 2s\n",
      "bestTest = 1.035803219\n",
      "bestIteration = 285\n",
      "Shrink model to first 286 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('shop_item_block_mean_lag_1', 25.30083121775169),\n",
       " ('item_block_mean_lag_1', 19.240815043070153),\n",
       " ('shop_item_block_mean_rolling_3', 10.3132583768939),\n",
       " ('item_block_mean_rolling_3', 7.607099134767541),\n",
       " ('shop_cat_block_mean_lag_1', 7.5781903379906606),\n",
       " ('item_category_id_mean_encoding', 5.8824662637678315),\n",
       " ('shop_cat_block_mean_rolling_3', 4.6168732235476755),\n",
       " ('item_category_id', 4.574041109276594),\n",
       " ('shop_item_share_of_shop_units_mean', 4.069333157270499),\n",
       " ('shop_share', 3.3999613653380583),\n",
       " ('shop_cat_block_median_rolling_3', 3.0582894370919327),\n",
       " ('shop_block_mean_lag_1', 2.979408461760438),\n",
       " ('shop_block_mean_rolling_3', 1.3794328714730213)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#catboost allows to use categorical features, it does its own mean encoding\n",
    "#had to be very careful with overfitting, bagging_temperature helped\n",
    "\n",
    "cb_model = CatBoostRegressor(iterations=1000,\n",
    "                             #learning_rate=0.05,\n",
    "                             eval_metric='RMSE',\n",
    "                             task_type = \"GPU\",\n",
    "                             use_best_model=True,\n",
    "                             od_type = \"Iter\",\n",
    "                             od_wait = 3,\n",
    "                             bagging_temperature = 20,\n",
    "                             cat_features=[0],\n",
    "                             random_seed = 42)\n",
    "\n",
    "\n",
    "\n",
    "cb_model.fit(x_train[features], y_train, #cat_features=categorical_features_indices,\n",
    "             eval_set=(x_val[features],y_val),\n",
    "             #cat_features=categorical_features_pos,         \n",
    "             verbose=True)\n",
    "\n",
    "scores = {}\n",
    "for i,score in enumerate(cb_model.get_feature_importance()):\n",
    "    scores[features[i]] = score\n",
    "\n",
    "sorted(scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [item[0] for item in scores.items() if item[1] > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test            = pd.read_csv('test.csv.gz')\n",
    "test = test.set_index('item_id').join(items.set_index('item_id'))\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what follows is the tedious building of the test data, was improved later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = [ \n",
    "    'shop_item_share_of_shop_units_mean','item_id_mean_encoding'\n",
    "                ]\n",
    "\n",
    "merge_col = ['item_id']\n",
    "cols=item_features+merge_col\n",
    "\n",
    "test = test.merge(training.drop_duplicates('item_id')[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_features = [\n",
    "        'shop_id_mean_encoding','shop_share'\n",
    "]\n",
    "\n",
    "merge_col = ['shop_id']\n",
    "cols=shop_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "        'item_category_id_mean_encoding'#,'cat_me_real'\n",
    "]\n",
    "\n",
    "merge_col = ['item_category_id']\n",
    "cols=cat_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_item_features = [\n",
    "        'shop_item_share_of_shop_units_mean'#,'cat_me_real'\n",
    "]\n",
    "\n",
    "merge_col = ['shop_id','item_id']\n",
    "cols=shop_item_features+merge_col\n",
    "\n",
    "\n",
    "test = test.merge(training.drop_duplicates(merge_col)[cols], on=merge_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_mean 3\n",
      "[['item_id', 'item_block_mean_rolling_3']]\n",
      "shop_block_mean 3\n",
      "[['shop_id', 'shop_block_mean_rolling_3']]\n",
      "shop_cat_block_mean 3\n",
      "[['shop_id', 'item_category_id', 'shop_cat_block_mean_rolling_3']]\n",
      "shop_cat_block_median 3\n",
      "[['shop_id', 'item_category_id', 'shop_cat_block_median_rolling_3']]\n"
     ]
    }
   ],
   "source": [
    "def add_rolls_test(df, cols, name, rolls = [3]):\n",
    "    for roll in rolls:\n",
    "        print(name, roll)\n",
    "        roll_name = name+\"_rolling_\" + str(roll)\n",
    "        roll_name_tmp = roll_name + \"_tmp\"\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[roll_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "    \n",
    "        block_units_rolling_temp = training\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].rolling(roll,min_periods=2).mean().reset_index()\\\n",
    "            .rename(columns={name:roll_name})\\\n",
    "            [cols+[roll_name]]\n",
    "        \n",
    "        print([cols[0:len(cols)-1]+[roll_name]])\n",
    "        thirty_three = block_units_rolling_temp[block_units_rolling_temp['date_block_num'] == 33].drop_duplicates(cols)\\\n",
    "                [cols[0:len(cols)-1]+[roll_name]]\n",
    "        df = df.merge(thirty_three, on=cols[0:len(cols)-1], how='left')\n",
    "    \n",
    "\n",
    "        del block_units_rolling_temp\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "test = add_rolls_test(test, ['item_id','date_block_num'], 'item_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n",
    "test = add_rolls_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_median')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 3\n",
      "[['shop_id', 'item_id', 'shop_item_block_mean_rolling_3']]\n"
     ]
    }
   ],
   "source": [
    "test = add_rolls_test(test, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_block_mean 1\n",
      "shop_block_mean 1\n",
      "shop_cat_block_mean 1\n"
     ]
    }
   ],
   "source": [
    "def add_lags_test(df, cols, name, lags = [1]):\n",
    "    \n",
    "    for lag in lags:\n",
    "        print(name, lag)\n",
    "        lag_name = name + \"_lag_\" + str(lag)\n",
    "        \n",
    "        try:\n",
    "            df.drop(columns=[lag_name],inplace=True)\n",
    "        except:\n",
    "            pass       \n",
    "\n",
    "        result = training\\\n",
    "            .drop_duplicates(cols)\\\n",
    "            .sort_values(cols)\\\n",
    "            .set_index(cols)\\\n",
    "            .groupby(cols[0:len(cols)-1],as_index=False)\\\n",
    "            [name].shift(lag)\\\n",
    "            .rename(columns={name:lag_name}).reset_index()\n",
    "        \n",
    "        thirty_three = result[result['date_block_num'] == 33].drop_duplicates(cols)\\\n",
    "                [cols[0:len(cols)-1] + [lag_name]]\n",
    "        df = df.merge(thirty_three, on=cols[0:len(cols)-1], how='left')\n",
    "\n",
    "        gc.collect()\n",
    "    \n",
    "    return df\n",
    "                                         \n",
    "\n",
    "                                        \n",
    "test = add_lags_test(test, ['item_id','date_block_num'], 'item_block_mean')\n",
    "test = add_lags_test(test, ['shop_id','date_block_num'], 'shop_block_mean')\n",
    "test = add_lags_test(test, ['shop_id','item_category_id','date_block_num'], 'shop_cat_block_mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_item_block_mean 1\n"
     ]
    }
   ],
   "source": [
    "test = add_lags_test(test, ['shop_id','item_id','date_block_num'], 'shop_item_block_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>shop_item_share_of_shop_units_mean_x</th>\n",
       "      <th>item_id_mean_encoding_x</th>\n",
       "      <th>shop_id_mean_encoding_x</th>\n",
       "      <th>item_category_id_mean_encoding_x</th>\n",
       "      <th>shop_item_share_of_shop_units_mean_y</th>\n",
       "      <th>item_id_mean_encoding_y</th>\n",
       "      <th>shop_id_mean_encoding_y</th>\n",
       "      <th>shop_share</th>\n",
       "      <th>item_category_id_mean_encoding_y</th>\n",
       "      <th>item_block_mean_rolling_3</th>\n",
       "      <th>shop_block_mean_rolling_3</th>\n",
       "      <th>shop_cat_block_mean_rolling_3</th>\n",
       "      <th>shop_cat_block_median_rolling_3</th>\n",
       "      <th>shop_item_block_mean_rolling_3</th>\n",
       "      <th>item_block_mean_lag_1</th>\n",
       "      <th>shop_block_mean_lag_1</th>\n",
       "      <th>shop_cat_block_mean_lag_1</th>\n",
       "      <th>shop_item_block_mean_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98079</th>\n",
       "      <td>10333</td>\n",
       "      <td>47001</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>0.034281</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>1.688803</td>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.034281</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>1.688803</td>\n",
       "      <td>7.735218</td>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.450149</td>\n",
       "      <td>1.291070</td>\n",
       "      <td>1.266054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.304982</td>\n",
       "      <td>1.171717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72357</th>\n",
       "      <td>7452</td>\n",
       "      <td>171936</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.295640</td>\n",
       "      <td>0.314336</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.295640</td>\n",
       "      <td>1.345255</td>\n",
       "      <td>0.314336</td>\n",
       "      <td>0.170442</td>\n",
       "      <td>0.252457</td>\n",
       "      <td>0.190057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.249656</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140858</th>\n",
       "      <td>14333</td>\n",
       "      <td>168002</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>0.044582</td>\n",
       "      <td>0.089903</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.237905</td>\n",
       "      <td>0.044582</td>\n",
       "      <td>0.089903</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.237905</td>\n",
       "      <td>0.053735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>1184</td>\n",
       "      <td>152473</td>\n",
       "      <td>59</td>\n",
       "      <td>76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323335</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323335</td>\n",
       "      <td>1.463167</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151297</th>\n",
       "      <td>15321</td>\n",
       "      <td>71158</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>0.180117</td>\n",
       "      <td>0.423623</td>\n",
       "      <td>0.435298</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>0.180117</td>\n",
       "      <td>0.423623</td>\n",
       "      <td>1.922239</td>\n",
       "      <td>0.435298</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.322687</td>\n",
       "      <td>0.192069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.360033</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151212</th>\n",
       "      <td>15318</td>\n",
       "      <td>64660</td>\n",
       "      <td>22</td>\n",
       "      <td>63</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.369496</td>\n",
       "      <td>0.435298</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.369496</td>\n",
       "      <td>1.687157</td>\n",
       "      <td>0.435298</td>\n",
       "      <td>0.069969</td>\n",
       "      <td>0.290314</td>\n",
       "      <td>0.136889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.311313</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81399</th>\n",
       "      <td>8472</td>\n",
       "      <td>17657</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>1.028662</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>0.046352</td>\n",
       "      <td>0.164302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.165428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112542</th>\n",
       "      <td>11915</td>\n",
       "      <td>125400</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>0.043858</td>\n",
       "      <td>0.096855</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.405424</td>\n",
       "      <td>0.043858</td>\n",
       "      <td>0.096855</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>1.489296</td>\n",
       "      <td>0.405424</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.244885</td>\n",
       "      <td>0.195038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.279383</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121174</th>\n",
       "      <td>12857</td>\n",
       "      <td>23695</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251428</td>\n",
       "      <td>0.405424</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251428</td>\n",
       "      <td>1.162267</td>\n",
       "      <td>0.405424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213751</td>\n",
       "      <td>0.114837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210845</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187303</th>\n",
       "      <td>19094</td>\n",
       "      <td>129505</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>0.168044</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>0.168044</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>2.484515</td>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.113813</td>\n",
       "      <td>0.462350</td>\n",
       "      <td>0.208016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.466006</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id      ID  shop_id  item_category_id  shop_item_share_of_shop_units_mean_x  item_id_mean_encoding_x  shop_id_mean_encoding_x  item_category_id_mean_encoding_x  shop_item_share_of_shop_units_mean_y  item_id_mean_encoding_y  shop_id_mean_encoding_y  shop_share  item_category_id_mean_encoding_y  item_block_mean_rolling_3  shop_block_mean_rolling_3  shop_cat_block_mean_rolling_3  shop_cat_block_median_rolling_3  shop_item_block_mean_rolling_3  item_block_mean_lag_1  shop_block_mean_lag_1  shop_cat_block_mean_lag_1  shop_item_block_mean_lag_1\n",
       "98079   10333    47001   31       37                0.034281                              0.291262                 1.688803                 0.281616                          0.034281                              0.291262                 1.688803                 7.735218    0.281616                          0.450149                   1.291070                   1.266054                       1.0                              1.333333                        0.372093               1.304982               1.171717                   1.0                       \n",
       "72357   7452     171936  37       55                0.032415                              0.216216                 0.295640                 0.314336                          0.032415                              0.216216                 0.295640                 1.345255    0.314336                          0.170442                   0.252457                   0.190057                       0.0                              0.000000                        0.069767               0.249656               0.166667                   0.0                       \n",
       "140858  14333    168002  36       41                0.044582                              0.089903                 0.082090                 0.237905                          0.044582                              0.089903                 0.082090                 0.026622    0.237905                          0.053735                   0.000000                   0.000000                       0.0                              0.000000                        0.023256               0.000000               0.000000                   0.0                       \n",
       "8513    1184     152473  59       76                0.000000                              0.000000                 0.323335                 0.076896                          0.000000                              0.000000                 0.323335                 1.463167    0.076896                          0.000000                   0.245579                   0.000000                       0.0                              0.000000                        0.000000               0.235893               0.000000                   0.0                       \n",
       "151297  15321    71158   24       63                0.043519                              0.180117                 0.423623                 0.435298                          0.043519                              0.180117                 0.423623                 1.922239    0.435298                          0.061856                   0.322687                   0.192069                       0.0                              0.000000                        0.069767               0.360033               0.303922                   0.0                       \n",
       "151212  15318    64660   22       63                0.042331                              0.083333                 0.369496                 0.435298                          0.042331                              0.083333                 0.369496                 1.687157    0.435298                          0.069969                   0.290314                   0.136889                       0.0                              0.000000                        0.071429               0.311313               0.078431                   0.0                       \n",
       "81399   8472     17657   3        43                0.033623                              0.123077                 0.223541                 0.102843                          0.033623                              0.123077                 0.223541                 1.028662    0.102843                          0.046352                   0.164302                   0.000000                       0.0                              0.000000                        0.047619               0.165428               0.000000                   0.0                       \n",
       "112542  11915    125400  52       40                0.043858                              0.096855                 0.325926                 0.405424                          0.043858                              0.096855                 0.325926                 1.489296    0.405424                          0.062225                   0.244885                   0.195038                       0.0                              0.000000                        0.023256               0.279383               0.233202                   0.0                       \n",
       "121174  12857    23695   2        40                0.033727                              0.000000                 0.251428                 0.405424                          0.033727                              0.000000                 0.251428                 1.162267    0.405424                          0.000000                   0.213751                   0.114837                       0.0                              0.000000                        0.000000               0.210845               0.083004                   0.0                       \n",
       "187303  19094    129505  47       37                0.045575                              0.168044                 0.548924                 0.281616                          0.045575                              0.168044                 0.548924                 2.484515    0.281616                          0.113813                   0.462350                   0.208016                       0.0                              0.000000                        0.023256               0.466006               0.191919                   0.0                       "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10003609, 0.07051432, 0.24561174, ..., 0.09224324, 0.12577658,\n",
       "       0.09141575])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_preds = cb_model.predict(test[features])\n",
    "cb_preds.clip(0,20,out=cb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37527545530509904\n",
      "16.349233789151185\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cb_preds))\n",
    "print(np.max(cb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = cb_preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
