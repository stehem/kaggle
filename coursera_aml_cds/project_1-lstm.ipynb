{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175775</th>\n",
       "      <td>2863</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.198523</td>\n",
       "      <td>0.185245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274804</th>\n",
       "      <td>4049</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.119139</td>\n",
       "      <td>0.410866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360819</th>\n",
       "      <td>19973</td>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130846</td>\n",
       "      <td>0.073659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686924</th>\n",
       "      <td>10334</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>14.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>10683.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.071288</td>\n",
       "      <td>0.194823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511801</th>\n",
       "      <td>7580</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.168571</td>\n",
       "      <td>0.162562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541264</th>\n",
       "      <td>8005</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>0.411594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056743</th>\n",
       "      <td>15298</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>0.197074</td>\n",
       "      <td>0.247976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471001</th>\n",
       "      <td>21732</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>10683.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>0.194660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930681</th>\n",
       "      <td>13588</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.221706</td>\n",
       "      <td>0.073659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948974</th>\n",
       "      <td>13720</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.125223</td>\n",
       "      <td>0.165533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "175775   2863     53       32              0                    25                9      2015  12.0            1229.0          258.0               3.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.317391               0.198523               0.185245                      \n",
       "274804   4049     45       32              0                    23                9      2015  23.0            654.0           3590.0              48.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.493333               0.119139               0.410866                      \n",
       "1360819  19973    41       32              0                    61                9      2015  0.0             686.0           554.0               4.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.000000               0.130846               0.073659                      \n",
       "686924   10334    34       27              0                    40                4      2015  14.0            424.0           10683.0             16.0                     12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.219178               0.071288               0.194823                      \n",
       "511801   7580     50       30              0                    64                7      2015  0.0             1126.0          1076.0              19.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.008368               0.168571               0.162562                      \n",
       "541264   8005     3        30              0                    23                7      2015  1.0             535.0           2759.0              49.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.004292               0.116132               0.411594                      \n",
       "1056743  15298    24       29              0                    63                6      2015  13.0            882.0           1425.0              8.0                      10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.248908               0.197074               0.247976                      \n",
       "1471001  21732    26       27              0                    40                4      2015  10.0            1527.0          10683.0             222.0                    12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.103896               0.200891               0.194660                      \n",
       "930681   13588    38       30              0                    61                7      2015  0.0             1354.0          516.0               13.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.037037               0.221706               0.073659                      \n",
       "948974   13720    49       32              0                    69                9      2015  12.0            567.0           665.0               8.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.416667               0.125223               0.165533                      "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', \n",
    "    #'category_cnt_block',\n",
    "    'shop_category_cnt_block',\n",
    "      'item_id_mean_encoding', \n",
    "    'shop_id_mean_encoding'\n",
    "    \n",
    "]\n",
    "\n",
    "#features = all_features\n",
    "\n",
    "#features = ['pca0', 'pca1', 'pca2', 'pca3',  'pca4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3478112  0.18928401 0.10767918 0.08343084 0.07857975]\n",
      "0.8067849771669491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5).fit(training[features])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "training_pca = pca.transform(training[features])\n",
    "\n",
    "for i,component in enumerate(pca.explained_variance_ratio_):\n",
    "    name = 'pca%d' % (i)\n",
    "    training[name] = np.array(training_pca).T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_block', 'shop_cnt_block', 'shop_category_cnt_block']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1)                 28        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 104s 540us/step - loss: 1.0707 - mean_squared_error: 1.0707 - val_loss: 0.9676 - val_mean_squared_error: 0.9676\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from -inf to 0.96756, saving model to lstm_best.hdf5\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 103s 536us/step - loss: 0.9855 - mean_squared_error: 0.9855 - val_loss: 0.9498 - val_mean_squared_error: 0.9498\n",
      "\n",
      "Epoch 00002: val_mean_squared_error did not improve from 0.96756\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 103s 537us/step - loss: 0.9684 - mean_squared_error: 0.9684 - val_loss: 0.9382 - val_mean_squared_error: 0.9382\n",
      "\n",
      "Epoch 00003: val_mean_squared_error did not improve from 0.96756\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 103s 535us/step - loss: 0.9661 - mean_squared_error: 0.9661 - val_loss: 0.9327 - val_mean_squared_error: 0.9327\n",
      "\n",
      "Epoch 00004: val_mean_squared_error did not improve from 0.96756\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 103s 535us/step - loss: 0.9579 - mean_squared_error: 0.9579 - val_loss: 0.9254 - val_mean_squared_error: 0.9254\n",
      "\n",
      "Epoch 00005: val_mean_squared_error did not improve from 0.96756\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 103s 536us/step - loss: 0.9550 - mean_squared_error: 0.9550 - val_loss: 0.9267 - val_mean_squared_error: 0.9267\n",
      "\n",
      "Epoch 00006: val_mean_squared_error did not improve from 0.96756\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 0.9626627756093175\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "dropout=0.2\n",
    "\n",
    "my_model = Sequential()\n",
    "reg = L1L2(l1=0.01,l2=0.01)\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 1,\\\n",
    "                  #kernel_regularizer=reg, \\\n",
    "                  dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "filepath = \"lstm_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_mean_squared_error',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0),checkpoint\n",
    "]\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 6, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3149657 ],\n",
       "       [0.08811408],\n",
       "       [1.3806906 ],\n",
       "       ...,\n",
       "       [0.14298671],\n",
       "       [0.11234349],\n",
       "       [0.0902549 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25702745\n",
      "4.8115597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3542884257097005\n",
      "16.49019305497366\n"
     ]
    }
   ],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
