{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175775</th>\n",
       "      <td>2863</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.198523</td>\n",
       "      <td>0.185245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274804</th>\n",
       "      <td>4049</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.119139</td>\n",
       "      <td>0.410866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360819</th>\n",
       "      <td>19973</td>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130846</td>\n",
       "      <td>0.073659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686924</th>\n",
       "      <td>10334</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>14.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>10683.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.071288</td>\n",
       "      <td>0.194823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511801</th>\n",
       "      <td>7580</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.168571</td>\n",
       "      <td>0.162562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541264</th>\n",
       "      <td>8005</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>0.411594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056743</th>\n",
       "      <td>15298</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>0.197074</td>\n",
       "      <td>0.247976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471001</th>\n",
       "      <td>21732</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>10683.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>0.194660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930681</th>\n",
       "      <td>13588</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.221706</td>\n",
       "      <td>0.073659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948974</th>\n",
       "      <td>13720</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.125223</td>\n",
       "      <td>0.165533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "175775   2863     53       32              0                    25                9      2015  12.0            1229.0          258.0               3.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.317391               0.198523               0.185245                      \n",
       "274804   4049     45       32              0                    23                9      2015  23.0            654.0           3590.0              48.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.493333               0.119139               0.410866                      \n",
       "1360819  19973    41       32              0                    61                9      2015  0.0             686.0           554.0               4.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.000000               0.130846               0.073659                      \n",
       "686924   10334    34       27              0                    40                4      2015  14.0            424.0           10683.0             16.0                     12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.219178               0.071288               0.194823                      \n",
       "511801   7580     50       30              0                    64                7      2015  0.0             1126.0          1076.0              19.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.008368               0.168571               0.162562                      \n",
       "541264   8005     3        30              0                    23                7      2015  1.0             535.0           2759.0              49.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.004292               0.116132               0.411594                      \n",
       "1056743  15298    24       29              0                    63                6      2015  13.0            882.0           1425.0              8.0                      10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.248908               0.197074               0.247976                      \n",
       "1471001  21732    26       27              0                    40                4      2015  10.0            1527.0          10683.0             222.0                    12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.103896               0.200891               0.194660                      \n",
       "930681   13588    38       30              0                    61                7      2015  0.0             1354.0          516.0               13.0                     10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.037037               0.221706               0.073659                      \n",
       "948974   13720    49       32              0                    69                9      2015  12.0            567.0           665.0               8.0                      11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.416667               0.125223               0.165533                      "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', \n",
    "    'shop_category_cnt_block_mean',\n",
    "    'item_id_mean_encoding'\n",
    "]\n",
    "\n",
    "#features = all_features\n",
    "\n",
    "#features = ['pca0', 'pca1', 'pca2', 'pca3',  'pca4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3478112  0.18928401 0.10767918 0.08343084 0.07857975]\n",
      "0.8067849771669491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5).fit(training[features])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "training_pca = pca.transform(training[features])\n",
    "\n",
    "for i,component in enumerate(pca.explained_variance_ratio_):\n",
    "    name = 'pca%d' % (i)\n",
    "    training[name] = np.array(training_pca).T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_block',\n",
       " 'shop_cnt_block',\n",
       " 'shop_category_cnt_block_mean',\n",
       " 'item_id_mean_encoding']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 105s 547us/step - loss: 1.0204 - mean_squared_error: 1.0204 - val_loss: 0.9394 - val_mean_squared_error: 0.9394\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.93936, saving model to lstm_best.hdf5\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 104s 540us/step - loss: 0.9508 - mean_squared_error: 0.9508 - val_loss: 0.8651 - val_mean_squared_error: 0.8651\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.93936 to 0.86514, saving model to lstm_best.hdf5\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 104s 541us/step - loss: 0.9234 - mean_squared_error: 0.9234 - val_loss: 0.8400 - val_mean_squared_error: 0.8400\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.86514 to 0.83998, saving model to lstm_best.hdf5\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 104s 541us/step - loss: 0.9065 - mean_squared_error: 0.9065 - val_loss: 0.7981 - val_mean_squared_error: 0.7981\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.83998 to 0.79813, saving model to lstm_best.hdf5\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 104s 542us/step - loss: 0.8836 - mean_squared_error: 0.8836 - val_loss: 0.7617 - val_mean_squared_error: 0.7617\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.79813 to 0.76174, saving model to lstm_best.hdf5\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 104s 542us/step - loss: 0.8721 - mean_squared_error: 0.8721 - val_loss: 0.7447 - val_mean_squared_error: 0.7447\n",
      "\n",
      "Epoch 00006: val_mean_squared_error improved from 0.76174 to 0.74466, saving model to lstm_best.hdf5\n",
      "Epoch 7/100\n",
      "192780/192780 [==============================] - 104s 541us/step - loss: 0.8567 - mean_squared_error: 0.8567 - val_loss: 0.7158 - val_mean_squared_error: 0.7158\n",
      "\n",
      "Epoch 00007: val_mean_squared_error improved from 0.74466 to 0.71583, saving model to lstm_best.hdf5\n",
      "Epoch 8/100\n",
      "192780/192780 [==============================] - 105s 542us/step - loss: 0.8549 - mean_squared_error: 0.8549 - val_loss: 0.7180 - val_mean_squared_error: 0.7180\n",
      "\n",
      "Epoch 00008: val_mean_squared_error did not improve from 0.71583\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 0.8473284612300881\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "dropout=0.25\n",
    "\n",
    "my_model = Sequential()\n",
    "reg = L1L2(l1=0.01,l2=0.01)\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 3,\\\n",
    "                  #kernel_regularizer=reg, \\\n",
    "                  dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "filepath = \"lstm_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_mean_squared_error',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0),checkpoint\n",
    "]\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 6, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91837597],\n",
       "       [0.05299751],\n",
       "       [0.9637222 ],\n",
       "       ...,\n",
       "       [0.10436922],\n",
       "       [0.05306201],\n",
       "       [0.01861872]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29258096\n",
      "7.480711\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3542884257097005\n",
      "16.49019305497366\n"
     ]
    }
   ],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
