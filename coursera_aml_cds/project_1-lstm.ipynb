{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601017</th>\n",
       "      <td>8874</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>6022.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139831</td>\n",
       "      <td>0.207054</td>\n",
       "      <td>0.194402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677947</th>\n",
       "      <td>10215</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>0.406424</td>\n",
       "      <td>0.045556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209177</th>\n",
       "      <td>3273</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073834</td>\n",
       "      <td>0.123882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107553</th>\n",
       "      <td>15922</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4181.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.289608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4078.0</td>\n",
       "      <td>75.376194</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1553.785714</td>\n",
       "      <td>330.0</td>\n",
       "      <td>6247.0</td>\n",
       "      <td>1336.398262</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>3228.865882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>2663.646850</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>73.363525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>135.813744</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.089856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>0.219265</td>\n",
       "      <td>0.136608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112674</th>\n",
       "      <td>1866</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>0.183266</td>\n",
       "      <td>0.212279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387800</th>\n",
       "      <td>5656</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.138278</td>\n",
       "      <td>0.633298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252430</th>\n",
       "      <td>18140</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>6022.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.194649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170557</th>\n",
       "      <td>16549</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>6474.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094650</td>\n",
       "      <td>0.073963</td>\n",
       "      <td>0.192821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646031</th>\n",
       "      <td>9580</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.750298</td>\n",
       "      <td>0.195932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900487</th>\n",
       "      <td>13313</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193343</td>\n",
       "      <td>0.130881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "601017   8874     18       31              0                    55                8      2015  4.0             1184.0          6022.0              124.0                    11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.139831               0.207054               0.194402                      \n",
       "677947   10215    57       31              0                    31                8      2015  8.0             2780.0          724.0               0.0                      11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.233480               0.406424               0.045556                      \n",
       "209177   3273     34       30              0                    56                7      2015  0.0             460.0           162.0               0.0                      10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.000000               0.073834               0.123882                      \n",
       "1107553  15922    12       33              0                    72                10     2015  1.0             4181.0          1976.0              44.0                     13.289608            0.0                 4078.0              75.376194           4.0                 1553.785714          330.0               6247.0              1336.398262         1161.0              3228.865882              0.0                     7680.0                  2663.646850             2290.0                  73.363525                     0.0                          2524.0                       135.813744                   30.0                         0.255649                  0                        20                       1.089856                 0                        0.054852               0.219265               0.136608                      \n",
       "112674   1866     16       29              0                    24                6      2015  15.0            1038.0          877.0               4.0                      10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.168831               0.183266               0.212279                      \n",
       "387800   5656     4        27              0                    3                 4      2015  0.0             899.0           746.0               8.0                      12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.148936               0.138278               0.633298                      \n",
       "1252430  18140    58       31              1                    55                8      2015  7.0             1738.0          6022.0              145.0                    11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.364807               0.264612               0.194649                      \n",
       "1170557  16549    34       30              0                    55                7      2015  4.0             460.0           6474.0              5.0                      10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.094650               0.073963               0.192821                      \n",
       "646031   9580     25       28              0                    40                5      2015  0.0             5712.0          9208.0              873.0                    11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.008772               0.750298               0.195932                      \n",
       "900487   13313    55       27              0                    47                4      2015  0.0             3422.0          116.0               0.0                      12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.000000               0.193343               0.130881                      "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "      \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1006562</th>\n",
       "      <td>-0.138832</td>\n",
       "      <td>-0.609103</td>\n",
       "      <td>1.617205</td>\n",
       "      <td>0.491855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37499</th>\n",
       "      <td>-0.151635</td>\n",
       "      <td>-0.350405</td>\n",
       "      <td>-0.927134</td>\n",
       "      <td>-0.473945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467254</th>\n",
       "      <td>-0.010802</td>\n",
       "      <td>2.029620</td>\n",
       "      <td>-0.701262</td>\n",
       "      <td>0.247004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880573</th>\n",
       "      <td>-0.151635</td>\n",
       "      <td>-0.839649</td>\n",
       "      <td>-1.019109</td>\n",
       "      <td>-0.514754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196181</th>\n",
       "      <td>-0.138832</td>\n",
       "      <td>-0.272795</td>\n",
       "      <td>0.770969</td>\n",
       "      <td>0.723103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573684</th>\n",
       "      <td>0.053213</td>\n",
       "      <td>-0.091706</td>\n",
       "      <td>-0.755384</td>\n",
       "      <td>-0.378725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24253</th>\n",
       "      <td>-0.126029</td>\n",
       "      <td>-0.874649</td>\n",
       "      <td>-0.778221</td>\n",
       "      <td>-0.514754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217888</th>\n",
       "      <td>-0.087620</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>0.770969</td>\n",
       "      <td>0.988358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446440</th>\n",
       "      <td>-0.023605</td>\n",
       "      <td>-0.024749</td>\n",
       "      <td>-0.679050</td>\n",
       "      <td>-0.127073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500513</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>-0.122142</td>\n",
       "      <td>-0.932139</td>\n",
       "      <td>-0.514754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block\n",
       "1006562 -0.138832       -0.609103        1.617205            0.491855               \n",
       "37499   -0.151635       -0.350405       -0.927134           -0.473945               \n",
       "1467254 -0.010802        2.029620       -0.701262            0.247004               \n",
       "880573  -0.151635       -0.839649       -1.019109           -0.514754               \n",
       "196181  -0.138832       -0.272795        0.770969            0.723103               \n",
       "573684   0.053213       -0.091706       -0.755384           -0.378725               \n",
       "24253   -0.126029       -0.874649       -0.778221           -0.514754               \n",
       "217888  -0.087620        0.176883        0.770969            0.988358               \n",
       "446440  -0.023605       -0.024749       -0.679050           -0.127073               \n",
       "500513   0.002001       -0.122142       -0.932139           -0.514754               "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[features].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 112\n",
      "Trainable params: 106\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 124s 643us/step - loss: 1.2576 - mean_squared_error: 1.2576 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 120s 622us/step - loss: 1.0366 - mean_squared_error: 1.0366 - val_loss: 0.9394 - val_mean_squared_error: 0.9394\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 120s 624us/step - loss: 0.9948 - mean_squared_error: 0.9948 - val_loss: 0.9066 - val_mean_squared_error: 0.9066\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 120s 625us/step - loss: 0.9590 - mean_squared_error: 0.9590 - val_loss: 0.8985 - val_mean_squared_error: 0.8985\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 120s 624us/step - loss: 0.9411 - mean_squared_error: 0.9411 - val_loss: 0.9336 - val_mean_squared_error: 0.9336\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 120s 624us/step - loss: 0.9320 - mean_squared_error: 0.9320 - val_loss: 1.1199 - val_mean_squared_error: 1.1199\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 1.0582599169390934\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "#x_train_scaled = MinMaxScaler().fit_transform(x_train[features])\n",
    "\n",
    "\n",
    "#x_reshaped = np.reshape(x_train_scaled, (x_train_scaled.shape[0], 10, x_train_scaled.shape[1]))\n",
    "    \n",
    "#x_val_scaled_reshaped = np.reshape(x_val_scaled, (x_val_scaled.shape[0], 1, x_val_scaled.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dropout=0.2\n",
    "\n",
    "my_model = Sequential()\n",
    "#bi directional?\n",
    "#my_model.add(CuDNNLSTM(units = 32,\\\n",
    "                # input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(CuDNNLSTM(units = 32,\\\n",
    "                 #input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(GRU(use_bias = True,units = 8, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 3, dropout=dropout,\\\n",
    "                  recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "my_model.add(BatchNormalization())\n",
    "my_model.add(Dropout(dropout))\n",
    "#my_model.add(CuDNNLSTM(units = 8,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(CuDNNLSTM(units = 16,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 4, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#lstmd_dataa = np.array(np.array(lstm_data)).reshape(271148,8,51)\n",
    "#print(lstmd_dataa.shape)\n",
    "#print(lstmd_dataa)\n",
    "#lstm_yy = np.array([np.array([y]) for y in lstm_y[0:100]])\n",
    "#print(lstm_yy.shape)\n",
    "#print(lstm_yy)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0)\n",
    "]\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61835307],\n",
       "       [0.1766897 ],\n",
       "       [0.7317034 ],\n",
       "       ...,\n",
       "       [0.16122672],\n",
       "       [0.16512874],\n",
       "       [0.10879266]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2775038\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
