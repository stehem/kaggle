{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539180</th>\n",
       "      <td>7956</td>\n",
       "      <td>57</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.625882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138748</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497482</th>\n",
       "      <td>22145</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.073360</td>\n",
       "      <td>0.179334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339784</th>\n",
       "      <td>19618</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.176103</td>\n",
       "      <td>0.179534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496800</th>\n",
       "      <td>22137</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.195342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140210</th>\n",
       "      <td>16153</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>0.203229</td>\n",
       "      <td>0.160670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33985</th>\n",
       "      <td>687</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315315</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>0.316074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482750</th>\n",
       "      <td>21948</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.199301</td>\n",
       "      <td>0.071690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854044</th>\n",
       "      <td>12970</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.217341</td>\n",
       "      <td>0.193790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045360</th>\n",
       "      <td>15223</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.570411</td>\n",
       "      <td>0.248845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "539180   7956     57       32              1                    6                 9      2015  9.0             2266.0          237.0               11.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.213675               0.399283               0.625882                      \n",
       "5602     83       4        29              0                    40                6      2015  0.0             793.0           9304.0              79.0                     10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.000000               0.138748               0.196160                      \n",
       "1497482  22145    34       27              0                    37                4      2015  0.0             424.0           4670.0              38.0                     12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.043290               0.073360               0.179334                      \n",
       "1339784  19618    5        32              0                    37                9      2015  7.0             1092.0          2989.0              52.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.105042               0.176103               0.179534                      \n",
       "1496800  22137    10       31              0                    40                8      2015  0.0             442.0           8513.0              59.0                     11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.000000               0.078812               0.195342                      \n",
       "1140210  16153    18       28              0                    64                5      2015  13.0            1434.0          906.0               10.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.296460               0.203229               0.160670                      \n",
       "33985    687      39       27              0                    73                4      2015  18.0            754.0           380.0               1.0                      12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.315315               0.120108               0.316074                      \n",
       "1482750  21948    24       30              0                    61                7      2015  0.0             1014.0          516.0               0.0                      10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.004292               0.199301               0.071690                      \n",
       "854044   12970    56       29              1                    55                6      2015  10.0            1566.0          6017.0              147.0                    10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.334764               0.217341               0.193790                      \n",
       "1045360  15223    42       28              0                    63                5      2015  6.0             4343.0          1370.0              75.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.086420               0.570411               0.248845                      "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "      \n",
    "    \n",
    "]\n",
    "\n",
    "#features = all_features\n",
    "\n",
    "#features = ['pca0', 'pca1', 'pca2', 'pca3',  'pca4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3478112  0.18928401 0.10767918 0.08343084 0.07857975]\n",
      "0.8067849771669491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5).fit(training[features])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "training_pca = pca.transform(training[features])\n",
    "\n",
    "for i,component in enumerate(pca.explained_variance_ratio_):\n",
    "    name = 'pca%d' % (i)\n",
    "    training[name] = np.array(training_pca).T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_block',\n",
       " 'shop_cnt_block',\n",
       " 'category_cnt_block',\n",
       " 'shop_category_cnt_block']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 84s 435us/step - loss: 1.0965 - mean_squared_error: 1.0543 - val_loss: 1.0279 - val_mean_squared_error: 1.0077\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 83s 429us/step - loss: 1.0363 - mean_squared_error: 1.0180 - val_loss: 0.9983 - val_mean_squared_error: 0.9799\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 84s 435us/step - loss: 1.0158 - mean_squared_error: 0.9976 - val_loss: 0.9881 - val_mean_squared_error: 0.9727\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 65s 336us/step - loss: 1.0030 - mean_squared_error: 0.9844 - val_loss: 0.9801 - val_mean_squared_error: 0.9595\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 65s 337us/step - loss: 0.9928 - mean_squared_error: 0.9729 - val_loss: 0.9685 - val_mean_squared_error: 0.9487\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 65s 340us/step - loss: 0.9895 - mean_squared_error: 0.9705 - val_loss: 0.9654 - val_mean_squared_error: 0.9459\n",
      "Epoch 7/100\n",
      "192780/192780 [==============================] - 65s 338us/step - loss: 0.9899 - mean_squared_error: 0.9701 - val_loss: 0.9710 - val_mean_squared_error: 0.9500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 0.9746956746674342\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "\n",
    "dropout=0.2\n",
    "\n",
    "my_model = Sequential()\n",
    "reg = L1L2(l1=0.01,l2=0.01)\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 3, kernel_regularizer=reg, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0)\n",
    "]\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 6, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6439266 ],\n",
       "       [0.15946472],\n",
       "       [0.8257191 ],\n",
       "       ...,\n",
       "       [0.15322077],\n",
       "       [0.15034592],\n",
       "       [0.09652233]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25486293\n",
      "10.4675665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3542884257097005\n",
      "16.49019305497366\n"
     ]
    }
   ],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
