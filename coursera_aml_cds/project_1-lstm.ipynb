{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539180</th>\n",
       "      <td>7956</td>\n",
       "      <td>57</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.625882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138748</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497482</th>\n",
       "      <td>22145</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.073360</td>\n",
       "      <td>0.179334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339784</th>\n",
       "      <td>19618</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.176103</td>\n",
       "      <td>0.179534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496800</th>\n",
       "      <td>22137</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.195342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140210</th>\n",
       "      <td>16153</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>0.203229</td>\n",
       "      <td>0.160670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33985</th>\n",
       "      <td>687</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315315</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>0.316074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482750</th>\n",
       "      <td>21948</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.199301</td>\n",
       "      <td>0.071690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854044</th>\n",
       "      <td>12970</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.217341</td>\n",
       "      <td>0.193790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045360</th>\n",
       "      <td>15223</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.570411</td>\n",
       "      <td>0.248845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "539180   7956     57       32              1                    6                 9      2015  9.0             2266.0          237.0               11.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.213675               0.399283               0.625882                      \n",
       "5602     83       4        29              0                    40                6      2015  0.0             793.0           9304.0              79.0                     10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.000000               0.138748               0.196160                      \n",
       "1497482  22145    34       27              0                    37                4      2015  0.0             424.0           4670.0              38.0                     12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.043290               0.073360               0.179334                      \n",
       "1339784  19618    5        32              0                    37                9      2015  7.0             1092.0          2989.0              52.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.105042               0.176103               0.179534                      \n",
       "1496800  22137    10       31              0                    40                8      2015  0.0             442.0           8513.0              59.0                     11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.000000               0.078812               0.195342                      \n",
       "1140210  16153    18       28              0                    64                5      2015  13.0            1434.0          906.0               10.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.296460               0.203229               0.160670                      \n",
       "33985    687      39       27              0                    73                4      2015  18.0            754.0           380.0               1.0                      12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.315315               0.120108               0.316074                      \n",
       "1482750  21948    24       30              0                    61                7      2015  0.0             1014.0          516.0               0.0                      10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.004292               0.199301               0.071690                      \n",
       "854044   12970    56       29              1                    55                6      2015  10.0            1566.0          6017.0              147.0                    10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.334764               0.217341               0.193790                      \n",
       "1045360  15223    42       28              0                    63                5      2015  6.0             4343.0          1370.0              75.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.086420               0.570411               0.248845                      "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "      \n",
    "    \n",
    "]\n",
    "\n",
    "#features = all_features\n",
    "\n",
    "#features = ['pca0', 'pca1', 'pca2', 'pca3',  'pca4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3478112  0.18928401 0.10767918 0.08343084 0.07857975]\n",
      "0.8067849771669491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5).fit(training[features])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "training_pca = pca.transform(training[features])\n",
    "\n",
    "for i,component in enumerate(pca.explained_variance_ratio_):\n",
    "    name = 'pca%d' % (i)\n",
    "    training[name] = np.array(training_pca).T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_block',\n",
       " 'shop_cnt_block',\n",
       " 'category_cnt_block',\n",
       " 'shop_category_cnt_block']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 119s 617us/step - loss: 1.0986 - mean_squared_error: 1.0986 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 77s 400us/step - loss: 1.0611 - mean_squared_error: 1.0611 - val_loss: 0.9869 - val_mean_squared_error: 0.9869\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 94s 490us/step - loss: 1.0404 - mean_squared_error: 1.0404 - val_loss: 0.9694 - val_mean_squared_error: 0.9694\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 77s 399us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 0.9544 - val_mean_squared_error: 0.9544\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 92s 475us/step - loss: 0.9998 - mean_squared_error: 0.9998 - val_loss: 0.9430 - val_mean_squared_error: 0.9430\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 76s 395us/step - loss: 1.0039 - mean_squared_error: 1.0039 - val_loss: 0.9356 - val_mean_squared_error: 0.9356\n",
      "Epoch 7/100\n",
      "192780/192780 [==============================] - 99s 516us/step - loss: 1.0041 - mean_squared_error: 1.0041 - val_loss: 0.9230 - val_mean_squared_error: 0.9230\n",
      "Epoch 8/100\n",
      "192780/192780 [==============================] - 84s 437us/step - loss: 0.9992 - mean_squared_error: 0.9992 - val_loss: 0.9163 - val_mean_squared_error: 0.9163\n",
      "Epoch 9/100\n",
      "192780/192780 [==============================] - 77s 397us/step - loss: 0.9900 - mean_squared_error: 0.9900 - val_loss: 0.9136 - val_mean_squared_error: 0.9136\n",
      "Epoch 10/100\n",
      "192780/192780 [==============================] - 74s 382us/step - loss: 0.9933 - mean_squared_error: 0.9933 - val_loss: 0.9121 - val_mean_squared_error: 0.9121\n",
      "Epoch 11/100\n",
      "192780/192780 [==============================] - 76s 393us/step - loss: 0.9797 - mean_squared_error: 0.9797 - val_loss: 0.9116 - val_mean_squared_error: 0.9116\n",
      "Epoch 12/100\n",
      "192780/192780 [==============================] - 80s 413us/step - loss: 0.9903 - mean_squared_error: 0.9903 - val_loss: 0.9091 - val_mean_squared_error: 0.9091\n",
      "Epoch 13/100\n",
      "192780/192780 [==============================] - 73s 377us/step - loss: 0.9763 - mean_squared_error: 0.9763 - val_loss: 0.8968 - val_mean_squared_error: 0.8968\n",
      "Epoch 14/100\n",
      "192780/192780 [==============================] - 86s 445us/step - loss: 0.9757 - mean_squared_error: 0.9757 - val_loss: 0.8993 - val_mean_squared_error: 0.8993\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 0.9483128432441754\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_train_scaled = MinMaxScaler().fit_transform(x_train[features])\n",
    "\n",
    "\n",
    "#x_reshaped = np.reshape(x_train_scaled, (x_train_scaled.shape[0], 10, x_train_scaled.shape[1]))\n",
    "    \n",
    "#x_val_scaled_reshaped = np.reshape(x_val_scaled, (x_val_scaled.shape[0], 1, x_val_scaled.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dropout=0.3\n",
    "\n",
    "my_model = Sequential()\n",
    "#bi directional?\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(CuDNNLSTM(units = 32,\\\n",
    "                 #input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(GRU(use_bias = True,units = 8, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 3, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dropout(dropout))\n",
    "#my_model.add(CuDNNLSTM(units = 8,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(CuDNNLSTM(units = 16,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 4, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#lstmd_dataa = np.array(np.array(lstm_data)).reshape(271148,8,51)\n",
    "#print(lstmd_dataa.shape)\n",
    "#print(lstmd_dataa)\n",
    "#lstm_yy = np.array([np.array([y]) for y in lstm_y[0:100]])\n",
    "#print(lstm_yy.shape)\n",
    "#print(lstm_yy)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0)\n",
    "]\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 6, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68502975],\n",
       "       [0.15780857],\n",
       "       [0.76122224],\n",
       "       ...,\n",
       "       [0.15192589],\n",
       "       [0.137075  ],\n",
       "       [0.12643987]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26820764\n",
      "9.9696865\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
