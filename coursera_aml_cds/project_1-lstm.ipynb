{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "sales_train = sales_train[sales_train['year'].isin([2013]) == False]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "sales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "sales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "sales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training[(~training['date_block_num'].isin([22,23]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['item_id','year'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['item_id','year'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['item_id','year'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['item_id','year'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['item_id','year'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['shop_id','year'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['shop_id','year'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['shop_id','year'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['shop_id','year'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['shop_id','year'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['item_category_id','year'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['item_category_id','year'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['item_category_id','year'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['item_category_id','year'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['item_category_id','year'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['shop_id', 'item_category_id','year'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['shop_id', 'item_category_id','year'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['shop_id', 'item_category_id','year'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['shop_id', 'item_category_id','year'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['shop_id', 'item_category_id','year'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['shop_id', 'item_id','year'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['shop_id', 'item_id','year'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['shop_id', 'item_id','year'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['shop_id', 'item_id','year'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['shop_id', 'item_id','year'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4476761</th>\n",
       "      <td>5247</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1825.4</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>721.055640</td>\n",
       "      <td>1842.5</td>\n",
       "      <td>107.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>233.005102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.889739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15941850</th>\n",
       "      <td>18902</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>15109.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1807.2</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>419.770861</td>\n",
       "      <td>1699.5</td>\n",
       "      <td>10174.3</td>\n",
       "      <td>6779.0</td>\n",
       "      <td>15109.0</td>\n",
       "      <td>2444.991387</td>\n",
       "      <td>9293.5</td>\n",
       "      <td>513.3</td>\n",
       "      <td>276.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>144.252382</td>\n",
       "      <td>511.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548964</th>\n",
       "      <td>602</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>978.302819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>28.023132</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379467</th>\n",
       "      <td>6387</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>7439.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.490521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1264.5</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>135.336453</td>\n",
       "      <td>1219.5</td>\n",
       "      <td>6585.4</td>\n",
       "      <td>4369.0</td>\n",
       "      <td>9282.0</td>\n",
       "      <td>1523.468715</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>19.535626</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459499</th>\n",
       "      <td>4056</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.501391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1193.1</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>195.684212</td>\n",
       "      <td>1150.5</td>\n",
       "      <td>1142.9</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>289.225084</td>\n",
       "      <td>1120.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.118041</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16322286</th>\n",
       "      <td>19337</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.240378</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>193.002111</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>97.575177</td>\n",
       "      <td>787.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.759525</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946186</th>\n",
       "      <td>14227</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>10456.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>128.9</td>\n",
       "      <td>94.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>30.139213</td>\n",
       "      <td>125.5</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>2596.0</td>\n",
       "      <td>256.586008</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>12410.6</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>14883.0</td>\n",
       "      <td>1725.857068</td>\n",
       "      <td>11893.5</td>\n",
       "      <td>330.9</td>\n",
       "      <td>257.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>72.332019</td>\n",
       "      <td>284.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.945807</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16761606</th>\n",
       "      <td>19828</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>5647.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.078032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>910.8</td>\n",
       "      <td>791.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>56.382429</td>\n",
       "      <td>915.5</td>\n",
       "      <td>6260.6</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>7704.0</td>\n",
       "      <td>898.538132</td>\n",
       "      <td>6104.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.338921</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164177</th>\n",
       "      <td>3702</td>\n",
       "      <td>48</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.490352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>116.172621</td>\n",
       "      <td>1106.5</td>\n",
       "      <td>219.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>88.926353</td>\n",
       "      <td>205.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.074624</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040422</th>\n",
       "      <td>19007</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>6322.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1222.3</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>159.136909</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>6260.6</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>7704.0</td>\n",
       "      <td>898.538132</td>\n",
       "      <td>6104.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>24.299113</td>\n",
       "      <td>110.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med\n",
       "4476761   5247     12       13              0                    24                2      2014  0.0             1947.0          0.0                 0.0                      0.0                  0.0                 0.0                 0.000000            0.0                 1825.4               1051.0              3400.0              721.055640          1842.5              107.2                    0.0                     740.0                   233.005102              0.0                     5.1                           0.0                          34.0                         10.889739                    0.0                          0.0                       0                        0                        0.000000                 0.0                    \n",
       "15941850  18902    58       24              0                    40                1      2015  0.0             2519.0          15109.0             738.0                    0.1                  0.0                 1.0                 0.300278            0.0                 1807.2               1319.0              2519.0              419.770861          1699.5              10174.3                  6779.0                  15109.0                 2444.991387             9293.5                  513.3                         276.0                        738.0                        144.252382                   511.5                        0.0                       0                        0                        0.000000                 0.0                    \n",
       "548964    602      20       16              0                    78                5      2014  1.0             0.0             77.0                0.0                      0.2                  0.0                 1.0                 0.400371            0.0                 326.1                0.0                 3261.0              978.302819          0.0                 86.9                     41.0                    138.0                   28.023132               87.5                    0.0                           0.0                          0.0                          0.000000                     0.0                          0.0                       0                        0                        0.000000                 0.0                    \n",
       "5379467   6387     59       19              0                    19                8      2014  10.0            1244.0          7439.0              112.0                    3.1                  0.0                 17.0                5.490521            0.0                 1264.5               1082.0              1491.0              135.336453          1219.5              6585.4                   4369.0                  9282.0                  1523.468715             6006.0                  76.2                          39.0                         112.0                        19.535626                    75.5                         0.0                       0                        0                        0.000000                 0.0                    \n",
       "3459499   4056     16       33              0                    24                10     2015  5.0             963.0           1197.0              8.0                      0.5                  0.0                 5.0                 1.501391            0.0                 1193.1               963.0               1698.0              195.684212          1150.5              1142.9                   749.0                   1692.0                  289.225084              1120.5                  13.0                          4.0                          26.0                         6.118041                     11.5                         0.0                       0                        0                        0.000000                 0.0                    \n",
       "16322286  19337    16       18              0                    49                7      2014  5.0             1371.0          793.0               3.0                      6.3                  3.0                 10.0                2.240378            6.0                 1523.0               1232.0              1913.0              193.002111          1535.0              806.0                    617.0                   958.0                   97.575177               787.5                   4.3                           1.0                          10.0                         2.759525                     3.5                          0.0                       0                        0                        0.000000                 0.0                    \n",
       "11946186  14227    19       18              4                    30                7      2014  139.0           1767.0          10456.0             283.0                    128.9                94.0                197.0               30.139213           125.5               1998.0               1703.0              2596.0              256.586008          1927.0              12410.6                  10130.0                 14883.0                 1725.857068             11893.5                 330.9                         257.0                        479.0                        72.332019                    284.0                        3.7                       0                        11                       2.945807                 4.0                    \n",
       "16761606  19828    2        18              0                    37                7      2014  3.0             838.0           5647.0              12.0                     1.2                  0.0                 3.0                 1.078032            1.0                 910.8                791.0               990.0               56.382429           915.5               6260.6                   4971.0                  7704.0                  898.538132              6104.0                  27.7                          12.0                         44.0                         9.338921                     26.0                         0.0                       0                        0                        0.000000                 0.0                    \n",
       "3164177   3702     48       31              0                    21                8      2015  0.0             1308.0          201.0               8.0                      0.4                  0.0                 1.0                 0.490352            0.0                 1149.0               990.0               1413.0              116.172621          1106.5              219.1                    94.0                    394.0                   88.926353               205.5                   5.6                           0.0                          12.0                         3.074624                     5.5                          0.0                       0                        0                        0.000000                 0.0                    \n",
       "16040422  19007    17       14              0                    37                3      2014  0.0             1396.0          6322.0              102.0                    0.0                  0.0                 0.0                 0.000000            0.0                 1222.3               989.0               1474.0              159.136909          1193.0              6260.6                   4971.0                  7704.0                  898.538132              6104.0                  111.3                         59.0                         155.0                        24.299113                    110.5                        0.0                       0                        0                        0.000000                 0.0                    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \n",
    "    'item_cnt_block', 'shop_cnt_block',\n",
    "       'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med','shop_item_cnt_block_std'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[features] = StandardScaler().fit_transform(training[features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[features] = training[features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15879631</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.225594</td>\n",
       "      <td>1.211402</td>\n",
       "      <td>0.151278</td>\n",
       "      <td>-0.109729</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.161633</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>-0.274792</td>\n",
       "      <td>-0.297482</td>\n",
       "      <td>-0.348120</td>\n",
       "      <td>-0.342238</td>\n",
       "      <td>-0.228043</td>\n",
       "      <td>0.902078</td>\n",
       "      <td>0.715022</td>\n",
       "      <td>1.083516</td>\n",
       "      <td>1.346057</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>0.195858</td>\n",
       "      <td>0.312943</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>-0.135231</td>\n",
       "      <td>0.243384</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229249</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.402084</td>\n",
       "      <td>-0.914107</td>\n",
       "      <td>-0.466089</td>\n",
       "      <td>-0.109729</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.161633</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>-0.090170</td>\n",
       "      <td>-0.183024</td>\n",
       "      <td>-0.218470</td>\n",
       "      <td>-0.141709</td>\n",
       "      <td>-0.080399</td>\n",
       "      <td>-0.940938</td>\n",
       "      <td>-0.901666</td>\n",
       "      <td>-1.008421</td>\n",
       "      <td>-1.057520</td>\n",
       "      <td>-0.928765</td>\n",
       "      <td>-0.487967</td>\n",
       "      <td>-0.429710</td>\n",
       "      <td>-0.500155</td>\n",
       "      <td>-0.472796</td>\n",
       "      <td>-0.484846</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10508076</th>\n",
       "      <td>0.200229</td>\n",
       "      <td>-1.053644</td>\n",
       "      <td>0.215142</td>\n",
       "      <td>-0.466089</td>\n",
       "      <td>0.295551</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.160573</td>\n",
       "      <td>0.081963</td>\n",
       "      <td>0.278127</td>\n",
       "      <td>-1.032009</td>\n",
       "      <td>-0.979594</td>\n",
       "      <td>-0.559059</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>-1.074470</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.263617</td>\n",
       "      <td>0.268374</td>\n",
       "      <td>0.257191</td>\n",
       "      <td>0.285724</td>\n",
       "      <td>-0.450814</td>\n",
       "      <td>-0.429710</td>\n",
       "      <td>-0.248932</td>\n",
       "      <td>-0.079528</td>\n",
       "      <td>-0.484846</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16252414</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.794918</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>-0.379944</td>\n",
       "      <td>-0.109729</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.161633</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>-0.835327</td>\n",
       "      <td>-0.683394</td>\n",
       "      <td>-0.999457</td>\n",
       "      <td>-0.824787</td>\n",
       "      <td>-0.789968</td>\n",
       "      <td>0.902078</td>\n",
       "      <td>0.715022</td>\n",
       "      <td>1.083516</td>\n",
       "      <td>1.346057</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>-0.400104</td>\n",
       "      <td>-0.375204</td>\n",
       "      <td>-0.399666</td>\n",
       "      <td>-0.353695</td>\n",
       "      <td>-0.403640</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15838841</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.066183</td>\n",
       "      <td>0.134570</td>\n",
       "      <td>-0.188513</td>\n",
       "      <td>-0.012912</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>-0.008869</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>-0.351722</td>\n",
       "      <td>-0.562269</td>\n",
       "      <td>-0.045341</td>\n",
       "      <td>0.183808</td>\n",
       "      <td>0.277647</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>-0.188997</td>\n",
       "      <td>0.225913</td>\n",
       "      <td>-0.142540</td>\n",
       "      <td>-0.136737</td>\n",
       "      <td>-0.104897</td>\n",
       "      <td>-0.119672</td>\n",
       "      <td>-0.144307</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309661</th>\n",
       "      <td>-0.017271</td>\n",
       "      <td>-1.053644</td>\n",
       "      <td>0.134570</td>\n",
       "      <td>-0.466089</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>-0.719770</td>\n",
       "      <td>-0.979594</td>\n",
       "      <td>-0.807555</td>\n",
       "      <td>-0.150342</td>\n",
       "      <td>-0.600525</td>\n",
       "      <td>0.183808</td>\n",
       "      <td>0.277647</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>-0.188997</td>\n",
       "      <td>0.225913</td>\n",
       "      <td>-0.340859</td>\n",
       "      <td>-0.429710</td>\n",
       "      <td>-0.289127</td>\n",
       "      <td>-0.142178</td>\n",
       "      <td>-0.330293</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123078</th>\n",
       "      <td>-0.076589</td>\n",
       "      <td>-0.362864</td>\n",
       "      <td>0.269151</td>\n",
       "      <td>0.041205</td>\n",
       "      <td>0.133439</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.102096</td>\n",
       "      <td>0.170504</td>\n",
       "      <td>-0.376873</td>\n",
       "      <td>-0.241800</td>\n",
       "      <td>-0.526132</td>\n",
       "      <td>-0.581739</td>\n",
       "      <td>-0.351080</td>\n",
       "      <td>0.902078</td>\n",
       "      <td>0.715022</td>\n",
       "      <td>1.083516</td>\n",
       "      <td>1.346057</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>0.341962</td>\n",
       "      <td>0.292503</td>\n",
       "      <td>0.199921</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>0.434610</td>\n",
       "      <td>1.239417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10234144</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.290749</td>\n",
       "      <td>-0.801837</td>\n",
       "      <td>-0.466089</td>\n",
       "      <td>-0.105226</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.140845</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>-0.217316</td>\n",
       "      <td>-0.163689</td>\n",
       "      <td>-0.405228</td>\n",
       "      <td>-0.495034</td>\n",
       "      <td>-0.170738</td>\n",
       "      <td>-0.828105</td>\n",
       "      <td>-0.791355</td>\n",
       "      <td>-0.912868</td>\n",
       "      <td>-0.982907</td>\n",
       "      <td>-0.805470</td>\n",
       "      <td>-0.483950</td>\n",
       "      <td>-0.429710</td>\n",
       "      <td>-0.490106</td>\n",
       "      <td>-0.456263</td>\n",
       "      <td>-0.482226</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625887</th>\n",
       "      <td>-0.096362</td>\n",
       "      <td>-0.820853</td>\n",
       "      <td>-0.930929</td>\n",
       "      <td>-0.466089</td>\n",
       "      <td>-0.109729</td>\n",
       "      <td>-0.036045</td>\n",
       "      <td>-0.161633</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>-1.048652</td>\n",
       "      <td>-0.979594</td>\n",
       "      <td>-1.039587</td>\n",
       "      <td>-0.493881</td>\n",
       "      <td>-1.074470</td>\n",
       "      <td>-0.958887</td>\n",
       "      <td>-0.924406</td>\n",
       "      <td>-1.021871</td>\n",
       "      <td>-1.054014</td>\n",
       "      <td>-0.947993</td>\n",
       "      <td>-0.488971</td>\n",
       "      <td>-0.429710</td>\n",
       "      <td>-0.503505</td>\n",
       "      <td>-0.479821</td>\n",
       "      <td>-0.484846</td>\n",
       "      <td>-0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266587</th>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.014155</td>\n",
       "      <td>1.048487</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.948503</td>\n",
       "      <td>0.616796</td>\n",
       "      <td>0.711440</td>\n",
       "      <td>0.760185</td>\n",
       "      <td>0.887994</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.273264</td>\n",
       "      <td>-0.022452</td>\n",
       "      <td>-0.281978</td>\n",
       "      <td>0.255004</td>\n",
       "      <td>0.890351</td>\n",
       "      <td>1.098450</td>\n",
       "      <td>0.582494</td>\n",
       "      <td>-0.072385</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.400705</td>\n",
       "      <td>0.626356</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>-0.158595</td>\n",
       "      <td>0.466044</td>\n",
       "      <td>1.508017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_std\n",
       "15879631 -0.096362       -0.225594        1.211402            0.151278                -0.109729            -0.036045           -0.161633           -0.187323           -0.080618           -0.274792            -0.297482           -0.348120           -0.342238           -0.228043            0.902078                 0.715022                1.083516                1.346057                0.842288                0.195858                      0.312943                     0.092732                    -0.135231                     0.243384                    -0.274340               \n",
       "229249   -0.096362       -0.402084       -0.914107           -0.466089                -0.109729            -0.036045           -0.161633           -0.187323           -0.080618           -0.090170            -0.183024           -0.218470           -0.141709           -0.080399           -0.940938                -0.901666               -1.008421               -1.057520               -0.928765               -0.487967                     -0.429710                    -0.500155                    -0.472796                    -0.484846                    -0.274340               \n",
       "10508076  0.200229       -1.053644        0.215142           -0.466089                 0.295551             0.320050            0.160573            0.081963            0.278127           -1.032009            -0.979594           -0.559059            0.088113           -1.074470            0.300366                 0.263617                0.268374                0.257191                0.285724               -0.450814                     -0.429710                    -0.248932                    -0.079528                    -0.484846                    -0.274340               \n",
       "16252414 -0.096362       -0.794918        0.699282           -0.379944                -0.109729            -0.036045           -0.161633           -0.187323           -0.080618           -0.835327            -0.683394           -0.999457           -0.824787           -0.789968            0.902078                 0.715022                1.083516                1.346057                0.842288               -0.400104                     -0.375204                    -0.399666                    -0.353695                    -0.403640                    -0.274340               \n",
       "15838841 -0.096362       -0.066183        0.134570           -0.188513                -0.012912            -0.036045           -0.016121           -0.004927           -0.008869           -0.098054             0.037387           -0.351722           -0.562269           -0.045341            0.183808                 0.277647                0.046024               -0.188997                0.225913               -0.142540                     -0.136737                    -0.104897                    -0.119672                    -0.144307                    -0.274340               \n",
       "15309661 -0.017271       -1.053644        0.134570           -0.466089                -0.006157            -0.036045            0.015060            0.018877            0.003089           -0.719770            -0.979594           -0.807555           -0.150342           -0.600525            0.183808                 0.277647                0.046024               -0.188997                0.225913               -0.340859                     -0.429710                    -0.289127                    -0.142178                    -0.330293                    -0.274340               \n",
       "12123078 -0.076589       -0.362864        0.269151            0.041205                 0.133439            -0.006371            0.087817            0.102096            0.170504           -0.376873            -0.241800           -0.526132           -0.581739           -0.351080            0.902078                 0.715022                1.083516                1.346057                0.842288                0.341962                      0.292503                     0.199921                     0.132858                     0.434610                     1.239417               \n",
       "10234144 -0.096362       -0.290749       -0.801837           -0.466089                -0.105226            -0.036045           -0.140845           -0.162090           -0.080618           -0.217316            -0.163689           -0.405228           -0.495034           -0.170738           -0.828105                -0.791355               -0.912868               -0.982907               -0.805470               -0.483950                     -0.429710                    -0.490106                    -0.456263                    -0.482226                    -0.274340               \n",
       "625887   -0.096362       -0.820853       -0.930929           -0.466089                -0.109729            -0.036045           -0.161633           -0.187323           -0.080618           -1.048652            -0.979594           -1.039587           -0.493881           -1.074470           -0.958887                -0.924406               -1.021871               -1.054014               -0.947993               -0.488971                     -0.429710                    -0.503505                    -0.479821                    -0.484846                    -0.274340               \n",
       "5266587   0.457273        0.014155        1.048487            0.290066                 0.948503             0.616796            0.711440            0.760185            0.887994            0.224360             0.273264           -0.022452           -0.281978            0.255004            0.890351                 1.098450                0.582494               -0.072385                0.972057                0.400705                      0.626356                     0.196571                    -0.158595                     0.466044                     1.508017               "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[features].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = training[['shop_item_cnt_block'] + ['date_block_num','item_id', 'shop_id', 'year'] + features].sort_values(by=[\"date_block_num\"]).groupby([\"item_id\", \"shop_id\", \"year\"])#['item_id_mean_encoding']#[features+['item_cnt_block']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups\n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for name, group in a:\n",
    "    #print(group.values)\n",
    "    steps = []\n",
    "    ys = []\n",
    "    #print(\"group.values\",group.values)\n",
    "    for step in group.values:\n",
    "        #print(step)\n",
    "        #print(\"step\", len(step))\n",
    "        #step is np.array \n",
    "        #step[4:] is np.array print(type(step[4:]))\n",
    "        steps.append(step[5:])\n",
    "        #print(step[9])\n",
    "        #print(step[0])\n",
    "        ys.append(step[0])\n",
    "    #remove last\n",
    "    #print(type(steps[0:8]))\n",
    "    #jan to sept, y = oct\n",
    "    lstm_data.append(np.array(steps[0:8]))\n",
    "    #remove first\n",
    "    #print(ys)\n",
    "    #preditct for setptember\n",
    "    lstm_y.append(ys[-1])\n",
    "    \n",
    "lstm_y = np.array([np.array([y]) for y in lstm_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873908\n",
      "1801396\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,35000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 64)             23040     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 56,641\n",
      "Trainable params: 56,385\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 96760 samples, validate on 10752 samples\n",
      "Epoch 1/100\n",
      "96760/96760 [==============================] - 71s 736us/step - loss: 1.9268 - mean_squared_error: 1.9268 - val_loss: 1.3855 - val_mean_squared_error: 1.3855\n",
      "Epoch 2/100\n",
      "96760/96760 [==============================] - 63s 651us/step - loss: 1.4214 - mean_squared_error: 1.4214 - val_loss: 1.3774 - val_mean_squared_error: 1.3774\n",
      "Epoch 3/100\n",
      "96760/96760 [==============================] - 64s 657us/step - loss: 1.3090 - mean_squared_error: 1.3090 - val_loss: 1.3884 - val_mean_squared_error: 1.3884\n",
      "Epoch 4/100\n",
      "96760/96760 [==============================] - 61s 629us/step - loss: 1.2156 - mean_squared_error: 1.2156 - val_loss: 1.1700 - val_mean_squared_error: 1.1700\n",
      "Epoch 5/100\n",
      "96760/96760 [==============================] - 64s 660us/step - loss: 1.1719 - mean_squared_error: 1.1719 - val_loss: 1.2416 - val_mean_squared_error: 1.2416\n",
      "Epoch 6/100\n",
      "96760/96760 [==============================] - 73s 752us/step - loss: 1.1440 - mean_squared_error: 1.1440 - val_loss: 1.0664 - val_mean_squared_error: 1.0664\n",
      "Epoch 7/100\n",
      "96760/96760 [==============================] - 68s 702us/step - loss: 1.1115 - mean_squared_error: 1.1115 - val_loss: 1.0847 - val_mean_squared_error: 1.0847\n",
      "Epoch 8/100\n",
      "96760/96760 [==============================] - 68s 700us/step - loss: 1.0736 - mean_squared_error: 1.0736 - val_loss: 0.9947 - val_mean_squared_error: 0.9947\n",
      "Epoch 9/100\n",
      "96760/96760 [==============================] - 68s 700us/step - loss: 1.0767 - mean_squared_error: 1.0767 - val_loss: 1.0787 - val_mean_squared_error: 1.0787\n",
      "Epoch 10/100\n",
      "96760/96760 [==============================] - 72s 742us/step - loss: 1.0267 - mean_squared_error: 1.0267 - val_loss: 1.0320 - val_mean_squared_error: 1.0320\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8lNW9x/HPb7KQhKwQSICAiewEWRQQFBAXiKC1i9t1vS6V2tpW22rVtna9t8tta93qVovWam0trq0oEVRARdl32ZcSkBAC2SB7zv3jGWLAQNbJJJPv+/XKK5OZZ57nN/OC+c5zznnOMeccIiIiAL5gFyAiIu2HQkFERGopFEREpJZCQUREaikURESklkJBRERqKRREGsnMnjGz/2nktjvN7IKW7kekrSkURESklkJBRERqKRQkpPibbe4yszVmdtjM/mxmKWb2ppkVm9k8M0uqs/0lZrbezArM7D0zG1rnsdFmtsL/vH8AUccd62IzW+V/7odmNqKZNd9iZlvN7KCZvW5mvf33m5n9wcz2m1mh/zUN9z82w8w2+GvbY2Z3NusNEzmOQkFC0aXAVGAQ8AXgTeAHQDLev/lvA5jZIOAF4A6gBzAH+JeZRZpZJPAq8FegG/BP/37xP/d0YBbwNaA78ATwupl1aUqhZnYe8CvgCqAXsAv4u//hacBk/+tIBK4E8v2P/Rn4mnMuDhgOvNOU44qciEJBQtHDzrlc59weYBHwsXNupXOuHHgFGO3f7krgDefc2865SuB3QDRwFjAeiAAecM5VOudmA0vrHOMW4Ann3MfOuWrn3F+Acv/zmuIaYJZzboW/vnuBCWaWDlQCccAQwJxznzjnPvU/rxIYZmbxzrlDzrkVTTyuSL0UChKKcuvcLq3n71j/7d5438wBcM7VALuBPv7H9rhjZ4zcVef2KcD3/E1HBWZWAPT1P68pjq+hBO9soI9z7h3gEeCPQK6ZPWlm8f5NLwVmALvMbIGZTWjicUXqpVCQzmwv3oc74LXh432w7wE+Bfr47zuqX53bu4H/dc4l1vmJcc690MIauuI1R+0BcM495Jw7A8jEa0a6y3//UufcF4GeeM1cLzbxuCL1UihIZ/YicJGZnW9mEcD38JqAPgQWA1XAt80s3My+Aoyr89w/Abea2Zn+DuGuZnaRmcU1sYa/ATea2Sh/f8Qv8Zq7dprZWP/+I4DDQBlQ7e/zuMbMEvzNXkVAdQveB5FaCgXptJxzm4BrgYeBA3id0l9wzlU45yqArwA3AIfw+h9ervPcZXj9Co/4H9/q37apNcwH7gNewjs76Q/8l//heLzwOYTXxJSP1+8BcB2w08yKgFv9r0OkxUyL7IiIyFE6UxARkVoKBRERqaVQEBGRWgoFERGpFR7sApoqOTnZpaenB7sMEZEOZfny5Qeccz0a2q7DhUJ6ejrLli0LdhkiIh2Kme1qeCs1H4mISB0KBRERqaVQEBGRWh2uT6E+lZWV5OTkUFZWFuxSAi4qKoq0tDQiIiKCXYqIhKCQCIWcnBzi4uJIT0/n2EktQ4tzjvz8fHJycsjIyAh2OSISgkKi+aisrIzu3buHdCAAmBndu3fvFGdEIhIcIREKQMgHwlGd5XWKSHCETCg0pKyymr0FpdRoVlgRkRPqNKFQUVXDgZJySsqrWn3fBQUFPProo01+3owZMygoKGj1ekREmqvThEJsl3B8ZhSVVrb6vk8UCtXVJ18Ma86cOSQmJrZ6PSIizRUSo48aw+cz4qLCKSqtwiW6Vm2bv+eee9i2bRujRo0iIiKC2NhYevXqxapVq9iwYQNf+tKX2L17N2VlZdx+++3MnDkT+GzKjpKSEqZPn87EiRP58MMP6dOnD6+99hrR0dGtVqOISGOEXCj87F/r2bC3qN7Hqmoc5ZXVREeG4WtCKAzrHc9PvpB5wsd//etfs27dOlatWsV7773HRRddxLp162qHjc6aNYtu3bpRWlrK2LFjufTSS+nevfsx+9iyZQsvvPACf/rTn7jiiit46aWXuPZarbAoIm2r0zQfAYT7DAyqqgPb2Txu3LhjriN46KGHGDlyJOPHj2f37t1s2bLlc8/JyMhg1KhRAJxxxhns3LkzoDWKiNQn5M4UTvaNHmDHgcOUV1UzOCUuYMM7u3btWnv7vffeY968eSxevJiYmBimTJlS73UGXbp0qb0dFhZGaWlpQGoTETmZTnWmABAfFU5FVQ1lVTWtts+4uDiKi4vrfaywsJCkpCRiYmLYuHEjH330UasdV0SktYXcmUJD4qMj2FNQSlFpJdERYa2yz+7du3P22WczfPhwoqOjSUlJqX3swgsv5PHHH2fEiBEMHjyY8ePHt8oxRUQCwVwHu5hrzJgx7vhFdj755BOGDh3a6H1s219CjXMMTIlr7fLaRFNfr4iImS13zo1paLtO13wEEB8dTmllNRVVJ7+OQESks+mkoeBNO11Y2vpXN4uIdGSdMhS6hIcRFRFGUVnrX90sItKRdcpQAO9s4Uh5FVXVrTcKSUSko+u0oZAQFY4DnS2IiNTRaUMhKiKMyDAfRepXEBGp1WlDwcyIj46guLyK6pqWDctt7tTZAA888ABHjhxp0fFFRFpLpw0F8PoVnHMUt7AJSaEgIqGi013RXFfXyDDCfV4TUmJMZLP3U3fq7KlTp9KzZ09efPFFysvL+fKXv8zPfvYzDh8+zBVXXEFOTg7V1dXcd9995ObmsnfvXs4991ySk5N59913W/HViYg0XeiFwpv3wL61jdrUgP5V1VTVOFxkGMYJJshLPQ2m//qE+6k7dXZ2djazZ89myZIlOOe45JJLWLhwIXl5efTu3Zs33ngD8OZESkhI4P777+fdd98lOTm5qa9URKTVdermI4Awn+EcLe5XOCo7O5vs7GxGjx7N6aefzsaNG9myZQunnXYa8+bN4+6772bRokUkJCS0yvFERFpT6J0pnOQbfX18NY6dnxaRGBNBWlJMiw/vnOPee+/la1/72uceW758OXPmzOHee+9l2rRp/PjHP27x8UREWlOnP1OoXaazrIrmTg5Yd+rsrKwsZs2aRUlJCQB79uxh//797N27l5iYGK699lruvPNOVqxY8bnniogEW+idKTRDQnQEhaWVHKmopmuXpr8ldafOnj59OldffTUTJkwAIDY2lueee46tW7dy11134fP5iIiI4LHHHgNg5syZTJ8+nV69eqmjWUSCrlNOnX286poaNnxaTHJsJL0SoltaYsBp6mwRaaqgT51tZrPMbL+ZrTvB4wlm9i8zW21m683sxkDV0pAwn4/YLuEUllY2uwlJRCQUBLJP4RngwpM8fhuwwTk3EpgC/N7Mmn+xQAsdXaazvBWX6RQR6WgCFgrOuYXAwZNtAsSZmQGx/m2bPRFRS7/hf7bGQvueIE9nMiISSMEcffQIMBTYC6wFbnfO1fs13cxmmtkyM1uWl5f3ucejoqLIz89v0QdmRJiPmMhwitpxKDjnyM/PJyoqKtiliEiICubooyxgFXAe0B9428wWOeeKjt/QOfck8CR4Hc3HP56WlkZOTg71BUZTFJdVUlhaRdmBLoT72udo3aioKNLS0oJdhoiEqGCGwo3Ar5339X6rme0AhgBLmrqjiIgIMjIyWlzQzgOHueJ37/Hji4dx08SW709EpKMJ5tfh/wDnA5hZCjAY2B7EekhP7srglDjmrt8XzDJERIImkENSXwAWA4PNLMfMbjazW83sVv8mvwDOMrO1wHzgbufcgUDV01hZmSks3XmQ/JLyYJciItLmAtZ85Jy7qoHH9wLTAnX85pqWmcpD72xl/if7uWJs32CXIyLSptpnb2oQZfaOp09itJqQRKRTUigcx8yYlpnCoq0HOFyu9ZtFpHNRKNQjKzOViqoaFmxu2RBXEZGORqFQjzGnJJEUE6EmJBHpdBQK9QgP83HB0BTe2bifCs2FJCKdiELhBLIyUykuq+Kj7fnBLkVEpM0oFE5g4sBkYiLD1IQkIp2KQuEEoiLCmDK4B29vyKWmRjOTikjnoFA4iWnDUtlfXM7K3QXBLkVEpE0oFE7i3CE9CfcZ2WpCEpFOQqFwEgnREUzo35256/dpcRsR6RQUCg3IykxlZ/4RtuwvCXYpIiIBp1BowNRhKQDMXacmJBEJfQqFBqTERzG6XyJzNygURCT0KRQaISszlXV7ithTUBrsUkREAkqh0AhZmakAGoUkIiFPodAIGcldGZQSq6ubRSTkKRQaadqwVJbsOMjBwxXBLkVEJGAUCo2UlZlKjYN5n+QGuxQRkYBRKDTS8D7eMp3Z6xUKIhK6FAqNZGZMHZbCoi15HKnQMp0iEpoUCk0wLTOF8qoaFmzSMp0iEpoUCk0wLr2blukUkZCmUGiC8DAf5w9NYb6W6RSREKVQaKKjy3R+vEPLdIpI6FEoNNGkgclER2iZThEJTQqFJoqKCOOcQT3IXq9lOkUk9CgUmiFreAr7i8tZlaNlOkUktCgUmuG8wSn+ZTp1IZuIhBaFQjMkxHjLdGZrmU4RCTEKhWaaNiyF7QcOs1XLdIpICFEoNNPUYd4aCxqFJCKhRKHQTKkJUYzqm8hc9SuISAgJWCiY2Swz229m606yzRQzW2Vm681sQaBqCZSszFTW7ilkr5bpFJEQEcgzhWeAC0/0oJklAo8ClzjnMoHLA1hLQGRlpgBaplNEQkfAQsE5txA4eJJNrgZeds79x7/9/kDVEiin9ohlQM9YNSGJSMgIZp/CICDJzN4zs+Vmdn0Qa2m2rMwUluw8yCEt0ykiISCYoRAOnAFcBGQB95nZoPo2NLOZZrbMzJbl5bWvtQyyMlOprnHM39jhTnRERD4nmKGQA7zlnDvsnDsALARG1rehc+5J59wY59yYHj16tGmRDTmtTwK9EqI0NFVEQkIwQ+E1YJKZhZtZDHAm8EkQ62kWM2PasBQWbtYynSLS8QVySOoLwGJgsJnlmNnNZnarmd0K4Jz7BHgLWAMsAZ5yzp1w+Gp7lpWZSnlVDQs3t6+mLRGRpgoP1I6dc1c1YpvfAr8NVA1tZVxGNxJjIpi7PpcLh/cKdjkiIs2mK5pbQXiYj/OHpDD/k1wqq7VMp4h0XAqFVpKVmUJRWRUfbz/ZpRkiIu2bQqGVTBrYg6gIn0YhiUiHplBoJdGR/mU6N+zTMp0i0mEpFFpRVmYquUXlrNYynSLSQSkUWtH5Q1II8xnZGzQXkoh0TAqFVpQQE8H4U7upX0FEOiyFQivLykxle95htu4vDnYpIiJNplBoZdNql+lUE5KIdDwKhVaWmhDFyL6JWnhHRDokhUIAZGWmsDqnkE8LtUyniHQsCoUAONqElK0mJBHpYBQKATCgZyz9e3TVKCQR6XAUCgGSlZnKxzu0TKeIdCwKhQA5ukznO1qmU0Q6EIVCgIxISyA1Xst0ikjHolAIEDNjWmYKC7fkUVpRHexyREQaRaEQQFmZqZRV1rBAy3SKSAfRqFAws9vNLN48fzazFWY2LdDFdXTjMrqREB1B9gY1IYlIx9DYM4WbnHNFwDSgB3Aj8OuAVRUiIsJ8nD+0J/M/2a9lOkWkQ2hsKJj/9wzgaefc6jr3yUlMG5ZKYWklS3ZomU4Raf8aGwrLzSwbLxTmmlkcoK++jXDOIC3TKSIdR2ND4WbgHmCsc+4IEIHXhCQNiI4MY/LAHmSvz9UynSLS7jU2FCYAm5xzBWZ2LfAjoDBwZYWWrMxU9hWVsXaP3jIRad8aGwqPAUfMbCTwfWAX8GzAqgox5w/tSZjP1IQkIu1eY0OhyjnngC8CDzrnHgTiAldWaEmMieTMDC3TKSLtX2NDodjM7gWuA94wszC8fgVppKzMVLblHWbr/pJglyIickKNDYUrgXK86xX2AX2A3wasqhA0LTMFQBeyiUi71qhQ8AfB80CCmV0MlDnn1KfQBL0SohmZlqC1m0WkXWvsNBdXAEuAy4ErgI/N7LJAFhaKpmWmsnp3AfsKy4JdiohIvRrbfPRDvGsU/ts5dz0wDrgvcGWFpiw1IYlIO9fYUPA55+quFpPfhOeK34CecZyqZTpFpB1r7Af7W2Y218xuMLMbgDeAOYErK3R9YURvPtiaz/dnr+ZweVWwyxEROUZ4YzZyzt1lZpcCZ+NNhPekc+6VgFYWor553gCqaxyPvreVj3cc5A9XjuL0fknBLktEBGhCE5Bz7iXn3Hedc99pTCCY2Swz229m6xrYbqyZVXeWjuuIMB93Zg3m7zMnUFXtuPzxxTwwbzNVmlpbRNqBk4aCmRWbWVE9P8VmVtTAvp8BLmxg/2HAb4C5Tao6BIzL6Mabd0ziiyN788C8LVz2+GJ2Hjgc7LJEpJM7aSg45+Kcc/H1/MQ55+IbeO5CoKFFBL4FvATsb2C7kBQfFcH9V47i4atGsz2vhBkPLeLFpbvxZhQREWl7QRtBZGZ9gC8Djzdi25lmtszMluXlhd56x18Y2Zu37pjMyLREvv/SGr7+3AoOHa4Idlki0gkFc1jpA8DdzrnqhjZ0zj3pnBvjnBvTo0ePNiit7fVOjOb5r57JD2cM5Z2N+8l6YCELN7diAFaVQ3Eu7N8IuxbDxjlQ8J/W27+IhIRGjT4KkDHA380MIBmYYWZVzrlXA3K0XR/Cwt9ClziIjIMusRAZW+d3XJ2//Y8fvS8yFnyBz0+fz7hl8qmcPSCZ2/++kutnLeHGs9O5+8IhREWEgXNQXgylh6CswPt9zE/BsbfrblN55PMHjEqAWz+AxL4Bf20i0jEELRSccxlHb5vZM8C/AxYI4H1TLiuCor3eB2t5CVQUg2vkqJ+IrscFyXHBUm/Y1Pd3HPjC6/lQ/+zvYaWHeKvfIbaxm5KleeStLKVXZBnh5QVwshOrsC4QnfTZT+Ip0Guk/+9E73eU/zfAi9fDy7fAf/8bwoL5/UBE2ouAfRKY2QvAFCDZzHKAn+Cfbts512A/Qqvrf673U5dzUFkKFSVeUFSU+MPC/3d999X9+2jAHL2vqrR1au2SQFh0IoO6JnEoJoVluY5Fh2MYeuopjByYji+mzgf/0Q/76CSIiG7acS7+gxcKC/8Pzv1B69QuIh1awELBOXdVE7a9IVB1nJQZRMZ4P7E9W76/6iovIOoNkjpnJ9VV9X+oRydBl/hjvrUnAWccruCel9bwgw25nFXVnd9fMZJeCU0MgPqMuAK2ves1q2VMhvSJLd+niHRo1tGGP44ZM8YtW7Ys2GW0OeccLy7bzc/+tYFwn/HLr5zGxSN6t3zH5SXwxGTvjOnrH0BMt5bvU0TaHTNb7pwb09B2mtSugzAzrhzbjznfnsSpPWL55t9W8t1/rKK4rLJlO+4SC5fNgsN58Oo3vCY1Eem0FAodTHpyV/556wRuP38gr67aw/QHF7F0Z0PXCDag9yiY+nPY/CYsebJ1ChWRDkmh0AFFhPn4ztRB/PPWs/CZceUTi/nd3E1UtmT+pPFfh4FZkP0j+HRN6xUrIh2KQqEDO+OUJObcPolLT0/jkXe3culjH7I9r6R5OzODLz0K0d1g9k1QoXmYRDojhUIHF9slnN9ePpLHrjmd/xw8wkUPvc/fPv5P8+ZP6poMl/4J8rfCnO+3frEi0u4pFELE9NN6MfeOyYxJT+IHr6zllmeXcaCkvOk7ypgMk74Hq56DtbNbv1ARadcUCiEkJT6Kv9w4jh9fPIyFWw5w4QMLeXdjMyagnXIv9D0T/nUHHNzR+oWKSLulUAgxPp9x08QMXv/m2STHduHGZ5Zy36vrKK1ocN7Bz4SFw6VPgfngpZuhuoXDXkWkw1AohKghqfG8etvZfHViBn/9aBcXP7yIdXsKG7+DxH5wyUOwZzm884vAFSoi7YpCIYRFRYTxo4uH8fxXz+RweTVffvQDHntvG9U1jeyEzvwSnHEDfPAgbJ0f0FpFpH1QKHQCZw9I5q07JjF1WAq/eWsjV/3pI3IO1TOVdn2yfgU9hsIrt0JJp1wgT6RTUSh0Eokxkfzx6tP5/eUj2bC3iOkPLGL28pyGh65GxnjTYJQXwStfg5oWXCAnIu2eQqETMTMuPSONN2+fxODUOO7852oue3xxw30NKcMg65ew7R1Y/HDbFCsiQaFQ6IT6dovhxa9N4P8uG8Gu/MN84ZH3ufflteSf7LqGMTfB0Etg/s8hZ3nbFSsibUqh0En5fMYVY/ryzp1TuOnsDP65bDfn/u49nvlgB1X1zaFk5o1GiusFL93krWInIiFHodDJxUdFcN/Fw3jz9kmMSEvkp//awIyHFvHh1gOf3zg6ybt+oWA3/Ps7mmZbJAQpFASAgSlx/PXmcTxx3Rkcqajm6qc+5uvPLWf3weNGKfUb713xvG42rPpbcIoVkYBRKEgtMyMrM5V53z2H700dxLub9nPB/Qv4w9ubj70ietJ3IX0SzLkTDmwJXsEi0uoUCvI5URFhfOv8gbzzvSlMHZbCg/O3cMH9C3hz7afeEFZfGHzlSQiPgtk3QlUzJt4TkXZJoSAn1DsxmkeuPp2/zxxPXFQ4X39+Bdc89TGb9hVDfG9v/YV9a+HtHwe7VBFpJQoFadD4U7vz729N5BdfzGT93iJmPLSIn76+nsK+F8CZt8LHj8OmN4Ndpoi0AoWCNEp4mI/rJqTz3p1TuHpcP55dvJNzf/8e/0i8BZd6Grz6DSjaG+wyRaSFFArSJEldI/nFl4bzr29NZECPWO5+bRO3lt1GdWUZvHQL1DRhim4RaXcUCtIsmb0T+MfXxvPQVaNZfaQnd5deB7vep2Teb4Jdmoi0gEJBms3MuGRkb9658xxSJ93E6zVnE/3B//HKq7Mpr9IZg0hHpFCQFouJDOfOC4cw6uuzyI/oxbiV3+ey+9/gnY25wS6t8Q7tUtOXCAoFaUX9eqXS88bn6OUr5K6KR7npmaXc8PQStueVBLu0+tXUwKa34OmL4MER3tKjmhpcOjmFgrSuPmfgu+DHTK5azHMj17Ns5yGyHljIr+Z8QnFZO1nrubIUlj0NfxwHL1wJh3bCaVfA+lfgrbs1p5N0auHBLkBC0IRvwfYFTNx2PwtueItfL/PxxMLtvLxyD/dcOIQvj+6Dz2dtX1dJHiz9Eyx9Co7kQ69RcOmfYdgXISwC4lLgw4eha0845662r0+kHbAGV95qZ8aMGeOWLVsW7DKkISX74bGzIaYb3PIuq3Ir+Mnr61m9u4DT+yXy00syGZGW2Da15G2CxY/A6n9AdTkMmg5nfRNOOdubEvyomhp47Ruw+gW4+AEYc2Pb1CfSBsxsuXNuTIPbKRQkYLbOh+e+AmfcAF94kJoax0srcvjNWxvJP1zBlWP6cmfWYJJju7T+sZ2DnYvgw0dgy1xvnqaRV8GE2yB54ImfV10Jf78Gtr4Nl/8Fhl3S+rWJBIFCQdqHt38MHzwIlz8DmV8GoKiskofnb+HpD3YSHRnGf43tyzmDejImPYmoiLCWHa+60usb+PBh2LcGYpJh3EwYezN0TW7cPiqOwLNfhE9Xw3UvQ/rEltUk0g4EPRTMbBZwMbDfOTe8nsevAe72/1kCfN05t7qh/SoUOpjqSpiVBQe2wq2LIOmU2oe27i/h129uZMHm/VRWO7qE+zjz1O5MHpjMpIE9GJQSi1kj+x5KC2DFX+DjJ6BoDyQP8s4KRlwJEdFNr/vIQXh6ujd1xw1vQK8RTd+HSDvSHkJhMt6H/bMnCIWzgE+cc4fMbDrwU+fcmQ3tV6HQAR3cAU9Mhh5D4MY5XqduHYfLq/h4Rz4LNx9g0ZY8tuUdBiAlvguTBvZg0sBkJg5Ipnt9zUyHdnkT8q14FipKvHUezvoWDJgKvhYOrivcA3+eBtUVcHM2dMto2f5EgijooeAvIh34d32hcNx2ScA651yfhvapUOig1s72rgOY9D04/+RTbe8pKOX9LXks3HKA97ccoLDUG8o6vE98bUiMCd9O5JJHYcNrYD4Yfql3ZtBrZOvWnbfJO9OJSvSCIbZn6+5fpI10tFC4ExjinPvqCR6fCcwE6Nev3xm7du1q5UqlTbx2G6x8Hq5/DU49p1FPqa5xrNtTyMLNeby/OZeknPncFPYG43ybOGJd2dbvMmLP+SbpGQMb39TUVDnL4C9fgO4DvKakqPjAHEckgDpMKJjZucCjwETnXH5D+9SZQgdWcRieOAfKi+HrHzSt43fV8/DRo3BwO6UxfXgv6VIeLpjAhnzv32/vhCjvLGJQMmf3Tyapa2Tr1r5lnneh2ylnwTWzITwAI6ZEAqhDhIKZjQBeAaY75zY3Zp8KhQ7u0zXw1Plw6rlw9T+OvU7geMW5sORJWPZnKD0Efc6ACd+EoZdAmHfd5e6DR1i0xeuLeH/rAYrLqjCDEX0SmDSwB5MH9WB0v0Qiwlrh4v01L8LLt3gXu132tLcsqUgH0e5Dwcz6Ae8A1zvnPmzsPhUKIeDjJ+DN70PWr2DCNz7/eO4GWPxHWPuiN3ppyEVeGPQbf9IQqaquYXVOIYu25LFoywFW7S6gusbRNTKMCf2TmTzIG9WU3j2m+U1Ni/8Ic38AY26Gi35/8lATaUeCHgpm9gIwBUgGcoGfABEAzrnHzewp4FLgaAdBVWMKViiEAOfg71fDlrfhq/Og9yjvvu3vehebbZsP4dEw+hoY/w3o3r9ZhyksrWTxtnwWbclj4ZY8dh8sBSAtKdo7ixiYzFn9k0mIiWhgT8d5+yfwwQMw5V6Yck+zahNpa0EPhUBRKISIIwe9aTAiomHid7xhpbnrvHmHzpzpfROP6daqh9yVf5iFm71RTYu35VNSXoXPYGTfRCYN7MGovgkMTo2nd0LUyc8knIPXvgmrnoOL7vcujBNp5xQK0v7tfN8b1eNqoOcwb0jpaZe3SSduZXUNq3YXsMgfEmtyCqjx/1eI6xLOoNQ4BqfGMSQ1jsEpcQxJjT/2jKK6Cv5xLWx+y3+19pcCXrNISygUpGPYnO112PY/L6jt80VllWzaV8zGfcVs3lfsv11EUVlV7TYp8V0YnBr/WVAkhzP07evxfbrSG5HUyGG2IsGgUBBpIecc+4rK2OQPiaOhsTWvhIoqbzGeRCvh5ej/pRd5vDziSboPGMPg1Hj6dYshLBjTg4ucgEJBJED6sY/bAAAQUklEQVSqqmvYmX/EHxRF5O7Zznf+8y3Ca8q5tOKn7HKpREX4GNizThOU/6dHbJfAXWQnchIKBZG2dGAL7s/TqAiPZe6Zz7K6oEvtmcWBkvLazZJiIvxBEV8bFINS4ojtovWuJLAUCiJtLWe513He7VS48Q2ISgAgv6ScTbmfNUFtyvX6LQ5XVNc+NS0puvaM4rQ+CZyWltjwKCiRJlAoiATD1vnwtyug73i49iWIiKp3s5oax56CUq9jO9c7o9i0r4jteYep8g+DSo6NrA2IEX0SGJGWQM/4+vcn0hCFgkiwrPknvPxVGPoFb/W2JkyHUVZZzcZ9xazNKWBNTiFrcgrZsr+4drhsanwUp6UlMKJPgvc7LZFurT3Pk4SkxoaCGjJFWtuIy+HIAXjrHnjju956z41sBoqKCGNU30RG9f1s/eojFVVs2FvkD4kC1uwp5O0NubWPpyVFMyItgdP6JDIyLYHMPgkkRDfxKm0RP4WCSCCM/zqU7If37/eu0j7vh83eVUxkOGPSuzEm/bMrvIvKKlm/p6g2JNbmFDJn7b7axzOSu3Kav8lpRFoimb3j6arObGkE/SsRCZTzfwyH82Dh/0HXHt70Ha0kPiqCCf27M6F/99r7Dh2uYO2eQtbu8c4olu08yOur9wLeicqAHrGMSEv0zirSEhjWK77la2JLyFEoiASKmdd0dOSgNyts12QY/pWAHS6paySTB3nThR+1v7iMdXu8vom1OYUs2JzHSytyAAj3GYNS4mpDYkSfRAanxhEZ3grTjEuHpY5mkUCrLIW/fgVylsI1/4T+5watlKNXadf2T+R4ZxYFR7wlTyPDfAztFceItETGpCcxNr0bvROjg1avtB6NPhJpT0oL4OkZULAL/vtf0Of0YFdUyzlHzqHSY4JiTU5B7XUUfRKjGZfRjbHp3RiXkUT/HrG6fqIDUiiItDdFn8Ksad7yojdnN3udiLZQVV3Dxn3FLNlxkKU7vZ8DJRWAd1X2mPRujEvvxtiMbmT2jm+dle0koBQKIu3Rga1eMER2hZuyIb5XsCtqFOccO/OPsHTHQZbsPMiynQfZmX8EgOiIMEb3S/SfSXRjdL9EYiLVXdneKBRE2qs9K7zpMBJPgRvnQHRiw89ph/YXlbF05yGW7jzIkh0H+WRfEc5BmM8Y3juesf4ziTGnJNE9NvBrZMjJKRRE2rNt78Lzl0PaWLjuZW8Fug6uqKySFbsO+ZubDrFqd0HtFOP9e3St7ZcYm96NtKRo9Uu0MYWCSHu37iWYfTMMngFXPAthbdjkUnEYCvdAUQ4U5nz+Ns5bJnXkVU2apqOu8qpq1uYU+pubDrFs58HaRYtS46MYm9GNcelJjM3oxqCecfi0/kRAKRREOoKPn4Q374LR18ElD7fO6nPVlVC0F4r2eB/whbvr3M7xPvxLDx33JIPYFEjoA/F9vO32roDU0yDrV5AxqcVl1dQ4NuUW1zY3Ld15kNwib1rx+Cjvqu2jI5yG90mgS3hgLqxzzlFd46iqcVRW11BV7ais8X7XvV1ZXUNNWSHd1j9LYlg5scOnQ9q4tg3vVqRQEOko3vkfWPhbmPQ97yrok6mp8eZVKtzt/3bv/6AvzPnsdvE+4Lj/11EJkNDX+8BPSPN/+Kd9djuuN4TXmVjPOe9MZt5PvWMNuRim/rxVR0wdHQpbd4TTtrzDAHQJ9zGybyIDesZSU+OorHZU1fmwrvuBXlVTU+/jJ9u2IV2o4PqwbL4R/jpJVkKV8xFuNZSFx1OZcS6xwy/CBk6FmG4N7qu9UCiIdBTOwb/vgOXPwLT/gf7nf/aNvvbbfZ3f1RXHPj88yvtwr/3AP3q7z2dB0CW2ebVVlsJHj8Ki+6GqHMbNhHPuguikFr/s+uSXlLPU39S0dOdBcg6VEh5mhPt8RIQZ4WE+wn127H0+H+FhRoT/sYgw33HPOfb5ET7/fsKMCP9za++nigF7XmXIpseIKttPfuokdoz8LitLkji05i36F3zAOb7VJFsRNfg40nM0MZkz8A3OgpThQV1nvCEKBZGOpKYaXrweNv772PstDOJ61fl27/+gT/AHQHya92010B9Gxbnw7v/Cyr96Zx1T7oUxN0FYiMzGWlMD61/2XuPB7V4z0QU/gfSJx2y2r7CMt9fvZeuqRSR/+h7n2EpG+HYAUBaTSsTgLMIGXwinnuMNO25HFAoiHU1lmffBFN7ls6ad2JT21Ya9bx3M/QHsWADdB3pnNoOy2vU35JNyDrZkw/xfQO5a79v+efc16jUVllby7sb9fLRmPeHb5jPRLWeSby1drYxqXyTulImED7kQBk6Dbhlt9IJOTKEgIoHhHGyeC9k/gvwtkHEOZP0SUocHu7Km2fUhzPsZ7P4IkjLg3B/C8EvB1/Srs8sqq/lg6wHmr93NoY0LGFOxlPPCVpJh3nTmVd0GEj44ywubfhOCcoalUBCRwKquhGWz4L1fQVkhjL4Wzv0RxKUEu7KT+3Q1zP85bJ0Hsalwzvfh9Otb7YO6usaxfNchstfvY/26FQwt/ojzwlZypm8jEVRRExmHb8D5XkAMmAqxPRreaStQKIhI2yg9BAt+C0ue8Dq9J30Xxn+j/V2Qd2ArvPs/sP4ViEr06hx7C0TGBOyQzjk27isme30ui9Zvp3vuYs71rWRqxBq6u4M4DPqcjg3MgkHTIHVks85UGkOhICJtK38bZN8Hm97wOsMv+KnXHBPs/obCHFjwG1j5vBdaE74BZ33L6zBvY7sPHuHtDblkr/+Uw7tWMMVWkhW5mky3FcPhYlO8oa4Ds7wp1rvEtdqxFQoiEhw7Fnqd0fvWetN4ZP0K+o5t+zoO53vLoS75E+C80VKTvgexPdu+lnocPFzB/E9yyd6Qy9rN2zirZgVZkauZ7FtLdE0JzheBnXKW18w0MAuSB7ToeAoFEQmemmpY/YLXdl+SC8Mv84Z4JvYL/LHLi2HxH+HDR6DyMIy8Gqbc3TbHbqYjFVUs3HyA7A37WLBhLwPKNzA1YhUzuqyhd+Uub6Nup8LZt8MZNzTrGAoFEQm+8hL44EH48GFwNTDhNq8tvxWbRWpVlsHSp7yzgyP5MPQSOO9H0GNw6x8rgCqra1i64yDZG3LJXr8PX9Fuzg9bxZe6riM88xJOu+TbzdqvQkFE2o/CHO+sYc0/oGtP78N69LXNnmzvGNVVsOp5r9+gaA+ceq43XUg7Wt2uuZxzrNtTRPaGfcxdv4/Lzkhj5uTmTTWiUBCR9idnudffsPsj70KxrP+FU6c0b181NbDhVe8q5Pyt0GeM10SVMbk1K25XqmscYc2cTbaxoaA19ESk7aSdATe9BZc/A+VF8OwX4W9XwoEtjd+Hc7DlbXjyHJh9I4RFwn+9AF+dF9KBADQ7EJoiYKFgZrPMbL+ZrTvB42ZmD5nZVjNbY2Yd/1xPRBpmBplfhtuWwgU/g50fwKPjYc734cjBkz/3Px/B0zPg+cu8C+a+/CTc+j4MmRH8oa8hIpBnCs8AF57k8enAQP/PTOCxANYiIu1NRBRMvAO+vdK7onjpn+Ch0bD4Uag6bibYfWvh+StgVhYc3AYzfgffXAYjr2ydfgmpFbCZtpxzC80s/SSbfBF41nmdGh+ZWaKZ9XLOfRqomkSkHYrtARf/wbu6OPuHMPdebxTRtF9AjyHw7i9h3WzvYrMLfupN393OZiANJcGcfrEPsLvO3zn++z4XCmY2E+9sgn792u9YYxFpgZRhcN0rXn/B3B/C36/27o+I8S46O+vbEJ0Y3Bo7gWCGQn0NgPUOhXLOPQk8Cd7oo0AWJSJBNnCqN6x05bPesqJjb2n/k+yFkGCGQg7Qt87facDeINUiIu1JWLg3LYW0uWAOSX0duN4/Cmk8UKj+BBGR4ArYmYKZvQBMAZLNLAf4CRAB4Jx7HJgDzAC2AkeAGwNVi4iINE4gRx9d1cDjDrgtUMcXEZGm0xXNIiJSS6EgIiK1FAoiIlJLoSAiIrUUCiIiUqvDradgZnnArmY+PRk40IrldHR6P46l9+Mzei+OFQrvxynOuR4NbdThQqElzGxZYxaZ6Cz0fhxL78dn9F4cqzO9H2o+EhGRWgoFERGp1dlC4clgF9DO6P04lt6Pz+i9OFaneT86VZ+CiIicXGc7UxARkZNQKIiISK1OEwpmdqGZbTKzrWZ2T7DrCSYz62tm75rZJ2a23sxuD3ZNwWZmYWa20sz+Hexags2/XvpsM9vo/zcyIdg1BYuZfcf/f2Sdmb1gZlHBrinQOkUomFkY8EdgOjAMuMrMhgW3qqCqAr7nnBsKjAdu6+TvB8DtwCfBLqKdeBB4yzk3BBhJJ31fzKwP8G1gjHNuOBAG/Fdwqwq8ThEKwDhgq3Nuu3OuAvg78MUg1xQ0zrlPnXMr/LeL8f7T9wluVcFjZmnARcBTwa4l2MwsHpgM/BnAOVfhnCsIblVBFQ5Em1k4EEMnWDK4s4RCH2B3nb9z6MQfgnWZWTowGvg4uJUE1QPA94GaYBfSDpwK5AFP+5vTnjKzrsEuKhicc3uA3wH/AT7FWzI4O7hVBV5nCQWr575OPxbXzGKBl4A7nHNFwa4nGMzsYmC/c255sGtpJ8KB04HHnHOjgcNAp+yDM7MkvBaFDKA30NXMrg1uVYHXWUIhB+hb5+80OsFp4MmYWQReIDzvnHs52PUE0dnAJWa2E69Z8Twzey64JQVVDpDjnDt65jgbLyQ6owuAHc65POdcJfAycFaQawq4zhIKS4GBZpZhZpF4nUWvB7mmoDEzw2sz/sQ5d3+w6wkm59y9zrk051w63r+Ld5xzIf9t8EScc/uA3WY22H/X+cCGIJYUTP8BxptZjP//zPl0gk738GAX0Bacc1Vm9k1gLt4IglnOufVBLiuYzgauA9aa2Sr/fT9wzs0JYk3SfnwLeN7/BWo7cGOQ6wkK59zHZjYbWIE3Ym8lnWC6C01zISIitTpL85GIiDSCQkFERGopFEREpJZCQUREaikURESklkJBpA2Z2RTNxCrtmUJBRERqKRRE6mFm15rZEjNbZWZP+NdbKDGz35vZCjObb2Y9/NuOMrOPzGyNmb3inzMHMxtgZvPMbLX/Of39u4+ts17B8/6rZUXaBYWCyHHMbChwJXC2c24UUA1cA3QFVjjnTgcWAD/xP+VZ4G7n3AhgbZ37nwf+6JwbiTdnzqf++0cDd+Ct7XEq3hXmIu1Cp5jmQqSJzgfOAJb6v8RHA/vxptb+h3+b54CXzSwBSHTOLfDf/xfgn2YWB/Rxzr0C4JwrA/Dvb4lzLsf/9yogHXg/8C9LpGEKBZHPM+Avzrl7j7nT7L7jtjvZHDEnaxIqr3O7Gv0/lHZEzUcinzcfuMzMegKYWTczOwXv/8tl/m2uBt53zhUCh8xskv/+64AF/vUpcszsS/59dDGzmDZ9FSLNoG8oIsdxzm0wsx8B2WbmAyqB2/AWnMk0s+VAIV6/A8B/A4/7P/Trzip6HfCEmf3cv4/L2/BliDSLZkkVaSQzK3HOxQa7DpFAUvORiIjU0pmCiIjU0pmCiIjUUiiIiEgthYKIiNRSKIiISC2FgoiI1Pp/Pmg9j1fz/WcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 1.0158541384655828\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "#x_train_scaled = MinMaxScaler().fit_transform(x_train[features])\n",
    "\n",
    "\n",
    "#x_reshaped = np.reshape(x_train_scaled, (x_train_scaled.shape[0], 10, x_train_scaled.shape[1]))\n",
    "    \n",
    "#x_val_scaled_reshaped = np.reshape(x_val_scaled, (x_val_scaled.shape[0], 1, x_val_scaled.shape[1]))\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0)\n",
    "]\n",
    "\n",
    "dropout=0\n",
    "\n",
    "my_model = Sequential()\n",
    "#bi directional?\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 4, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 64, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 48, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 64, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "my_model.add(BatchNormalization())\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 4, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#lstmd_dataa = np.array(np.array(lstm_data)).reshape(271148,8,51)\n",
    "#print(lstmd_dataa.shape)\n",
    "#print(lstmd_dataa)\n",
    "#lstm_yy = np.array([np.array([y]) for y in lstm_y[0:100]])\n",
    "#print(lstm_yy.shape)\n",
    "#print(lstm_yy)\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=64, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique())) & (training['item_id'].isin(test['item_id'].unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96760, 8, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n"
     ]
    }
   ],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    if index % 10000 == 0:\n",
    "        print(index)\n",
    "    line = training_test[(training_test['year'] == 2015) & (training_test['shop_id'] == row['shop_id']) & (training_test['item_id'] == row['item_id'])].sort_values(by=['date_block_num'])[features].values\n",
    "    test_lstm_data.append(line[1:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = [sample[1:9] for sample in test_lstm_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214200"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4426848],\n",
       "       [0.       ],\n",
       "       [1.1061953],\n",
       "       ...,\n",
       "       [0.8175033],\n",
       "       [0.       ],\n",
       "       [0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5007466\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3542884257097005\n",
      "16.49019305497366\n"
     ]
    }
   ],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
