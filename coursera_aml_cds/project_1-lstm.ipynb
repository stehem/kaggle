{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "items           = pd.read_csv('items.csv',usecols=[\"item_id\", \"item_category_id\"])\n",
    "item_categories = pd.read_csv('item_categories.csv')\n",
    "shops           = pd.read_csv('shops.csv')\n",
    "sales_train     = pd.read_csv('sales_train.csv.gz')\n",
    "test            = pd.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train[['day','month', 'year']] = sales_train['date'].str.split('.', expand=True).astype(int)\n",
    "#sales_train = sales_train[sales_train['year'].isin([2013,2014]) == False]\n",
    "sales_train = sales_train[sales_train['date_block_num'] > 26]\n",
    "sales_train = sales_train.set_index('item_id').join(items.set_index('item_id'))\n",
    "sales_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales=1000\n",
    "sums = sales_train.groupby('item_id')['item_cnt_day'].sum().reset_index().rename(columns={\"item_cnt_day\":\"item_total_sales\"}).sort_values(by='item_total_sales')\n",
    "\n",
    "#ids_keep = sums[(sums['item_total_sales'] > 0) & (sums['item_total_sales'] < max_sales)]['item_id'].unique()\n",
    "ids_keep = sums[(sums['item_total_sales'] > 0)]['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids = sales_train['item_id'].unique()\n",
    "#train_item_ids = np.setdiff1d(train_item_ids, ids_reject)\n",
    "#train_item_ids = ids_keep\n",
    "train_shop_ids = sales_train['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "train_blocks = sales_train['date_block_num'].unique()\n",
    "\n",
    "#all_item_ids = np.unique(np.append(test_item_ids,train_item_ids))\n",
    "all_item_ids = test_item_ids\n",
    "\n",
    "#all_shop_ids = np.unique(np.append(train_shop_ids,test_shop_ids))\n",
    "all_shop_ids = test_shop_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for dbn in range(np.min(train_blocks), np.max(train_blocks)+1):\n",
    "    sales = sales_train[sales_train.date_block_num==dbn]\n",
    "    #item_ids = np.intersect1d(sales.item_id.unique(), test_item_ids)\n",
    "    item_ids = all_item_ids\n",
    "    #dbn_combos = list(product(sales.shop_id.unique(), item_ids, [dbn]))\n",
    "    dbn_combos = list(product(all_shop_ids, item_ids, [dbn]))\n",
    "    for combo in dbn_combos:\n",
    "        combinations.append(combo)\n",
    "        \n",
    "all_combos = pd.DataFrame(np.unique(np.vstack([combinations]), axis=0), columns=['shop_id','item_id','date_block_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_item_cnt_block\"})\n",
    "\n",
    "training = all_combos.merge(ys, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "training['shop_item_cnt_block'] = training['shop_item_cnt_block'].clip(0,20).astype('int8')\n",
    "\n",
    "training = training.set_index('item_id').join(items.set_index('item_id'))\n",
    "training.reset_index(inplace=True)\n",
    "\n",
    "for col in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    training[col] = pd.to_numeric(training[col], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sales_train[['date_block_num', 'month', 'year']].drop_duplicates(['date_block_num', 'month', 'year'])\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for index,row in dates.iterrows():\n",
    "    dates_dict[row['date_block_num']] = {\"month\": row['month'], \"year\": row['year']}\n",
    "    \n",
    "training['month'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['month']), downcast='unsigned')\n",
    "training['year'] = pd.to_numeric(training['date_block_num'].apply(lambda block: dates_dict[block]['year']), downcast='unsigned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = sales_train.groupby(['item_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"item_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['item_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"category_cnt_block\"})\n",
    "\n",
    "\n",
    "training = training.merge(ys, on=['item_category_id', 'date_block_num'], how='left').fillna(0)\n",
    "\n",
    "\n",
    "ys = sales_train.groupby(['shop_id', 'item_category_id', 'date_block_num'], as_index=False)['item_cnt_day']\\\n",
    "                .sum().rename(columns={\"item_cnt_day\":\"shop_category_cnt_block\"})\n",
    "\n",
    "training = training.merge(ys, on=['shop_id', 'item_category_id', 'date_block_num'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['item_cnt_block_mean'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.mean)\n",
    "training['item_cnt_block_min'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.min)\n",
    "training['item_cnt_block_max'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.max)\n",
    "training['item_cnt_block_std'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.std)\n",
    "training['item_cnt_block_med'] = training.groupby(['date_block_num'])['item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.mean)\n",
    "training['shop_cnt_block_min'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.min)\n",
    "training['shop_cnt_block_max'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.max)\n",
    "training['shop_cnt_block_std'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.std)\n",
    "training['shop_cnt_block_med'] = training.groupby(['date_block_num'])['shop_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['category_cnt_block_mean'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.mean)\n",
    "training['category_cnt_block_min'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.min)\n",
    "training['category_cnt_block_max'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.max)\n",
    "training['category_cnt_block_std'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.std)\n",
    "training['category_cnt_block_med'] = training.groupby(['date_block_num'])['category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_category_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.mean)\n",
    "training['shop_category_cnt_block_min'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.min)\n",
    "training['shop_category_cnt_block_max'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.max)\n",
    "training['shop_category_cnt_block_std'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.std)\n",
    "training['shop_category_cnt_block_med'] = training.groupby(['date_block_num'])['shop_category_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['shop_item_cnt_block_mean'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.mean)\n",
    "training['shop_item_cnt_block_min'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.min)\n",
    "training['shop_item_cnt_block_max'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.max)\n",
    "training['shop_item_cnt_block_std'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.std)\n",
    "training['shop_item_cnt_block_med'] = training.groupby(['date_block_num'])['shop_item_cnt_block'].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n"
     ]
    }
   ],
   "source": [
    "#https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "columns = [\"item_id\", \"shop_id\", \"item_category_id\"]\n",
    "\n",
    "\n",
    "\n",
    "y_train = training[\"shop_item_cnt_block\"].values\n",
    "folds = KFold(n_splits = 5, shuffle=True).split(training)\n",
    "\n",
    "i=1\n",
    "for in_fold_index, out_of_fold_index in folds:\n",
    "    print(\"fold\", i)\n",
    "    #print(np.intersect1d(training.loc[in_fold_index][\"shop_id\"].unique(), training.loc[out_of_fold_index][\"shop_id\"].unique()))\n",
    "    #print(len(in_fold_index))\n",
    "    for column in columns:\n",
    "        means = training.iloc[in_fold_index].groupby(column)['shop_item_cnt_block'].mean()\n",
    "            #x_validation[column + \"_mean_target\"] = means\\\n",
    "        name = column + '_mean_encoding'\n",
    "        training.loc[out_of_fold_index,name] = training.loc[out_of_fold_index][column].map(means)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_cnt_block</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_cnt_block</th>\n",
       "      <th>shop_cnt_block</th>\n",
       "      <th>category_cnt_block</th>\n",
       "      <th>shop_category_cnt_block</th>\n",
       "      <th>item_cnt_block_mean</th>\n",
       "      <th>item_cnt_block_min</th>\n",
       "      <th>item_cnt_block_max</th>\n",
       "      <th>item_cnt_block_std</th>\n",
       "      <th>item_cnt_block_med</th>\n",
       "      <th>shop_cnt_block_mean</th>\n",
       "      <th>shop_cnt_block_min</th>\n",
       "      <th>shop_cnt_block_max</th>\n",
       "      <th>shop_cnt_block_std</th>\n",
       "      <th>shop_cnt_block_med</th>\n",
       "      <th>category_cnt_block_mean</th>\n",
       "      <th>category_cnt_block_min</th>\n",
       "      <th>category_cnt_block_max</th>\n",
       "      <th>category_cnt_block_std</th>\n",
       "      <th>category_cnt_block_med</th>\n",
       "      <th>shop_category_cnt_block_mean</th>\n",
       "      <th>shop_category_cnt_block_min</th>\n",
       "      <th>shop_category_cnt_block_max</th>\n",
       "      <th>shop_category_cnt_block_std</th>\n",
       "      <th>shop_category_cnt_block_med</th>\n",
       "      <th>shop_item_cnt_block_mean</th>\n",
       "      <th>shop_item_cnt_block_min</th>\n",
       "      <th>shop_item_cnt_block_max</th>\n",
       "      <th>shop_item_cnt_block_std</th>\n",
       "      <th>shop_item_cnt_block_med</th>\n",
       "      <th>item_id_mean_encoding</th>\n",
       "      <th>shop_id_mean_encoding</th>\n",
       "      <th>item_category_id_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539180</th>\n",
       "      <td>7956</td>\n",
       "      <td>57</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.625882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138748</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497482</th>\n",
       "      <td>22145</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.073360</td>\n",
       "      <td>0.179334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339784</th>\n",
       "      <td>19618</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.648627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>61.946153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1719.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.0</td>\n",
       "      <td>1596.048841</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2829.167059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>2461.715660</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>66.414052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>114.964885</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.246452</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.176103</td>\n",
       "      <td>0.179534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496800</th>\n",
       "      <td>22137</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.840196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>57.770225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1551.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>1090.984155</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>3253.890392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8513.0</td>\n",
       "      <td>2995.889840</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>75.921218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>128.648912</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.031644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.195342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140210</th>\n",
       "      <td>16153</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>0.203229</td>\n",
       "      <td>0.160670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33985</th>\n",
       "      <td>687</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.535490</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>124.515785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1711.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7341.0</td>\n",
       "      <td>1447.095173</td>\n",
       "      <td>1309.5</td>\n",
       "      <td>4010.790784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>4102.264551</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>88.694935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>195.630747</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.215145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.079221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315315</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>0.316074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482750</th>\n",
       "      <td>21948</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.808824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>53.842045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1427.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5987.0</td>\n",
       "      <td>1114.915109</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>3335.517843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9283.0</td>\n",
       "      <td>3239.632607</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>75.583501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>141.362130</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.949685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.199301</td>\n",
       "      <td>0.071690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854044</th>\n",
       "      <td>12970</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>58.426138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>1194.835848</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>3318.272157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>3228.111861</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>74.266709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>150.766699</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.221471</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.008618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.217341</td>\n",
       "      <td>0.193790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045360</th>\n",
       "      <td>15223</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.949804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>89.593827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1592.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6327.0</td>\n",
       "      <td>1311.452767</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>3428.631373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>3303.055672</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>75.539594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>147.855428</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.018289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.570411</td>\n",
       "      <td>0.248845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  shop_id  date_block_num  shop_item_cnt_block  item_category_id  month  year  item_cnt_block  shop_cnt_block  category_cnt_block  shop_category_cnt_block  item_cnt_block_mean  item_cnt_block_min  item_cnt_block_max  item_cnt_block_std  item_cnt_block_med  shop_cnt_block_mean  shop_cnt_block_min  shop_cnt_block_max  shop_cnt_block_std  shop_cnt_block_med  category_cnt_block_mean  category_cnt_block_min  category_cnt_block_max  category_cnt_block_std  category_cnt_block_med  shop_category_cnt_block_mean  shop_category_cnt_block_min  shop_category_cnt_block_max  shop_category_cnt_block_std  shop_category_cnt_block_med  shop_item_cnt_block_mean  shop_item_cnt_block_min  shop_item_cnt_block_max  shop_item_cnt_block_std  shop_item_cnt_block_med  item_id_mean_encoding  shop_id_mean_encoding  item_category_id_mean_encoding\n",
       "539180   7956     57       32              1                    6                 9      2015  9.0             2266.0          237.0               11.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.213675               0.399283               0.625882                      \n",
       "5602     83       4        29              0                    40                6      2015  0.0             793.0           9304.0              79.0                     10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.000000               0.138748               0.196160                      \n",
       "1497482  22145    34       27              0                    37                4      2015  0.0             424.0           4670.0              38.0                     12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.043290               0.073360               0.179334                      \n",
       "1339784  19618    5        32              0                    37                9      2015  7.0             1092.0          2989.0              52.0                     11.648627            0.0                 3390.0              61.946153           3.0                 1719.523810          0.0                 6867.0              1596.048841         1230.0              2829.167059              0.0                     7107.0                  2461.715660             1670.0                  66.414052                     0.0                          1079.0                       114.964885                   29.0                         0.246452                  0                        20                       1.115817                 0                        0.105042               0.176103               0.179534                      \n",
       "1496800  22137    10       31              0                    40                8      2015  0.0             442.0           8513.0              59.0                     11.840196           -1.0                 3551.0              57.770225           3.0                 1551.500000          0.0                 5714.0              1090.984155         1271.0              3253.890392              0.0                     8513.0                  2995.889840             1788.0                  75.921218                     0.0                          1189.0                       128.648912                   32.0                         0.260037                  0                        20                       1.031644                 0                        0.000000               0.078812               0.195342                      \n",
       "1140210  16153    18       28              0                    64                5      2015  13.0            1434.0          906.0               10.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.296460               0.203229               0.160670                      \n",
       "33985    687      39       27              0                    73                4      2015  18.0            754.0           380.0               1.0                      12.535490           -1.0                 7300.0              124.515785          2.0                 1711.166667          0.0                 7341.0              1447.095173         1309.5              4010.790784              0.0                     14751.0                 4102.264551             2285.0                  88.694935                    -1.0                          2506.0                       195.630747                   26.0                         0.215145                  0                        20                       1.079221                 0                        0.315315               0.120108               0.316074                      \n",
       "1482750  21948    24       30              0                    61                7      2015  0.0             1014.0          516.0               0.0                      10.808824           -1.0                 3347.0              53.842045           3.0                 1427.642857          0.0                 5987.0              1114.915109         1108.0              3335.517843              0.0                     9283.0                  3239.632607             1890.0                  75.583501                    -1.0                          1475.0                       141.362130                   32.0                         0.227605                  0                        20                       0.949685                 0                        0.004292               0.199301               0.071690                      \n",
       "854044   12970    56       29              1                    55                6      2015  10.0            1566.0          6017.0              147.0                    10.833333           -1.0                 3473.0              58.426138           2.0                 1430.904762          0.0                 6160.0              1194.835848         1058.0              3318.272157              0.0                     9304.0                  3228.111861             1919.0                  74.266709                     0.0                          1529.0                       150.766699                   29.0                         0.221471                  0                        20                       1.008618                 0                        0.334764               0.217341               0.193790                      \n",
       "1045360  15223    42       28              0                    63                5      2015  6.0             4343.0          1370.0              75.0                     11.949804            0.0                 3768.0              89.593827           2.0                 1592.166667          0.0                 6327.0              1311.452767         1211.5              3428.631373              0.0                     9208.0                  3303.055672             1635.0                  75.539594                    -1.0                          2005.0                       147.855428                   26.0                         0.213301                  0                        20                       1.018289                 0                        0.086420               0.570411               0.248845                      "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "training.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'shop_id', 'date_block_num', 'shop_item_cnt_block',\n",
       "       'item_category_id', 'month', 'year', 'item_cnt_block',\n",
       "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
       "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
       "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
       "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
       "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
       "       'category_cnt_block_min', 'category_cnt_block_max',\n",
       "       'category_cnt_block_std', 'category_cnt_block_med',\n",
       "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
       "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
       "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
       "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
       "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
       "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
       "       'item_category_id_mean_encoding'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \n",
    "    'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "       'item_cnt_block_mean', 'item_cnt_block_min', 'item_cnt_block_max',\n",
    "       'item_cnt_block_std', 'item_cnt_block_med', 'shop_cnt_block_mean',\n",
    "       'shop_cnt_block_min', 'shop_cnt_block_max', 'shop_cnt_block_std',\n",
    "       'shop_cnt_block_med', 'category_cnt_block_mean',\n",
    "       'category_cnt_block_min', 'category_cnt_block_max',\n",
    "       'category_cnt_block_std', 'category_cnt_block_med',\n",
    "       'shop_category_cnt_block_mean', 'shop_category_cnt_block_min',\n",
    "       'shop_category_cnt_block_max', 'shop_category_cnt_block_std',\n",
    "       'shop_category_cnt_block_med', 'shop_item_cnt_block_mean',\n",
    "       'shop_item_cnt_block_min', 'shop_item_cnt_block_max',\n",
    "       'shop_item_cnt_block_std', 'shop_item_cnt_block_med',\n",
    "       'item_id_mean_encoding', 'shop_id_mean_encoding',\n",
    "       'item_category_id_mean_encoding'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    \n",
    "     'item_cnt_block',\n",
    "       'shop_cnt_block', 'category_cnt_block', 'shop_category_cnt_block',\n",
    "      \n",
    "    \n",
    "]\n",
    "\n",
    "#features = all_features\n",
    "\n",
    "#features = ['pca0', 'pca1', 'pca2', 'pca3',  'pca4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "training[all_features] = StandardScaler().fit_transform(training[all_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[all_features] = training[all_features].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3478112  0.18928401 0.10767918 0.08343084 0.07857975]\n",
      "0.8067849771669491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5).fit(training[features])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "training_pca = pca.transform(training[features])\n",
    "\n",
    "for i,component in enumerate(pca.explained_variance_ratio_):\n",
    "    name = 'pca%d' % (i)\n",
    "    training[name] = np.array(training_pca).T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 28, 29, 30, 31, 32, 33]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "dbns = sorted(training.date_block_num.unique())\n",
    "\n",
    "windows = []\n",
    "for i,_ in enumerate(dbns):\n",
    "    if (i+window_size) <= len(dbns):\n",
    "        window = dbns[i:i+window_size]\n",
    "        windows.append(window)  \n",
    " \n",
    "windows = [list(range(27,34))]\n",
    "\n",
    "print(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_block',\n",
       " 'shop_cnt_block',\n",
       " 'category_cnt_block',\n",
       " 'shop_category_cnt_block']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "        \n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_sample\n",
    "importlib.reload(build_sample)\n",
    "\n",
    "from build_sample import build_sample_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_sample_f,args=[window, training, features]) for window in windows]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "lstm_data = []\n",
    "lstm_y = []\n",
    "\n",
    "for result in res:\n",
    "    for idx, sample in enumerate(result.get()[0]):\n",
    "        lstm_data.append(sample)\n",
    "        lstm_y.append(result.get()[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data)\n",
    "small_y = np.array(lstm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632988\n",
      "601517\n"
     ]
    }
   ],
   "source": [
    "print(len(lstm_y))\n",
    "\n",
    "print(len([y for y in lstm_y if y == 0]))\n",
    "\n",
    "zeros_indices = {}\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    \n",
    "    if y == 0:\n",
    "        zeros_indices[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data_no_zeros = []\n",
    "lstm_y_no_zeros = []\n",
    "for idx,sample in enumerate(lstm_data):\n",
    "    if idx not in zeros_indices:\n",
    "        lstm_data_no_zeros.append(sample)\n",
    "        lstm_y_no_zeros.append(lstm_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_zeros = []\n",
    "for idx,y in enumerate(lstm_y):\n",
    "    if idx in zeros_indices:\n",
    "        lstm_zeros.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_data_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(lstm_data_no_zeros))\n",
    "\n",
    "for zero_idx in np.random.choice(lstm_zeros,30000,replace=False):\n",
    "    lstm_data_no_zeros.append(lstm_data[zero_idx])\n",
    "    lstm_y_no_zeros.append(lstm_y[zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = np.array(lstm_data_no_zeros)\n",
    "small_y = np.array(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(small_data, small_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lstm_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192780, 6, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55323, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lstm_y_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_no_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 192780 samples, validate on 21420 samples\n",
      "Epoch 1/100\n",
      "192780/192780 [==============================] - 75s 387us/step - loss: 0.9899 - mean_squared_error: 0.9899 - val_loss: 0.9470 - val_mean_squared_error: 0.9470\n",
      "Epoch 2/100\n",
      "192780/192780 [==============================] - 65s 335us/step - loss: 0.8909 - mean_squared_error: 0.8909 - val_loss: 0.9115 - val_mean_squared_error: 0.9115\n",
      "Epoch 3/100\n",
      "192780/192780 [==============================] - 69s 360us/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8845 - val_mean_squared_error: 0.8845\n",
      "Epoch 4/100\n",
      "192780/192780 [==============================] - 72s 373us/step - loss: 0.8369 - mean_squared_error: 0.8369 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
      "Epoch 5/100\n",
      "192780/192780 [==============================] - 70s 361us/step - loss: 0.8216 - mean_squared_error: 0.8216 - val_loss: 0.8573 - val_mean_squared_error: 0.8573\n",
      "Epoch 6/100\n",
      "192780/192780 [==============================] - 73s 379us/step - loss: 0.8093 - mean_squared_error: 0.8093 - val_loss: 0.8481 - val_mean_squared_error: 0.8481\n",
      "Epoch 7/100\n",
      "192780/192780 [==============================] - 70s 361us/step - loss: 0.8008 - mean_squared_error: 0.8008 - val_loss: 0.8433 - val_mean_squared_error: 0.8433\n",
      "Epoch 8/100\n",
      "192780/192780 [==============================] - 78s 404us/step - loss: 0.7945 - mean_squared_error: 0.7945 - val_loss: 0.8370 - val_mean_squared_error: 0.8370\n",
      "Epoch 9/100\n",
      "192780/192780 [==============================] - 80s 413us/step - loss: 0.7899 - mean_squared_error: 0.7899 - val_loss: 0.8282 - val_mean_squared_error: 0.8282\n",
      "Epoch 10/100\n",
      "192780/192780 [==============================] - 74s 386us/step - loss: 0.7830 - mean_squared_error: 0.7830 - val_loss: 0.8229 - val_mean_squared_error: 0.8229\n",
      "Epoch 11/100\n",
      "192780/192780 [==============================] - 97s 503us/step - loss: 0.7790 - mean_squared_error: 0.7790 - val_loss: 0.8535 - val_mean_squared_error: 0.8535\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse val: 0.9238293722753348\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_train_scaled = MinMaxScaler().fit_transform(x_train[features])\n",
    "\n",
    "\n",
    "#x_reshaped = np.reshape(x_train_scaled, (x_train_scaled.shape[0], 10, x_train_scaled.shape[1]))\n",
    "    \n",
    "#x_val_scaled_reshaped = np.reshape(x_val_scaled, (x_val_scaled.shape[0], 1, x_val_scaled.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dropout=0\n",
    "\n",
    "my_model = Sequential()\n",
    "#bi directional?\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(CuDNNLSTM(units = 32,\\\n",
    "                 #input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(GRU(use_bias = True,units = 8, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 3, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(CuDNNLSTM(units = 8,input_shape = (small_data.shape[1],len(features)), return_sequences=True))\n",
    "#my_model.add(CuDNNLSTM(units = 16,input_shape = (small_data.shape[1],len(features))))\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "#my_model.add(LSTM(use_bias = True,unit_forget_bias=True,units = 4, dropout=dropout,recurrent_dropout=dropout,input_shape = (small_data.shape[1],len(features))))\n",
    "#my_model.add(Dropout(dropout))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#lstmd_dataa = np.array(np.array(lstm_data)).reshape(271148,8,51)\n",
    "#print(lstmd_dataa.shape)\n",
    "#print(lstmd_dataa)\n",
    "#lstm_yy = np.array([np.array([y]) for y in lstm_y[0:100]])\n",
    "#print(lstm_yy.shape)\n",
    "#print(lstm_yy)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0)\n",
    "]\n",
    "\n",
    "history = my_model.fit(train_data, y_train, batch_size=32, epochs=100,\n",
    "                      validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = training[(training['shop_id'].isin(test['shop_id'].unique()))\\\n",
    "                         & (training['item_id'].isin(test['item_id'].unique())) \\\n",
    "                        & (training['date_block_num'].isin(windows[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21420),\n",
       " (21420, 42840),\n",
       " (42840, 64260),\n",
       " (64260, 85680),\n",
       " (85680, 107100),\n",
       " (107100, 128520),\n",
       " (128520, 149940),\n",
       " (149940, 171360),\n",
       " (171360, 192780),\n",
       " (192780, 214200)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0, 235620, 21420))\n",
    "b = list(range(21420, 257040, 21420))\n",
    "intervals = list(zip(a,b))[:-1]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21420)\n",
      "(21420, 42840)\n",
      "(42840, 64260)\n",
      "(64260, 85680)\n",
      "(85680, 107100)\n",
      "(107100, 128520)\n",
      "(128520, 149940)\n",
      "(149940, 171360)\n",
      "(171360, 192780)\n",
      "(192780, 214200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import importlib\n",
    "import build_test\n",
    "importlib.reload(build_test)\n",
    "\n",
    "window_size = len(windows[0])\n",
    "\n",
    "from build_test import build_test_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_test_f,args=[interval, test, training_test, features, window_size]) for interval in intervals]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = []\n",
    "\n",
    "for interval in intervals:\n",
    "    for re in res:\n",
    "        if interval in re.get():\n",
    "            for sample in re.get()[interval]:\n",
    "                test_lstm_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_data = np.array(test_lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 6, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lstm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74331474],\n",
       "       [0.14329466],\n",
       "       [0.9498613 ],\n",
       "       ...,\n",
       "       [0.14786017],\n",
       "       [0.13979822],\n",
       "       [0.07430372]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model.predict(np.array(test_lstm_data),batch_size=len(test_lstm_data))\n",
    "preds.clip(0,20,out=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2769023\n",
      "14.779468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpreds = pd.read_csv('submissionbest.csv')['item_cnt_month']\n",
    "print(np.mean(bestpreds))\n",
    "print(np.max(bestpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = pd.read_csv('lr110.csv')['item_cnt_month']\n",
    "lg_preds = pd.read_csv('lg110.csv')['item_cnt_month']\n",
    "#cb_preds = pd.read_csv('cb102.csv')['item_cnt_month']\n",
    "\n",
    "\n",
    "#preds = np.mean(np.array([lr_preds, lg_preds]),axis=0)\n",
    "\n",
    "preds = (lg_preds * 0.50) + (lr_preds * 0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
