{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.576407</td>\n",
       "      <td>2.191111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.818333</td>\n",
       "      <td>0.011250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-321.000000</td>\n",
       "      <td>2.171697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.181298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.190899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.200499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>382.000000</td>\n",
       "      <td>2.211096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acoustic_data  time_to_failure\n",
       "count  150000.000000    150000.000000\n",
       "mean        4.576407         2.191111\n",
       "std        11.818333         0.011250\n",
       "min      -321.000000         2.171697\n",
       "25%         2.000000         2.181298\n",
       "50%         5.000000         2.190899\n",
       "75%         7.000000         2.200499\n",
       "max       382.000000         2.211096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'train/%s' % (np.random.choice(splits))\n",
    "#\n",
    "columns = ['acoustic_data','time_to_failure']\n",
    "df = pd.read_csv(path, float_precision='round_trip', header=None)\n",
    "df.columns = columns\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS=150\n",
    "\n",
    "import build_segment\n",
    "importlib.reload(build_segment)\n",
    "\n",
    "from build_segment import build_segment_f\n",
    "\n",
    "split_chunks = np.array_split(splits,mp.cpu_count())\n",
    "\n",
    "param_test = False\n",
    "param_augment = False\n",
    "param_scale = True\n",
    "param_noise = 0.5\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS,param_test,param_augment,\n",
    "                                                  param_scale,param_noise]) for chunk in split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>abs</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>sum</th>\n",
       "      <th>uniq</th>\n",
       "      <th>pos</th>\n",
       "      <th>negs</th>\n",
       "      <th>ssum</th>\n",
       "      <th>imax</th>\n",
       "      <th>imin</th>\n",
       "      <th>abs_nrg</th>\n",
       "      <th>abs_sum_chg</th>\n",
       "      <th>autocorr_10</th>\n",
       "      <th>cid_ce</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean_chg</th>\n",
       "      <th>reocurring_pct</th>\n",
       "      <th>r_sigma</th>\n",
       "      <th>ratio_to_length</th>\n",
       "      <th>skewness</th>\n",
       "      <th>strike_below</th>\n",
       "      <th>strike_above</th>\n",
       "      <th>last_loc_max</th>\n",
       "      <th>first_loc_max</th>\n",
       "      <th>last_loc_min</th>\n",
       "      <th>first_loc_min</th>\n",
       "      <th>perc_reocurr_dp</th>\n",
       "      <th>perc_reocurr_all</th>\n",
       "      <th>sum_reoccurr_val</th>\n",
       "      <th>sum_reoccurr_dp</th>\n",
       "      <th>ratio_value_number</th>\n",
       "      <th>peaks</th>\n",
       "      <th>mean_head</th>\n",
       "      <th>mean_tail</th>\n",
       "      <th>abs_diff_head_tail</th>\n",
       "      <th>pos_head</th>\n",
       "      <th>neg_head</th>\n",
       "      <th>pos_tail</th>\n",
       "      <th>neg_tail</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>augmented</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.312871</td>\n",
       "      <td>-0.055498</td>\n",
       "      <td>0.098801</td>\n",
       "      <td>0.193184</td>\n",
       "      <td>-0.390512</td>\n",
       "      <td>0.298210</td>\n",
       "      <td>0.778053</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.220049</td>\n",
       "      <td>-0.536560</td>\n",
       "      <td>0.510463</td>\n",
       "      <td>0.074175</td>\n",
       "      <td>-0.539278</td>\n",
       "      <td>-0.599953</td>\n",
       "      <td>-0.061198</td>\n",
       "      <td>0.161554</td>\n",
       "      <td>-1.175285</td>\n",
       "      <td>-0.670582</td>\n",
       "      <td>0.200644</td>\n",
       "      <td>0.897364</td>\n",
       "      <td>-1.153674</td>\n",
       "      <td>0.248994</td>\n",
       "      <td>0.220049</td>\n",
       "      <td>-0.338520</td>\n",
       "      <td>-1.056704</td>\n",
       "      <td>-0.188552</td>\n",
       "      <td>-0.798443</td>\n",
       "      <td>-0.539278</td>\n",
       "      <td>-0.584208</td>\n",
       "      <td>-0.599953</td>\n",
       "      <td>-1.153674</td>\n",
       "      <td>-0.479786</td>\n",
       "      <td>-0.141337</td>\n",
       "      <td>0.395077</td>\n",
       "      <td>0.220049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.193184</td>\n",
       "      <td>-0.536560</td>\n",
       "      <td>0.510463</td>\n",
       "      <td>-0.536560</td>\n",
       "      <td>0.510463</td>\n",
       "      <td>5.3051</td>\n",
       "      <td>False</td>\n",
       "      <td>xzafi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262267</td>\n",
       "      <td>-0.185507</td>\n",
       "      <td>0.493387</td>\n",
       "      <td>-0.297918</td>\n",
       "      <td>-0.336894</td>\n",
       "      <td>-0.390512</td>\n",
       "      <td>0.298210</td>\n",
       "      <td>-0.297596</td>\n",
       "      <td>0.262267</td>\n",
       "      <td>-0.334179</td>\n",
       "      <td>0.309632</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>-0.323254</td>\n",
       "      <td>-0.221413</td>\n",
       "      <td>-0.583031</td>\n",
       "      <td>-0.273281</td>\n",
       "      <td>-0.485691</td>\n",
       "      <td>0.079219</td>\n",
       "      <td>-0.018586</td>\n",
       "      <td>-0.412550</td>\n",
       "      <td>-0.753101</td>\n",
       "      <td>1.204422</td>\n",
       "      <td>-1.319470</td>\n",
       "      <td>-0.334179</td>\n",
       "      <td>1.422779</td>\n",
       "      <td>-0.022972</td>\n",
       "      <td>0.144187</td>\n",
       "      <td>-0.490078</td>\n",
       "      <td>-0.221413</td>\n",
       "      <td>-0.826781</td>\n",
       "      <td>-0.583031</td>\n",
       "      <td>1.204422</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.259228</td>\n",
       "      <td>-0.334179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262267</td>\n",
       "      <td>0.262267</td>\n",
       "      <td>-0.336894</td>\n",
       "      <td>0.309632</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>0.309632</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>5.3051</td>\n",
       "      <td>False</td>\n",
       "      <td>xzafi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.427991</td>\n",
       "      <td>-0.517759</td>\n",
       "      <td>0.493387</td>\n",
       "      <td>-0.611109</td>\n",
       "      <td>-0.513587</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.298210</td>\n",
       "      <td>-0.297596</td>\n",
       "      <td>-0.427991</td>\n",
       "      <td>-0.580503</td>\n",
       "      <td>0.884404</td>\n",
       "      <td>-0.778247</td>\n",
       "      <td>-0.543669</td>\n",
       "      <td>-0.411476</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>-0.428262</td>\n",
       "      <td>-0.376485</td>\n",
       "      <td>1.109564</td>\n",
       "      <td>1.178031</td>\n",
       "      <td>-0.443984</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.668941</td>\n",
       "      <td>-0.829325</td>\n",
       "      <td>-0.580503</td>\n",
       "      <td>-0.702797</td>\n",
       "      <td>-0.712126</td>\n",
       "      <td>-0.188552</td>\n",
       "      <td>-0.674461</td>\n",
       "      <td>-0.411476</td>\n",
       "      <td>-0.446531</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>-0.668941</td>\n",
       "      <td>0.188646</td>\n",
       "      <td>-0.704807</td>\n",
       "      <td>-0.361145</td>\n",
       "      <td>-0.580503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.427991</td>\n",
       "      <td>-0.427991</td>\n",
       "      <td>-0.513587</td>\n",
       "      <td>0.884404</td>\n",
       "      <td>-0.778247</td>\n",
       "      <td>0.884404</td>\n",
       "      <td>-0.778247</td>\n",
       "      <td>5.3051</td>\n",
       "      <td>False</td>\n",
       "      <td>xzafi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.349237</td>\n",
       "      <td>3.635390</td>\n",
       "      <td>-2.708446</td>\n",
       "      <td>4.108911</td>\n",
       "      <td>3.241132</td>\n",
       "      <td>-5.620581</td>\n",
       "      <td>-2.896897</td>\n",
       "      <td>4.004999</td>\n",
       "      <td>-0.349237</td>\n",
       "      <td>3.545422</td>\n",
       "      <td>-3.570079</td>\n",
       "      <td>3.857762</td>\n",
       "      <td>4.645036</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>-0.044921</td>\n",
       "      <td>4.415237</td>\n",
       "      <td>4.686936</td>\n",
       "      <td>-1.662705</td>\n",
       "      <td>-2.293637</td>\n",
       "      <td>0.678757</td>\n",
       "      <td>0.713979</td>\n",
       "      <td>-0.749104</td>\n",
       "      <td>1.719428</td>\n",
       "      <td>3.545422</td>\n",
       "      <td>1.588347</td>\n",
       "      <td>2.733647</td>\n",
       "      <td>1.142401</td>\n",
       "      <td>-0.184892</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>-0.308855</td>\n",
       "      <td>-0.044921</td>\n",
       "      <td>-0.749104</td>\n",
       "      <td>-2.262272</td>\n",
       "      <td>2.816881</td>\n",
       "      <td>-1.235101</td>\n",
       "      <td>3.545422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.349237</td>\n",
       "      <td>-0.349237</td>\n",
       "      <td>3.241132</td>\n",
       "      <td>-3.570079</td>\n",
       "      <td>3.857762</td>\n",
       "      <td>-3.570079</td>\n",
       "      <td>3.857762</td>\n",
       "      <td>5.3051</td>\n",
       "      <td>False</td>\n",
       "      <td>xzafi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.141820</td>\n",
       "      <td>-0.185507</td>\n",
       "      <td>0.127463</td>\n",
       "      <td>0.021634</td>\n",
       "      <td>-0.160201</td>\n",
       "      <td>-0.390512</td>\n",
       "      <td>0.298210</td>\n",
       "      <td>0.778053</td>\n",
       "      <td>0.141820</td>\n",
       "      <td>-0.211018</td>\n",
       "      <td>-0.440765</td>\n",
       "      <td>0.309625</td>\n",
       "      <td>-0.069648</td>\n",
       "      <td>-0.457354</td>\n",
       "      <td>-1.050069</td>\n",
       "      <td>-0.129520</td>\n",
       "      <td>0.201507</td>\n",
       "      <td>-0.798250</td>\n",
       "      <td>-0.491384</td>\n",
       "      <td>-0.352175</td>\n",
       "      <td>0.713979</td>\n",
       "      <td>1.261373</td>\n",
       "      <td>-0.731296</td>\n",
       "      <td>-0.211018</td>\n",
       "      <td>-0.821779</td>\n",
       "      <td>0.666183</td>\n",
       "      <td>1.475139</td>\n",
       "      <td>-0.718967</td>\n",
       "      <td>-0.457354</td>\n",
       "      <td>-0.489146</td>\n",
       "      <td>-1.050069</td>\n",
       "      <td>1.261373</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>-0.239944</td>\n",
       "      <td>0.141493</td>\n",
       "      <td>-0.211018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141820</td>\n",
       "      <td>0.141820</td>\n",
       "      <td>-0.160201</td>\n",
       "      <td>-0.440765</td>\n",
       "      <td>0.309625</td>\n",
       "      <td>-0.440765</td>\n",
       "      <td>0.309625</td>\n",
       "      <td>5.3051</td>\n",
       "      <td>False</td>\n",
       "      <td>xzafi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean       max       min       std       abs       q25       q50       q75       sum      uniq       pos      negs      ssum      imax      imin   abs_nrg  abs_sum_chg  autocorr_10    cid_ce  kurtosis  mean_chg  reocurring_pct   r_sigma  ratio_to_length  skewness  strike_below  strike_above  last_loc_max  first_loc_max  last_loc_min  first_loc_min  perc_reocurr_dp  perc_reocurr_all  sum_reoccurr_val  sum_reoccurr_dp  ratio_value_number  peaks  mean_head  mean_tail  abs_diff_head_tail  pos_head  neg_head  pos_tail  neg_tail  time_to_failure  augmented segment\n",
       "0  0.646774  0.312871 -0.055498  0.098801  0.193184 -0.390512  0.298210  0.778053  0.646774  0.220049 -0.536560  0.510463  0.074175 -0.539278 -0.599953 -0.061198  0.161554    -1.175285    -0.670582  0.200644  0.897364 -1.153674        0.248994  0.220049        -0.338520 -1.056704     -0.188552     -0.798443     -0.539278      -0.584208     -0.599953      -1.153674        -0.479786         -0.141337          0.395077         0.220049            0.0    0.646774   0.646774   0.193184           -0.536560  0.510463 -0.536560  0.510463  5.3051           False      xzafi \n",
       "1  0.262267 -0.185507  0.493387 -0.297918 -0.336894 -0.390512  0.298210 -0.297596  0.262267 -0.334179  0.309632 -0.259416 -0.323254 -0.221413 -0.583031 -0.273281 -0.485691     0.079219    -0.018586 -0.412550 -0.753101  1.204422       -1.319470 -0.334179         1.422779 -0.022972      0.144187     -0.490078     -0.221413      -0.826781     -0.583031       1.204422         0.634268          0.013617          0.259228        -0.334179            0.0    0.262267   0.262267  -0.336894            0.309632 -0.259416  0.309632 -0.259416  5.3051           False      xzafi \n",
       "2 -0.427991 -0.517759  0.493387 -0.611109 -0.513587  0.655502  0.298210 -0.297596 -0.427991 -0.580503  0.884404 -0.778247 -0.543669 -0.411476 -0.187064 -0.428262 -0.376485     1.109564     1.178031 -0.443984 -0.202946 -0.668941       -0.829325 -0.580503        -0.702797 -0.712126     -0.188552     -0.674461     -0.411476      -0.446531     -0.187064      -0.668941         0.188646         -0.704807         -0.361145        -0.580503            0.0   -0.427991  -0.427991  -0.513587            0.884404 -0.778247  0.884404 -0.778247  5.3051           False      xzafi \n",
       "3 -0.349237  3.635390 -2.708446  4.108911  3.241132 -5.620581 -2.896897  4.004999 -0.349237  3.545422 -3.570079  3.857762  4.645036  0.093175 -0.044921  4.415237  4.686936    -1.662705    -2.293637  0.678757  0.713979 -0.749104        1.719428  3.545422         1.588347  2.733647      1.142401     -0.184892      0.093175      -0.308855     -0.044921      -0.749104        -2.262272          2.816881         -1.235101         3.545422            0.0   -0.349237  -0.349237   3.241132           -3.570079  3.857762 -3.570079  3.857762  5.3051           False      xzafi \n",
       "4  0.141820 -0.185507  0.127463  0.021634 -0.160201 -0.390512  0.298210  0.778053  0.141820 -0.211018 -0.440765  0.309625 -0.069648 -0.457354 -1.050069 -0.129520  0.201507    -0.798250    -0.491384 -0.352175  0.713979  1.261373       -0.731296 -0.211018        -0.821779  0.666183      1.475139     -0.718967     -0.457354      -0.489146     -1.050069       1.261373         0.634268         -0.239944          0.141493        -0.211018            0.0    0.141820   0.141820  -0.160201           -0.440765  0.309625 -0.440765  0.309625  5.3051           False      xzafi "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "res[0].get()[100].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "shared_train_data = pickle.load(open(\"shared_train_data.pickle\", \"rb\"))\n",
    "shared_val_data = pickle.load(open(\"shared_val_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_FEATURES=len(res[0].get()[0].drop(['time_to_failure','segment'], axis=1).columns)\n",
    "\n",
    "#training = np.empty((len(splits),TIMESTEPS,NUMBER_OF_FEATURES),dtype=float)\n",
    "#targets = np.empty((len(splits),1),dtype=float)\n",
    "# train_data = np.empty((len(shared_train_data),TIMESTEPS,NUMBER_OF_FEATURES),dtype=float)\n",
    "# y_train = np.empty((len(shared_train_data),1),dtype=float)\n",
    "# val_data = np.empty((len(shared_val_data),TIMESTEPS,NUMBER_OF_FEATURES),dtype=float)\n",
    "# y_val = np.empty((len(shared_val_data),1),dtype=float)\n",
    "train_data = []\n",
    "y_train = []\n",
    "val_data = []\n",
    "y_val = []\n",
    "\n",
    "\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        if df['segment'].unique() in shared_train_data:\n",
    "            train_data.append(df.drop(['time_to_failure','segment'], axis=1).values)\n",
    "            y_train.append(np.array([df['time_to_failure'].unique()]))\n",
    "        elif df['segment'].unique() in shared_val_data: \n",
    "            val_data.append(df.drop(['time_to_failure','segment'], axis=1).values)\n",
    "            y_val.append(np.array([df['time_to_failure'].unique()]))\n",
    "            \n",
    "train_data = np.array(train_data).reshape((len(shared_train_data),TIMESTEPS,NUMBER_OF_FEATURES))\n",
    "y_train = np.array(y_train).reshape((len(shared_train_data),1))\n",
    "val_data = np.array(val_data).reshape((len(shared_val_data),TIMESTEPS,NUMBER_OF_FEATURES))\n",
    "y_val = np.array(y_val).reshape((len(shared_val_data),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 8)                 1296      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,305\n",
      "Trainable params: 1,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#train_data, val_data, y_train, y_val = train_test_split(training, targets, test_size=0.1, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU#,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "dropout=0.2\n",
    "BATCH_SIZE=128\n",
    "\n",
    "\n",
    "my_model = Sequential()\n",
    "\n",
    "\n",
    "my_model.add(GRU(use_bias = True,#unit_forget_bias=True,\\\n",
    "                  units = 8,\\\n",
    "                  input_shape=(TIMESTEPS, NUMBER_OF_FEATURES),\n",
    "                  dropout=dropout,recurrent_dropout=dropout,\n",
    "                  #return_sequences=True\n",
    "                  ))\n",
    "\n",
    "#my_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "                 \n",
    "                    \n",
    "#my_model.add(Dense(8))\n",
    "#my_model.add(BatchNormalization())\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mae',optimizer = 'adam', metrics = ['mean_absolute_error'])\n",
    "my_model.summary()\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "filepath=\"lstm.weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    #EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "\n",
    "my_model.load_weights('lstm.weights.393-2.15.hdf5')\n",
    "\n",
    "# history = my_model.fit(train_data, y_train, batch_size=BATCH_SIZE, epochs=2000, shuffle=True,\n",
    "#                       validation_data=(val_data,y_val), callbacks=callbacks\n",
    "#                     )\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "#import math\n",
    "#print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns=res[0].get()[0].columns.values\n",
    "\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "i=0\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        data = data.append(df)\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6750 into shape (1,150,44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-47ca673cd7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6750 into shape (1,150,44)"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "grouped = data[data['segment'].isin(shared_val_data)]\\\n",
    "        .drop(['time_to_failure'], axis=1)\\\n",
    "        .sort_values(by='segment').groupby('segment')\n",
    "\n",
    "\n",
    "for name, group in grouped:\n",
    "    preds.append(my_model.predict(group.drop(['segment'], axis=1).values.reshape(1,TIMESTEPS,NUMBER_OF_FEATURES))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(preds, open( \"stacked_lstm_val.pickle\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLITS='test'\n",
    "test_splits = [f for f in listdir(TEST_SPLITS) if isfile(join(TEST_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "test_split_chunks = np.array_split(test_splits,mp.cpu_count())\n",
    "\n",
    "import build_segment\n",
    "importlib.reload(build_segment)\n",
    "\n",
    "from build_segment import build_segment_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    test_res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS, True]) \\\n",
    "           for chunk in test_split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(150, 44)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6600 into shape (1,newaxis,45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-54bdcc906cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seg_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUMBER_OF_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6600 into shape (1,newaxis,45)"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "preds = []\n",
    "i=0\n",
    "for r in test_res:\n",
    "    for df in r.get():\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        #training[i] = df.loc[:,df.columns != 'time_to_failure']\n",
    "        ids.append(df['seg_id'].unique()[0].split(\".\")[0])\n",
    "        test_df = df.drop('seg_id', axis=1)\n",
    "        print(test_df.values.shape)\n",
    "        preds.append(my_model.predict(test_df.values.reshape(1,-1,NUMBER_OF_FEATURES))[0][0])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean     5.234952   \n",
       "std      2.658105   \n",
       "min     -0.397661   \n",
       "25%      2.985751   \n",
       "50%      4.613823   \n",
       "75%      7.828412   \n",
       "max      10.344594  \n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean     5.322992   \n",
       "std      2.626039   \n",
       "min     -0.497457   \n",
       "25%      3.176856   \n",
       "50%      4.755400   \n",
       "75%      7.700604   \n",
       "max      10.682412  \n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res[0].get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test/%s' % (np.random.choice(test_splits))\n",
    "#\n",
    "\n",
    "df = pd.read_csv(path, float_precision='round_trip', header=[0])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
