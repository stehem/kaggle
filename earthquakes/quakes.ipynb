{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splits[0:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xzauf',\n",
       " 'xzdkn',\n",
       " 'xzaak',\n",
       " 'xzbgq',\n",
       " 'xzcuo',\n",
       " 'xzcwy',\n",
       " 'xzcky',\n",
       " 'xzehm',\n",
       " 'xzaqi',\n",
       " 'xzayj',\n",
       " 'xzdlo',\n",
       " 'xzehs',\n",
       " 'xtw',\n",
       " 'xzdew',\n",
       " 'xzaqr',\n",
       " 'xzbbo',\n",
       " 'xet',\n",
       " 'xzecc',\n",
       " 'xzcuw',\n",
       " 'xtp',\n",
       " 'xzdfm',\n",
       " 'xzcsn',\n",
       " 'xzfbf',\n",
       " 'xzbvv',\n",
       " 'xzbmr',\n",
       " 'xzeeb',\n",
       " 'xzdrk',\n",
       " 'xdy',\n",
       " 'xzbci',\n",
       " 'xra',\n",
       " 'xxj',\n",
       " 'xzffy',\n",
       " 'xzagu',\n",
       " 'xzamy',\n",
       " 'xzczg',\n",
       " 'xzdwm',\n",
       " 'xjv',\n",
       " 'xlu',\n",
       " 'xft',\n",
       " 'xzdif',\n",
       " 'xzdpw',\n",
       " 'xzbun',\n",
       " 'xzaqh',\n",
       " 'xzfap',\n",
       " 'xzadw',\n",
       " 'xzcqg',\n",
       " 'xzatz',\n",
       " 'xzelh',\n",
       " 'xzbwp',\n",
       " 'xzeot',\n",
       " 'xzbrf',\n",
       " 'xzees',\n",
       " 'xzddf',\n",
       " 'xzegg',\n",
       " 'xzfet',\n",
       " 'xzbjb',\n",
       " 'xzcvz',\n",
       " 'xzefu',\n",
       " 'xzbhz',\n",
       " 'xdd',\n",
       " 'xzbft',\n",
       " 'xzddz',\n",
       " 'xzanw',\n",
       " 'xzaxn',\n",
       " 'xip',\n",
       " 'xzaku',\n",
       " 'xzbhd',\n",
       " 'xzctx',\n",
       " 'xzcgk',\n",
       " 'xgf',\n",
       " 'xun',\n",
       " 'xzdzb',\n",
       " 'xxt',\n",
       " 'xzdkh',\n",
       " 'xzfgi',\n",
       " 'xzdyx',\n",
       " 'xzffi',\n",
       " 'xrh',\n",
       " 'xzdlz',\n",
       " 'xzach',\n",
       " 'xzbcc',\n",
       " 'xzbkw',\n",
       " 'xir',\n",
       " 'xzcug',\n",
       " 'xzbfh',\n",
       " 'xzbqp',\n",
       " 'xzdzc',\n",
       " 'xzcbm',\n",
       " 'xzffr',\n",
       " 'xzcol',\n",
       " 'xzddu',\n",
       " 'xzeym',\n",
       " 'xzapb',\n",
       " 'xzafg',\n",
       " 'xzfcu',\n",
       " 'xzfdy',\n",
       " 'xzakw',\n",
       " 'xkq',\n",
       " 'xzbpq',\n",
       " 'xzbyp',\n",
       " 'xzasu',\n",
       " 'xzevj',\n",
       " 'xzchc',\n",
       " 'xzenr',\n",
       " 'xwt',\n",
       " 'xvf',\n",
       " 'xym',\n",
       " 'xzcfh',\n",
       " 'xzeck',\n",
       " 'xzdtr',\n",
       " 'xzbam',\n",
       " 'xzbix',\n",
       " 'xzasa',\n",
       " 'xzdjo',\n",
       " 'xzbek',\n",
       " 'xif',\n",
       " 'xzbsw',\n",
       " 'xzdlu',\n",
       " 'xzcdq',\n",
       " 'xzbjl',\n",
       " 'xzejf',\n",
       " 'xzbla',\n",
       " 'xzeec',\n",
       " 'xzesh',\n",
       " 'xhm',\n",
       " 'xzbvd',\n",
       " 'xzdog',\n",
       " 'xzaxh',\n",
       " 'xzafr',\n",
       " 'xzcib',\n",
       " 'xzcjk',\n",
       " 'xzegp',\n",
       " 'xzbuz',\n",
       " 'xzdac',\n",
       " 'xzdth',\n",
       " 'xzeur',\n",
       " 'xzeri',\n",
       " 'xob',\n",
       " 'xzclz',\n",
       " 'xzecr',\n",
       " 'xae',\n",
       " 'xaa',\n",
       " 'xzckc',\n",
       " 'xzasq',\n",
       " 'xzdof',\n",
       " 'xzdxe',\n",
       " 'xzaxc',\n",
       " 'xzdgs',\n",
       " 'xzejy',\n",
       " 'xzeti',\n",
       " 'xzegu',\n",
       " 'xzdsg',\n",
       " 'xzfbj',\n",
       " 'xye',\n",
       " 'xts',\n",
       " 'xzase',\n",
       " 'xzczd',\n",
       " 'xzbvi',\n",
       " 'xzdnv',\n",
       " 'xzbyv',\n",
       " 'xzeev',\n",
       " 'xzdvn',\n",
       " 'xzbvc',\n",
       " 'xzbzx',\n",
       " 'xhw',\n",
       " 'xzbxt',\n",
       " 'xzdnr',\n",
       " 'xzdkl',\n",
       " 'xzerq',\n",
       " 'xzerk',\n",
       " 'xzbzi',\n",
       " 'xzagx',\n",
       " 'xzeyx',\n",
       " 'xzchu',\n",
       " 'xzafx',\n",
       " 'xtz',\n",
       " 'xby',\n",
       " 'xzbhf',\n",
       " 'xzepb',\n",
       " 'xzbnb',\n",
       " 'xzczq',\n",
       " 'xzbmf',\n",
       " 'xsx',\n",
       " 'xzdmz',\n",
       " 'xzeph',\n",
       " 'xzcos',\n",
       " 'xzcvp',\n",
       " 'xzebp',\n",
       " 'xzeox',\n",
       " 'xzapv',\n",
       " 'xzcoy',\n",
       " 'xzcwf',\n",
       " 'xzbag',\n",
       " 'xzdle',\n",
       " 'xcj',\n",
       " 'xzdaa',\n",
       " 'xzcpj',\n",
       " 'xcb',\n",
       " 'xzcaz',\n",
       " 'xzdhg',\n",
       " 'xju',\n",
       " 'xzddb',\n",
       " 'xzcjo',\n",
       " 'xoc',\n",
       " 'xzczr',\n",
       " 'xzclq',\n",
       " 'xls',\n",
       " 'xwn',\n",
       " 'xzbvr',\n",
       " 'xzbop',\n",
       " 'xzcrz',\n",
       " 'xzawk',\n",
       " 'xzbmt',\n",
       " 'xzcob',\n",
       " 'xzcyn',\n",
       " 'xzamm',\n",
       " 'xzbid',\n",
       " 'xzety',\n",
       " 'xzail',\n",
       " 'xzaig',\n",
       " 'xzbdm',\n",
       " 'xzdae',\n",
       " 'xzdfn',\n",
       " 'xzeun',\n",
       " 'xyt',\n",
       " 'xzarj',\n",
       " 'xzega',\n",
       " 'xzdwq',\n",
       " 'xzagz',\n",
       " 'xzazq',\n",
       " 'xzbja',\n",
       " 'xzctw',\n",
       " 'xzdtz',\n",
       " 'xzbat',\n",
       " 'xzekn',\n",
       " 'xzbzj',\n",
       " 'xzdzs',\n",
       " 'xxg',\n",
       " 'xzcbs',\n",
       " 'xzdiq',\n",
       " 'xox',\n",
       " 'xxl',\n",
       " 'xzaov',\n",
       " 'xzear',\n",
       " 'xzbgd',\n",
       " 'xhe',\n",
       " 'xzczo',\n",
       " 'xzbiq',\n",
       " 'xzefv',\n",
       " 'xzdqc',\n",
       " 'xxo',\n",
       " 'xzenh',\n",
       " 'xxs',\n",
       " 'xzdvv',\n",
       " 'xzbbb',\n",
       " 'xmo',\n",
       " 'xzdbd',\n",
       " 'xzdgx',\n",
       " 'xuo',\n",
       " 'xzccd',\n",
       " 'xzdet',\n",
       " 'xzepw',\n",
       " 'xzbvs',\n",
       " 'xsc',\n",
       " 'xzclb',\n",
       " 'xzbif',\n",
       " 'xzaxm',\n",
       " 'xzaca',\n",
       " 'xzejs',\n",
       " 'xzeco',\n",
       " 'xzcxf',\n",
       " 'xzbsq',\n",
       " 'xgj',\n",
       " 'xzesv',\n",
       " 'xzbxg',\n",
       " 'xzccl',\n",
       " 'xzbgk',\n",
       " 'xzcfi',\n",
       " 'xmx',\n",
       " 'xzaqw',\n",
       " 'xzekm',\n",
       " 'xfv',\n",
       " 'xos',\n",
       " 'xzbug',\n",
       " 'xzcig',\n",
       " 'xzaqq',\n",
       " 'xzedi',\n",
       " 'xzddp',\n",
       " 'xzfaw',\n",
       " 'xzcta',\n",
       " 'xzauo',\n",
       " 'xzbar',\n",
       " 'xkk',\n",
       " 'xzavk',\n",
       " 'xuk',\n",
       " 'xzeyg',\n",
       " 'xzdnj',\n",
       " 'xxc',\n",
       " 'xzdxc',\n",
       " 'xro',\n",
       " 'xzbmy',\n",
       " 'xzaxp',\n",
       " 'xkf',\n",
       " 'xzczu',\n",
       " 'xzczk',\n",
       " 'xzbtw',\n",
       " 'xzexj',\n",
       " 'xcg',\n",
       " 'xla',\n",
       " 'xnj',\n",
       " 'xzbxr',\n",
       " 'xzanh',\n",
       " 'xzcgj',\n",
       " 'xzeim',\n",
       " 'xzcmy',\n",
       " 'xzdil',\n",
       " 'xzesg',\n",
       " 'xzbgr',\n",
       " 'xzcnb',\n",
       " 'xzami',\n",
       " 'xzakq',\n",
       " 'xzdad',\n",
       " 'xzfbv',\n",
       " 'xzauy',\n",
       " 'xzenm',\n",
       " 'xzarw',\n",
       " 'xxe',\n",
       " 'xzdvk',\n",
       " 'xzfbq',\n",
       " 'xzceb',\n",
       " 'xzbpf',\n",
       " 'xzdef',\n",
       " 'xzamo',\n",
       " 'xzcay',\n",
       " 'xzdnt',\n",
       " 'xzffa',\n",
       " 'xzczb',\n",
       " 'xgx',\n",
       " 'xzcsk',\n",
       " 'xzcnr',\n",
       " 'xzaxs',\n",
       " 'xmf',\n",
       " 'xzacc',\n",
       " 'xzbrz',\n",
       " 'xni',\n",
       " 'xzcum',\n",
       " 'xzblf',\n",
       " 'xzdfc',\n",
       " 'xzbzs',\n",
       " 'xzcnu',\n",
       " 'xzbwb',\n",
       " 'xzdmy',\n",
       " 'xzdcr',\n",
       " 'xov',\n",
       " 'xzejz',\n",
       " 'xzajk',\n",
       " 'xzcme',\n",
       " 'xzfaz',\n",
       " 'xzepi',\n",
       " 'xzaxa',\n",
       " 'xzbnd',\n",
       " 'xzbud',\n",
       " 'xzedy',\n",
       " 'xzbdz',\n",
       " 'xzckn',\n",
       " 'xzceq',\n",
       " 'xpz',\n",
       " 'xzdem',\n",
       " 'xzbyn',\n",
       " 'xzbpu',\n",
       " 'xzdpm',\n",
       " 'xzekz',\n",
       " 'xzcfs',\n",
       " 'xzdfd',\n",
       " 'xzbtg',\n",
       " 'xzdzt',\n",
       " 'xzcrh',\n",
       " 'xbz',\n",
       " 'xvy',\n",
       " 'xzfam',\n",
       " 'xzcld',\n",
       " 'xhz',\n",
       " 'xzeoq',\n",
       " 'xzere',\n",
       " 'xzfdf',\n",
       " 'xfd',\n",
       " 'xzfbh',\n",
       " 'xzabo',\n",
       " 'xzevp',\n",
       " 'xed',\n",
       " 'xbv',\n",
       " 'xzdgn',\n",
       " 'xzcjb',\n",
       " 'xzbna',\n",
       " 'xzdyi',\n",
       " 'xzbnl',\n",
       " 'xzbiz',\n",
       " 'xzdro',\n",
       " 'xzakh',\n",
       " 'xzdql',\n",
       " 'xzeqc',\n",
       " 'xzeoy',\n",
       " 'xxw',\n",
       " 'xzaag',\n",
       " 'xzekw',\n",
       " 'xzegm',\n",
       " 'xzasp',\n",
       " 'xzcah',\n",
       " 'xzdqp',\n",
       " 'xzcmc',\n",
       " 'xzdgu',\n",
       " 'xzdbs',\n",
       " 'xzcca',\n",
       " 'xzadm',\n",
       " 'xzctv',\n",
       " 'xzdqu',\n",
       " 'xzabl',\n",
       " 'xzbxq',\n",
       " 'xzbrv',\n",
       " 'xzdjq',\n",
       " 'xzbms',\n",
       " 'xzdiu',\n",
       " 'xow',\n",
       " 'xzehk',\n",
       " 'xzate',\n",
       " 'xzcfc',\n",
       " 'xzaqf',\n",
       " 'xzbth',\n",
       " 'xzejm',\n",
       " 'xzeps',\n",
       " 'xzbus',\n",
       " 'xzaxe',\n",
       " 'xzejl',\n",
       " 'xzcmd',\n",
       " 'xdz',\n",
       " 'xzcwg',\n",
       " 'xzdfw',\n",
       " 'xzbnt',\n",
       " 'xzbis',\n",
       " 'xbx',\n",
       " 'xzarp',\n",
       " 'xzbcj',\n",
       " 'xzaar',\n",
       " 'xzaqn',\n",
       " 'xzcmn',\n",
       " 'xzctd',\n",
       " 'xzcom',\n",
       " 'xit',\n",
       " 'xfw',\n",
       " 'xzasc',\n",
       " 'xzahk',\n",
       " 'xzdne',\n",
       " 'xuj',\n",
       " 'xzaxq',\n",
       " 'xzasd',\n",
       " 'xpy',\n",
       " 'xzdww',\n",
       " 'xzehi',\n",
       " 'xzbwc',\n",
       " 'xzesp',\n",
       " 'xzajr',\n",
       " 'xzchw',\n",
       " 'xzccs',\n",
       " 'xzdbz',\n",
       " 'xzeej',\n",
       " 'xqp',\n",
       " 'xzebw',\n",
       " 'xzcpa',\n",
       " 'xlq',\n",
       " 'xzats',\n",
       " 'xgu',\n",
       " 'xad',\n",
       " 'xzbhh',\n",
       " 'xlg',\n",
       " 'xzend',\n",
       " 'xzcwu',\n",
       " 'xfg',\n",
       " 'xzbqx',\n",
       " 'xzerf',\n",
       " 'xzbfo',\n",
       " 'xzeep',\n",
       " 'xzfbr',\n",
       " 'xzafn',\n",
       " 'xzeua',\n",
       " 'xzdxv',\n",
       " 'xzana',\n",
       " 'xlk',\n",
       " 'xzcap',\n",
       " 'xzfbb',\n",
       " 'xzfcj',\n",
       " 'xzebd',\n",
       " 'xzeie',\n",
       " 'xzecn',\n",
       " 'xzexh',\n",
       " 'xzess',\n",
       " 'xzcfy',\n",
       " 'xzdsz',\n",
       " 'xzdii',\n",
       " 'xzcin',\n",
       " 'xzbws',\n",
       " 'xcw',\n",
       " 'xnl',\n",
       " 'xzatn',\n",
       " 'xzdss',\n",
       " 'xzama',\n",
       " 'xpf',\n",
       " 'xzenp',\n",
       " 'xez',\n",
       " 'xzcdm',\n",
       " 'xzdrl',\n",
       " 'xzezh',\n",
       " 'xzamh',\n",
       " 'xzbvk',\n",
       " 'xzajd',\n",
       " 'xzapj',\n",
       " 'xzata',\n",
       " 'xzcre',\n",
       " 'xzbqh',\n",
       " 'xzaxz',\n",
       " 'xzbtj',\n",
       " 'xzevy',\n",
       " 'xrc',\n",
       " 'xou',\n",
       " 'xqo',\n",
       " 'xzdna',\n",
       " 'xzdkb',\n",
       " 'xzewa',\n",
       " 'xzdgf',\n",
       " 'xzaol',\n",
       " 'xeg',\n",
       " 'xzfgh',\n",
       " 'xzcgt',\n",
       " 'xzdmc',\n",
       " 'xzbbt',\n",
       " 'xzcjx',\n",
       " 'xzbfs',\n",
       " 'xpe',\n",
       " 'xzdup',\n",
       " 'xzaoh',\n",
       " 'xci',\n",
       " 'xzaqs',\n",
       " 'xzevz',\n",
       " 'xzdiw',\n",
       " 'xzbkk',\n",
       " 'xzdkc',\n",
       " 'xzcgx',\n",
       " 'xvd',\n",
       " 'xrd',\n",
       " 'xzdlb',\n",
       " 'xzcxs',\n",
       " 'xzbcs',\n",
       " 'xfr',\n",
       " 'xoj',\n",
       " 'xzbkb',\n",
       " 'xzaqe',\n",
       " 'xzcnx',\n",
       " 'xzbox',\n",
       " 'xzbdh',\n",
       " 'xwc',\n",
       " 'xzamq',\n",
       " 'xzdzf',\n",
       " 'xcx',\n",
       " 'xzcqw',\n",
       " 'xzcew',\n",
       " 'xzbdx',\n",
       " 'xzeth',\n",
       " 'xzejj',\n",
       " 'xzdcc',\n",
       " 'xzbye',\n",
       " 'xxq',\n",
       " 'xzeqy',\n",
       " 'xzevg',\n",
       " 'xzael',\n",
       " 'xzert',\n",
       " 'xzeyy',\n",
       " 'xzdnn',\n",
       " 'xzeld',\n",
       " 'xzbgx',\n",
       " 'xzego',\n",
       " 'xpt',\n",
       " 'xzcek',\n",
       " 'xzeov',\n",
       " 'xzddl',\n",
       " 'xzaxo',\n",
       " 'xzbvn',\n",
       " 'xzcni',\n",
       " 'xzaxd',\n",
       " 'xzdvz',\n",
       " 'xij',\n",
       " 'xzadc',\n",
       " 'xzdhu',\n",
       " 'xzcut',\n",
       " 'xzcce',\n",
       " 'xzbyi',\n",
       " 'xzfdo',\n",
       " 'xzbpi',\n",
       " 'xzevs',\n",
       " 'xzdun',\n",
       " 'xda',\n",
       " 'xzcof',\n",
       " 'xzaoi',\n",
       " 'xzcvs',\n",
       " 'xzans',\n",
       " 'xzbkt',\n",
       " 'xzdrj',\n",
       " 'xzbwa',\n",
       " 'xxr',\n",
       " 'xzaej',\n",
       " 'xzblw',\n",
       " 'xzehb',\n",
       " 'xzevb',\n",
       " 'xzefj',\n",
       " 'xvj',\n",
       " 'xzewu',\n",
       " 'xzaob',\n",
       " 'xzawd',\n",
       " 'xzeqx',\n",
       " 'xzepf',\n",
       " 'xzbmu',\n",
       " 'xtt',\n",
       " 'xzaki',\n",
       " 'xzbkf',\n",
       " 'xzawb',\n",
       " 'xzazw',\n",
       " 'xzcyh',\n",
       " 'xzefn',\n",
       " 'xzded',\n",
       " 'xzevk',\n",
       " 'xzdjl',\n",
       " 'xzdbv',\n",
       " 'xke',\n",
       " 'xzdsr',\n",
       " 'xzano',\n",
       " 'xzdgw',\n",
       " 'xzeel',\n",
       " 'xzemb',\n",
       " 'xzacq',\n",
       " 'xzemq',\n",
       " 'xzatb',\n",
       " 'xyl',\n",
       " 'xyo',\n",
       " 'xzciu',\n",
       " 'xzdzm',\n",
       " 'xzeuj',\n",
       " 'xzfav',\n",
       " 'xnq',\n",
       " 'xth',\n",
       " 'xzbyy',\n",
       " 'xzbmg',\n",
       " 'xzdnf',\n",
       " 'xzfbw',\n",
       " 'xzabb',\n",
       " 'xzdck',\n",
       " 'xsi',\n",
       " 'xzdqi',\n",
       " 'xzaqb',\n",
       " 'xzcyb',\n",
       " 'xzccg',\n",
       " 'xzdmp',\n",
       " 'xzacp',\n",
       " 'xzejh',\n",
       " 'xzali',\n",
       " 'xzbaf',\n",
       " 'xzcjs',\n",
       " 'xzeay',\n",
       " 'xzajf',\n",
       " 'xzaan',\n",
       " 'xzeeu',\n",
       " 'xzfcd',\n",
       " 'xzeyq',\n",
       " 'xzbbn',\n",
       " 'xzdxt',\n",
       " 'xzdow',\n",
       " 'xzacz',\n",
       " 'xzact',\n",
       " 'xzdko',\n",
       " 'xzdyy',\n",
       " 'xzbet',\n",
       " 'xzcal',\n",
       " 'xie',\n",
       " 'xzapa',\n",
       " 'xxz',\n",
       " 'xzbsm',\n",
       " 'xzdgr',\n",
       " 'xzbey',\n",
       " 'xhc',\n",
       " 'xzezf',\n",
       " 'xzajm',\n",
       " 'xzcbd',\n",
       " 'xzeis',\n",
       " 'xzaxy',\n",
       " 'xzdlx',\n",
       " 'xzeqf',\n",
       " 'xzany',\n",
       " 'xwz',\n",
       " 'xzavi',\n",
       " 'xzccn',\n",
       " 'xzahz',\n",
       " 'xzait',\n",
       " 'xjs',\n",
       " 'xzdnu',\n",
       " 'xim',\n",
       " 'xzbvy',\n",
       " 'xzbji',\n",
       " 'xzcrv',\n",
       " 'xzbwd',\n",
       " 'xzbjq',\n",
       " 'xzfaf',\n",
       " 'xzbyr',\n",
       " 'xzcuz',\n",
       " 'xzdru',\n",
       " 'xzboa',\n",
       " 'xzeef',\n",
       " 'xzent',\n",
       " 'xzclf',\n",
       " 'xzelw',\n",
       " 'xzcvb',\n",
       " 'xzcnd',\n",
       " 'xzcaa',\n",
       " 'xmh',\n",
       " 'xzaom',\n",
       " 'xei',\n",
       " 'xzbry',\n",
       " 'xzcnq',\n",
       " 'xzawz',\n",
       " 'xfo',\n",
       " 'xmq',\n",
       " 'xzdnx',\n",
       " 'xkv',\n",
       " 'xzemy',\n",
       " 'xzcis',\n",
       " 'xzbrx',\n",
       " 'xzciz',\n",
       " 'xzbqw',\n",
       " 'xzamj',\n",
       " 'xzcbi',\n",
       " 'xzcai',\n",
       " 'xzdce',\n",
       " 'xzfcq',\n",
       " 'xzffs',\n",
       " 'xzbmh',\n",
       " 'xzetc',\n",
       " 'xzeze',\n",
       " 'xzefm',\n",
       " 'xce',\n",
       " 'xzbgp',\n",
       " 'xzett',\n",
       " 'xzdgz',\n",
       " 'xzdqv',\n",
       " 'xzcsb',\n",
       " 'xzbii',\n",
       " 'xzasr',\n",
       " 'xzcec',\n",
       " 'xzehy',\n",
       " 'xiz',\n",
       " 'xzbqu',\n",
       " 'xzeht',\n",
       " 'xzefl',\n",
       " 'xzekc',\n",
       " 'xzbqm',\n",
       " 'xzfep',\n",
       " 'xzfas',\n",
       " 'xzdal',\n",
       " 'xzbxf',\n",
       " 'xzagi',\n",
       " 'xzegc',\n",
       " 'xzbfa',\n",
       " 'xzdpe',\n",
       " 'xzdsx',\n",
       " 'xzakb',\n",
       " 'xzbur',\n",
       " 'xzetf',\n",
       " 'xzenn',\n",
       " 'xka',\n",
       " 'xzado',\n",
       " 'xzeow',\n",
       " 'xfk',\n",
       " 'xzarn',\n",
       " 'xzbrm',\n",
       " 'xzdxm',\n",
       " 'xzcpn',\n",
       " 'xho',\n",
       " 'xpb',\n",
       " 'xzctg',\n",
       " 'xeo',\n",
       " 'xzbex',\n",
       " 'xzezw',\n",
       " 'xgk',\n",
       " 'xzcrp',\n",
       " 'xzcju',\n",
       " 'xzdkq',\n",
       " 'xzezm',\n",
       " 'xzawp',\n",
       " 'xzbrt',\n",
       " 'xzeji',\n",
       " 'xzbak',\n",
       " 'xgb',\n",
       " 'xzarb',\n",
       " 'xzajy',\n",
       " 'xzder',\n",
       " 'xeu',\n",
       " 'xzcgb',\n",
       " 'xzeoz',\n",
       " 'xzaqy',\n",
       " 'xzdnh',\n",
       " 'xzbqr',\n",
       " 'xzbbw',\n",
       " 'xzenu',\n",
       " 'xzbrj',\n",
       " 'xzebi',\n",
       " 'xzbkq',\n",
       " 'xzdxr',\n",
       " 'xzeof',\n",
       " 'xzdba',\n",
       " 'xzczv',\n",
       " 'xzcmi',\n",
       " 'xzdtg',\n",
       " 'xzacf',\n",
       " 'xqq',\n",
       " 'xzcoj',\n",
       " 'xuw',\n",
       " 'xzffb',\n",
       " 'xzdju',\n",
       " 'xzags',\n",
       " 'xsl',\n",
       " 'xzaja',\n",
       " 'xbt',\n",
       " 'xzalj',\n",
       " 'xzdjm',\n",
       " 'xzdaw',\n",
       " 'xzdom',\n",
       " 'xzbve',\n",
       " 'xzbda',\n",
       " 'xzaic',\n",
       " 'xzcck',\n",
       " 'xzebz',\n",
       " 'xzalp',\n",
       " 'xzeod',\n",
       " 'xzdkg',\n",
       " 'xzbae',\n",
       " 'xzbqk',\n",
       " 'xzdgc',\n",
       " 'xzbmq',\n",
       " 'xzbxn',\n",
       " 'xzeew',\n",
       " 'xzdmg',\n",
       " 'xol',\n",
       " 'xzcnk',\n",
       " 'xzbzt',\n",
       " 'xzbke',\n",
       " 'xzbzp',\n",
       " 'xzdea',\n",
       " 'xzelg',\n",
       " 'xzake',\n",
       " 'xzeyp',\n",
       " 'xzdwi',\n",
       " 'xzavu',\n",
       " 'xzbtb',\n",
       " 'xzbon',\n",
       " 'xqh',\n",
       " 'xzcer',\n",
       " 'xzcnv',\n",
       " 'xzeno',\n",
       " 'xgn',\n",
       " 'xzdvs',\n",
       " 'xzduj',\n",
       " 'xzcpt',\n",
       " 'xzald',\n",
       " 'xry',\n",
       " 'xzejp',\n",
       " 'xzcey',\n",
       " 'xzetu',\n",
       " 'xzbxy',\n",
       " 'xzckk',\n",
       " 'xzdfa',\n",
       " 'xzdfr',\n",
       " 'xzcso',\n",
       " 'xzdxq',\n",
       " 'xzeix',\n",
       " 'xzbfy',\n",
       " 'xzfeh',\n",
       " 'xzakn',\n",
       " 'xzdfp',\n",
       " 'xzfdj',\n",
       " 'xpc',\n",
       " 'xzayy',\n",
       " 'xse',\n",
       " 'xzbbi',\n",
       " 'xzcmj',\n",
       " 'xzbkr',\n",
       " 'xzcrw',\n",
       " 'xzazz',\n",
       " 'xzemg',\n",
       " 'xmj',\n",
       " 'xzcra',\n",
       " 'xzdtf',\n",
       " 'xfh',\n",
       " 'xzbuv',\n",
       " 'xzbcv',\n",
       " 'xzewj',\n",
       " 'xzabc',\n",
       " 'xzcpk',\n",
       " 'xzeaa',\n",
       " 'xkj',\n",
       " 'xzcwa',\n",
       " 'xxu',\n",
       " 'xzegv',\n",
       " 'xzaym',\n",
       " 'xiq',\n",
       " 'xcr',\n",
       " 'xzagl',\n",
       " 'xzbtt',\n",
       " 'xzdtw',\n",
       " 'xzbez',\n",
       " 'xzeqh',\n",
       " 'xzdlt',\n",
       " 'xjn',\n",
       " 'xaw',\n",
       " 'xzbwr',\n",
       " 'xzako',\n",
       " 'xjj',\n",
       " 'xzdwz',\n",
       " 'xnt',\n",
       " 'xzctn',\n",
       " 'xzeoi',\n",
       " 'xzadd',\n",
       " 'xzeyr',\n",
       " 'xzdpc',\n",
       " 'xzbxz',\n",
       " 'xzccm',\n",
       " 'xzbwq',\n",
       " 'xzcge',\n",
       " 'xzedg',\n",
       " 'xzdvw',\n",
       " 'xug',\n",
       " 'xzast',\n",
       " 'xzenj',\n",
       " 'xzebs',\n",
       " 'xzbll',\n",
       " 'xzcbu',\n",
       " 'xbb',\n",
       " 'xzdld',\n",
       " 'xzeex',\n",
       " 'xva',\n",
       " 'xzbxe',\n",
       " 'xis',\n",
       " 'xhv',\n",
       " 'xzebj',\n",
       " 'xuf',\n",
       " 'xzarx',\n",
       " 'xzbxu',\n",
       " 'xzbsf',\n",
       " 'xzaxf',\n",
       " 'xzbuy',\n",
       " 'xzbee',\n",
       " 'xbo',\n",
       " 'xzbjj',\n",
       " 'xzbki',\n",
       " 'xzaot',\n",
       " 'xzcjy',\n",
       " 'xki',\n",
       " 'xzdma',\n",
       " 'xzbmp',\n",
       " 'xzeso',\n",
       " 'xzept',\n",
       " 'xzbyq',\n",
       " 'xzfbc',\n",
       " 'xzcyg',\n",
       " 'xzcva',\n",
       " 'xzcgr',\n",
       " 'xzdhe',\n",
       " 'xax',\n",
       " 'xzdys',\n",
       " 'xzcot',\n",
       " 'xzcwk',\n",
       " 'xzcav',\n",
       " 'xzdxh',\n",
       " 'xat',\n",
       " 'xzcts',\n",
       " 'xzcrq',\n",
       " 'xzbjm',\n",
       " 'xzcvh',\n",
       " 'xzfbd',\n",
       " 'xzcxh',\n",
       " 'xlw',\n",
       " 'xzfcn',\n",
       " 'xzbdw',\n",
       " 'xzeaw',\n",
       " 'xzalv',\n",
       " 'xzehf',\n",
       " 'xzbvz',\n",
       " 'xzech',\n",
       " 'xzaqu',\n",
       " 'xzdkr',\n",
       " 'xzbie',\n",
       " 'xzeni',\n",
       " 'xzbxx',\n",
       " 'xzerg',\n",
       " 'xzeaj',\n",
       " 'xbq',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 200\n",
    "\n",
    "\n",
    "rows = np.array_split(list(range(0,150000)),int(150000/TIMESTEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 6, 7, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3],[4,5,6],[6,7,8]]\n",
    "\n",
    "np.delete(a, 1, axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i,split in enumerate(splits):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=len(splits)\n",
    "\n",
    "def get_segment_data(split, sequence_idx):\n",
    "    columns = ['acoustic_data','time_to_failure']\n",
    "    features = ['acoustic_data','rolling_100']\n",
    "\n",
    "    path = 'train/%s' % (split)\n",
    "    #print(\"DEBUGGGGG\")\n",
    "    #print(path)\n",
    "    skipped_rows_indices = get_skipped_rows(sequence_idx)\n",
    "    df = pd.read_csv(path, float_precision='round_trip', header=None, skiprows=skipped_rows_indices)\n",
    "    df.columns = columns\n",
    "    df['rolling_100'] = df['acoustic_data'].rolling(window=100, min_periods=1).mean()#.apply(np.log)\n",
    "    df['acoustic_data'] = df['acoustic_data'].astype(float)\n",
    "    df[features] = StandardScaler().fit_transform(df[features])\n",
    "    return df[features].values, df['time_to_failure'].values[-1]\n",
    "\n",
    "\n",
    "def get_skipped_rows(sequence_idx):\n",
    "    return np.delete(rows, sequence_idx, axis=0).reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "def get_generated_batch(sequence_idx):\n",
    "    batch = np.empty((len(splits),TIMESTEPS,2),dtype=float)\n",
    "    targets = np.empty((len(splits),1),dtype=float)\n",
    "    for i,split in enumerate(splits):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        segment_data, target = get_segment_data(split, sequence_idx)\n",
    "        batch[i] = segment_data\n",
    "        targets[i] = target\n",
    "    return batch, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "split_size = 500\n",
    "\n",
    "\n",
    "def get_sequence(sequence_idx, sequence_batch_size):\n",
    "    print(\"DEBUGGGGG 1\")\n",
    "    splits_chunk = splits[sequence_idx:sequence_idx+sequence_batch_size]\n",
    "    print(\"DEBUGGGGG 2\")\n",
    "\n",
    "    training, ys = read_raw_training_data(splits_chunk)\n",
    "    print(\"DEBUGGGGG 3\")\n",
    "    new_training, new_ys = fornat_training_data(training, ys)\n",
    "    print(\"DEBUGGGGG 4\")\n",
    "    train, Y = swap_axes(new_training, new_ys)\n",
    "    print(\"DEBUGGGGG 5\")\n",
    "\n",
    "    return train, Y\n",
    "    \n",
    "    \n",
    "def read_raw_training_data(splits_chunk): \n",
    "    training = []\n",
    "    ys = []\n",
    "\n",
    "    features = ['acoustic_data','time_to_failure']\n",
    "\n",
    "    for chunk in splits_chunk:\n",
    "        path = 'train/%s' % (chunk)\n",
    "        #print(\"DEBUGGGGG\")\n",
    "        #print(path)\n",
    "        chunk_df = pd.read_csv(path, float_precision='round_trip', header=None)\n",
    "        chunk_df.columns = features\n",
    "        chunk_df['rolling_100'] = chunk_df['acoustic_data'].rolling(window=100, min_periods=1).mean()#.apply(np.log)\n",
    "        chunk_df[features] = StandardScaler().fit_transform(chunk_df[features])\n",
    "        training.append(chunk_df[features].values)\n",
    "        ys.append(chunk_df['time_to_failure'].values)\n",
    "\n",
    "    training = np.array(training)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    return training, ys\n",
    "\n",
    "def fornat_training_data(training, ys):\n",
    "    new_training = []\n",
    "    new_ys = []\n",
    "    for i,sequence in enumerate(training):\n",
    "        #split each sequence in split_size\n",
    "        splits = np.array_split(sequence, split_size)\n",
    "        #print(np.array(splits).shape)\n",
    "        new_training.append(splits)\n",
    "        splits_y = np.array_split(ys[i], split_size)\n",
    "        new_ys.append(splits_y)\n",
    "\n",
    "\n",
    "    new_training = np.array(new_training)\n",
    "    new_ys = np.array(new_ys)\n",
    "    return new_training, new_ys\n",
    "\n",
    "\n",
    "def swap_axes(new_training,new_ys):\n",
    "    train = np.swapaxes(new_training,0,1)\n",
    "    train = train.reshape(-1,300,2)\n",
    "    \n",
    "    targets = np.swapaxes(new_ys,0,1)\n",
    "    \n",
    "    Y = []\n",
    "    for target in targets:\n",
    "        Y.append(np.array(target[:,-1]))\n",
    "\n",
    "    Y = np.array(Y).reshape(-1)\n",
    "    \n",
    "    return train, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_chunk = splits[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/stephane/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (45480,2) into shape (150000,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-92e95ff211fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rolling_100'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acoustic_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.apply(np.log)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_to_failure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (45480,2) into shape (150000,2)"
     ]
    }
   ],
   "source": [
    "training = np.empty((200,150000,2),dtype=float)\n",
    "ys = np.empty((200,150000),dtype=float)\n",
    "\n",
    "features = ['acoustic_data','time_to_failure']\n",
    "\n",
    "\n",
    "for i,chunk in enumerate(splits_chunk):\n",
    "    path = 'train/%s' % (chunk)\n",
    "    chunk_df = pd.read_csv(path, float_precision='round_trip', header=None)\n",
    "    chunk_df.columns = features\n",
    "    chunk_df['rolling_100'] = chunk_df['acoustic_data'].rolling(window=100, min_periods=1).mean()#.apply(np.log)\n",
    "    chunk_df[features] = StandardScaler().fit_transform(chunk_df[features])\n",
    "    training[i] = chunk_df[features].values\n",
    "    ys[i] = chunk_df['time_to_failure'].values\n",
    "\n",
    "training = np.array(training)\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 150000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 150000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of batches must cover a sequence length i.e. 100 * 1500 = 15000, batch size = 1500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 500\n",
    "new_training = []\n",
    "new_ys = []\n",
    "for i,sequence in enumerate(training):\n",
    "    #split each sequence in split_size\n",
    "    splits = np.array_split(sequence, split_size)\n",
    "    #print(np.array(splits).shape)\n",
    "    new_training.append(splits)\n",
    "    splits_y = np.array_split(ys[i], split_size)\n",
    "    new_ys.append(splits_y)\n",
    "\n",
    "    \n",
    "new_training = np.array(new_training)\n",
    "new_ys = np.array(new_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1,2,3], [4,5,6]], [[10,20,30], [40,50,60]]])\n",
    "print(a.shape)\n",
    "np.array(a[0])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "a\n",
    "a.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-d993494fc05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "np.array(new_ys[0])[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500, 300, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.swapaxes(new_training,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(-1,300,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.swapaxes(new_ys,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for target in targets:\n",
    "    Y.append(np.array(target[:,-1]))\n",
    "    \n",
    "Y = np.array(Y).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 4, 1)\n",
      "[[[[    1]\n",
      "   [    2]\n",
      "   [    3]\n",
      "   [    4]]\n",
      "\n",
      "  [[    5]\n",
      "   [    6]\n",
      "   [    7]\n",
      "   [    8]]\n",
      "\n",
      "  [[    8]\n",
      "   [    9]\n",
      "   [   10]\n",
      "   [   11]]]\n",
      "\n",
      "\n",
      " [[[   10]\n",
      "   [   20]\n",
      "   [   30]\n",
      "   [   40]]\n",
      "\n",
      "  [[   50]\n",
      "   [   60]\n",
      "   [   70]\n",
      "   [   80]]\n",
      "\n",
      "  [[   80]\n",
      "   [   90]\n",
      "   [  100]\n",
      "   [  110]]]\n",
      "\n",
      "\n",
      " [[[ 1000]\n",
      "   [ 2000]\n",
      "   [ 3000]\n",
      "   [ 4000]]\n",
      "\n",
      "  [[ 5000]\n",
      "   [ 6000]\n",
      "   [ 7000]\n",
      "   [ 8000]]\n",
      "\n",
      "  [[ 8000]\n",
      "   [ 9000]\n",
      "   [10000]\n",
      "   [11000]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[    1],\n",
       "         [    2],\n",
       "         [    3],\n",
       "         [    4]],\n",
       "\n",
       "        [[   10],\n",
       "         [   20],\n",
       "         [   30],\n",
       "         [   40]],\n",
       "\n",
       "        [[ 1000],\n",
       "         [ 2000],\n",
       "         [ 3000],\n",
       "         [ 4000]]],\n",
       "\n",
       "\n",
       "       [[[    5],\n",
       "         [    6],\n",
       "         [    7],\n",
       "         [    8]],\n",
       "\n",
       "        [[   50],\n",
       "         [   60],\n",
       "         [   70],\n",
       "         [   80]],\n",
       "\n",
       "        [[ 5000],\n",
       "         [ 6000],\n",
       "         [ 7000],\n",
       "         [ 8000]]],\n",
       "\n",
       "\n",
       "       [[[    8],\n",
       "         [    9],\n",
       "         [   10],\n",
       "         [   11]],\n",
       "\n",
       "        [[   80],\n",
       "         [   90],\n",
       "         [  100],\n",
       "         [  110]],\n",
       "\n",
       "        [[ 8000],\n",
       "         [ 9000],\n",
       "         [10000],\n",
       "         [11000]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[[1],[2],[3],[4]],[[5],[6],[7],[8]],[[8],[9],[10],[11]]], [[[10],[20],[30],[40]],[[50],[60],[70],[80]],[[80],[90],[100],[110]]],\\\n",
    "              [[[1000],[2000],[3000],[4000]],[[5000],[6000],[7000],[8000]],[[8000],[9000],[10000],[11000]]] ])\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "np.swapaxes(a,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data, y_train, y_val = train_test_split(train, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class MY_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, split_filenames):\n",
    "        self.split_filenames = split_filenames\n",
    "\n",
    "    #This function computes the number of batches that this generator is supposed to produce. \n",
    "    #So, we divide the number of total samples by the batch_size and return that value.    \n",
    "    def __len__(self):\n",
    "        return int(150000 / TIMESTEPS)\n",
    "\n",
    "    #Here, given the batch numberidx you need to put together a list that consists of data \n",
    "    #batch and the ground-truth (GT). In this example, we read a batch images of size \n",
    "    #self.batch and return an array of form[image_batch, GT]\n",
    "    def __getitem__(self, idx):\n",
    "        train,Y = get_generated_batch(idx)\n",
    "        #print(\"idx\",idx)\n",
    "        #print(\"LOLILOL\")\n",
    "        #print(train.shape, Y.shape)\n",
    "\n",
    "        return (train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (4195, 3)                 84        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (4195, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 88\n",
      "Trainable params: 88\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "  6/500 [..............................] - ETA: 4:22:26 - loss: 5.7265 - mean_absolute_error: 5.7265100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1100\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1300\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1400\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1600\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1700\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1800\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "1900\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2100\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2200\n",
      "2300\n",
      "2200\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2300\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2400\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2400\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2500\n",
      "2600\n",
      "2600\n",
      "2600\n",
      "2700\n",
      "2600\n",
      "2700\n",
      "2700\n",
      "2600\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2700\n",
      "2800\n",
      "2800\n",
      "2700\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2800\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "2900\n",
      "3000\n",
      "3000\n",
      "2900\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3100\n",
      "3100\n",
      "3000\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3100\n",
      "3200\n",
      "3200\n",
      "3100\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3200\n",
      "3300\n",
      "3300\n",
      "3200\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3300\n",
      "3400\n",
      "3400\n",
      "3300\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3400\n",
      "3500\n",
      "3500\n",
      "3400\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3500\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3500\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3600\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3700\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3700\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3800\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3800\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "3900\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "3900\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4000\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "4100\n",
      "0\n",
      "  9/500 [..............................] - ETA: 5:29:28 - loss: 5.7170 - mean_absolute_error: 5.71700\n",
      " 10/500 [..............................] - ETA: 4:56:00 - loss: 5.7139 - mean_absolute_error: 5.71390\n",
      "0\n",
      "4100\n",
      "0\n",
      "0\n",
      " 11/500 [..............................] - ETA: 4:30:38 - loss: 5.7110 - mean_absolute_error: 5.71100\n",
      "100\n",
      "100\n",
      "100\n",
      "0\n",
      " 15/500 [..............................] - ETA: 3:18:34 - loss: 5.6986 - mean_absolute_error: 5.6986100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "200\n",
      "300\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "300\n",
      "400\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "400\n",
      "500\n",
      "500\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "600\n",
      "500\n",
      "600\n",
      "600\n",
      "500\n",
      "600\n",
      "600\n",
      "600\n",
      "700\n",
      "600\n",
      "700\n",
      "700\n",
      "600\n",
      "700\n",
      "700\n",
      "800\n",
      "700\n",
      "700\n",
      "800\n",
      "800\n",
      "800\n",
      "700\n",
      "800\n",
      "900\n",
      "800\n",
      "800\n",
      "900\n",
      "900\n",
      "900\n",
      "800\n",
      "900\n",
      "1000\n",
      "900\n",
      "900\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1000\n",
      "1100\n",
      "1000\n",
      "1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-2:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/stephane/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-1:\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4ea638feafad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                       )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "dropout=0.2\n",
    "\n",
    "\n",
    "my_model = Sequential()\n",
    "\n",
    "my_model.add(CuDNNLSTM(#use_bias = True,unit_forget_bias=True,\\\n",
    "                  units = 3,\\\n",
    "                  stateful=True,batch_input_shape=(BATCH_SIZE,TIMESTEPS,2),\\\n",
    "                  #dropout=dropout,recurrent_dropout=dropout,\n",
    "                  ))\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.compile(loss = 'mae',optimizer = 'adam', metrics = ['mean_absolute_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=0, verbose=0)\n",
    "]\n",
    "\n",
    "#history = my_model.fit(train, Y, batch_size=BATCH_SIZE, epochs=100, shuffle=False,\n",
    "                      #validation_data=(val_data,y_val), callbacks=callbacks\n",
    "                    #  )\n",
    "my_training_batch_generator = MY_Generator(splits)\n",
    "        \n",
    "my_model.fit_generator(generator=my_training_batch_generator,\n",
    "                                          steps_per_epoch=500,\n",
    "                                          epochs=10,\n",
    "                                          shuffle=False,\n",
    "                                          #verbose=1,\n",
    "                                          #validation_data=my_validation_batch_generator,\n",
    "                                          #validation_steps=(num_validation_samples // batch_size),\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=8,\n",
    "                                          max_queue_size=32\n",
    "                      )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "#import math\n",
    "#print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MY_Generator' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f19bcd1be2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_training_batch_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'MY_Generator' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(my_training_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
