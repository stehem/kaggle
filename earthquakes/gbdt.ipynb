{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import itertools\n",
    "\n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS=1\n",
    "\n",
    "import build_segment\n",
    "importlib.reload(build_segment)\n",
    "\n",
    "from build_segment import build_segment_f\n",
    "\n",
    "split_chunks = np.array_split(splits,mp.cpu_count())\n",
    "\n",
    "#def build_segment_f(splits, number_of_groups,test=False, augment=False, scale=True, noise=0.5):\n",
    "\n",
    "param_test = False\n",
    "param_augment = False\n",
    "param_scale = False\n",
    "param_noise = 0.5\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS,param_test,param_augment,param_scale,param_noise]) for chunk in split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res[0].get()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=res[0].get()[0].columns.values\n",
    "\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "i=0\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        data = data.append(df)\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "data.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations2 = list(itertools.combinations(data.columns.values, 2))\n",
    "combinations3 = list(itertools.combinations(data.columns.values, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations2:\n",
    "    if 'augmented' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    feature = f'{f1}_mult_{f2}'\n",
    "    data[feature] = data[f1] * data[f2]\n",
    "    feature = f'{f1}_plus_{f2}'\n",
    "    data[feature] = data[f1] + data[f2]\n",
    "    feature = f'{f1}_div_{f2}'\n",
    "    #print(feature)\n",
    "    data[feature] = data[f1] / data[f2]\n",
    "    data[feature] = pd.to_numeric(data[feature], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations3:\n",
    "    if 'augmented' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    f3 = combination[2]\n",
    "    feature = f'{f1}_mult_{f2}_mult_{f3}'\n",
    "    data[feature] = data[f1] * data[f2] * data[f3]\n",
    "    feature = f'{f1}_plus_{f2}_plus_{f3}'\n",
    "    data[feature] = data[f1] + data[f2] + data[f3]\n",
    "    feature = f'{f1}_div_{f2}_div_{f3}'\n",
    "    #print(feature)\n",
    "    data[feature] = data[f1] / data[f2] / data[f3]\n",
    "    data[feature] = pd.to_numeric(data[feature], downcast='float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combinations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7f8f8acf964b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combinations' is not defined"
     ]
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.1\n",
    "#train_data, val_data, y_train, y_val = train_test_split(training, targets, test_size=test_size, random_state=42)\n",
    "\n",
    "val_size = int(len(data)*0.1)\n",
    "non_augmented = data[data['augmented'] == False]\n",
    "val_indices = np.random.choice(non_augmented.index.values, val_size)\n",
    "val_data = data[data.index.isin(val_indices)].drop('augmented', axis=1)\n",
    "train_data = data[~data.index.isin(val_indices)].drop('augmented', axis=1)\n",
    "\n",
    "train_y = train_data['time_to_failure']\n",
    "val_y = val_data['time_to_failure']\n",
    "\n",
    "train_data = train_data.drop('time_to_failure', axis=1)\n",
    "val_data = val_data.drop('time_to_failure', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cb_model = CatBoostRegressor(iterations=10000,\n",
    "                             #learning_rate=0.05,\n",
    "                             eval_metric='MAE',\n",
    "                             task_type = \"GPU\",\n",
    "                             use_best_model=True,\n",
    "                             od_type = \"Iter\",\n",
    "                             od_wait = 20,\n",
    "                             #depth=3,\n",
    "                             border_count=254,\n",
    "                             #bagging_temperature = 20,\n",
    "                             #cat_features=[0],\n",
    "                             random_seed = 42)\n",
    "\n",
    "\n",
    "\n",
    "cb_model.fit(train_data[features], train_y, #cat_features=categorical_features_indices,\n",
    "             eval_set=(val_data[features],val_y),\n",
    "             #cat_features=categorical_features_pos,         \n",
    "             verbose=True)\n",
    "\n",
    "scores = {}\n",
    "for i,score in enumerate(cb_model.get_feature_importance()):\n",
    "    scores[features[i]] = score\n",
    "\n",
    "sorted(scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\tvalid_0's l1: 2.56877\n",
      "[20]\tvalid_0's l1: 2.32894\n",
      "[30]\tvalid_0's l1: 2.20539\n",
      "[40]\tvalid_0's l1: 2.14617\n",
      "[50]\tvalid_0's l1: 2.12913\n",
      "[60]\tvalid_0's l1: 2.12064\n",
      "[70]\tvalid_0's l1: 2.12249\n",
      "[80]\tvalid_0's l1: 2.12429\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 2.12008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mean_mult_sum_mult_negs', 189),\n",
       " ('mean_div_pos', 135),\n",
       " ('imax_div_imin', 90),\n",
       " ('mean_mult_negs_mult_cid_ce', 88),\n",
       " ('max_div_min_div_ssum', 87),\n",
       " ('q75_div_autocorr_10_div_r_sigma', 80),\n",
       " ('min_plus_std_plus_uniq', 80),\n",
       " ('max_div_min_div_r_sigma', 74),\n",
       " ('abs_sum_chg_mult_cid_ce', 71),\n",
       " ('std_div_q50_div_negs', 68),\n",
       " ('min_div_abs_div_reocurring_pct', 68),\n",
       " ('q25_mult_imin_mult_autocorr_10', 66),\n",
       " ('mean_div_pos_div_abs_sum_chg', 64),\n",
       " ('kurtosis_div_r_sigma_div_skewness', 63),\n",
       " ('max_div_kurtosis_div_r_sigma', 63),\n",
       " ('negs_div_r_sigma_div_ratio_to_length', 61),\n",
       " ('max_div_min_div_imin', 57),\n",
       " ('negs_div_autocorr_10_div_reocurring_pct', 54),\n",
       " ('negs_div_autocorr_10_div_r_sigma', 53),\n",
       " ('negs_div_abs_nrg_div_r_sigma', 53),\n",
       " ('q50_div_imin_div_skewness', 53),\n",
       " ('min_div_abs_div_ssum', 47),\n",
       " ('q75_mult_negs_mult_autocorr_10', 46)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgtrain = lgbm.Dataset(train_data[features], label=train_y)\n",
    "lgval = lgbm.Dataset(val_data[features], label=val_y)\n",
    "\n",
    "\n",
    "# needs to keep overfiting under control, default params don't cut it at all\n",
    "params = {\n",
    "        \"num_threads\": 8,\n",
    "        \"verbosity\": -1,\n",
    "        #\"zero_as_missing\": \"true\",\n",
    "        \"boosting\":'gbdt',\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"mae\",\n",
    "        \"seed\": 42,\n",
    "        \"learning_rate\" : 0.05,\n",
    "        #\"min_data_in_leaf\": 100,\n",
    "        #\"num_leaves\": 10,\n",
    "        #\"max_depth\" : 4,\n",
    "        #\"bagging_fraction\": 0.7,\n",
    "        #\"bagging_freq\": 1,\n",
    "        #\"feature_fraction\": 0.7,\n",
    "        #\"lambda_l1\": 10,\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "model_lgb = lgbm.train(params, lgtrain, 10000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=30, \n",
    "                      verbose_eval=10, \n",
    "                      evals_result=evals_result)\n",
    "\n",
    "\n",
    "scores = {}\n",
    "for i,score in enumerate(model_lgb.feature_importance()):\n",
    "    scores[features[i]] = score\n",
    "\n",
    "sorted(scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [item[0] for item in scores.items() if item[1] > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  2.1884148717136336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression,BayesianRidge, HuberRegressor\n",
    "\n",
    "lr_features = features[0:10]\n",
    "\n",
    "lr_model =  Lasso(alpha=0.5)\n",
    "lr_model.fit(train_data[lr_features], train_y)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_preds = lr_model.predict(val_data[lr_features])\n",
    "print(\"mae: \", mean_absolute_error(val_y, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLITS='test'\n",
    "test_splits = [f for f in listdir(TEST_SPLITS) if isfile(join(TEST_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "test_split_chunks = np.array_split(test_splits,mp.cpu_count())\n",
    "    \n",
    "    \n",
    "param_test = True\n",
    "param_augment = False\n",
    "param_scale = False\n",
    "param_noise = 0.6\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS,param_test,param_augment,param_scale,param_noise]) for chunk in test_split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624\n"
     ]
    }
   ],
   "source": [
    "columns=res[0].get()[0].columns.values\n",
    "\n",
    "test_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "i=0\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        #print(df)\n",
    "        test_data = test_data.append(df)\n",
    "        #print(len(test_data))\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations2 = list(itertools.combinations(test_data.columns.values, 2))\n",
    "combinations3 = list(itertools.combinations(test_data.columns.values, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations2:\n",
    "    if 'seg_id' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    feature = f'{f1}_mult_{f2}'\n",
    "    test_data[feature] = test_data[f1] * test_data[f2]\n",
    "    feature = f'{f1}_plus_{f2}'\n",
    "    test_data[feature] = test_data[f1] + test_data[f2]\n",
    "    feature = f'{f1}_div_{f2}'\n",
    "    #print(feature)\n",
    "    test_data[feature] = test_data[f1] / test_data[f2]\n",
    "    test_data[feature] = pd.to_numeric(test_data[feature], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations3:\n",
    "    if 'seg_id' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    f3 = combination[2]\n",
    "    feature = f'{f1}_mult_{f2}_mult_{f3}'\n",
    "    test_data[feature] = test_data[f1] * test_data[f2] * test_data[f3]\n",
    "    feature = f'{f1}_plus_{f2}_plus_{f3}'\n",
    "    test_data[feature] = test_data[f1] + test_data[f2] + test_data[f3]\n",
    "    feature = f'{f1}_div_{f2}_div_{f3}'\n",
    "    #print(feature)\n",
    "    test_data[feature] = test_data[f1] / test_data[f2] / test_data[f3]\n",
    "    test_data[feature] = pd.to_numeric(test_data[feature], downcast='float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data['seg_id'].apply(lambda id: id.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cb_model.predict(test_data[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_preds = model_lgb.predict(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr_model.predict(test_data[lr_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (lg_preds * 0.5) + (lr_preds * 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = lg_preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean        5.863660\n",
       "std         2.288841\n",
       "min         1.269167\n",
       "25%         4.052866\n",
       "50%         5.483414\n",
       "75%         7.649506\n",
       "max        11.784076\n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean        5.347878\n",
       "std         2.108800\n",
       "min        -4.808612\n",
       "25%         3.805956\n",
       "50%         4.916270\n",
       "75%         6.885264\n",
       "max        10.936613\n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_preds = pd.read_csv('lgbm.csv')['time_to_failure']\n",
    "cb_preds = pd.read_csv('cb1549.csv')['time_to_failure']\n",
    "lstm_preds = pd.read_csv('lstm1627.csv')['time_to_failure']\n",
    "\n",
    "\n",
    "preds = (cb_preds * 0.4) + (lgbm_preds * 0.5)\n",
    "\n",
    "preds.clip(0,20,out=preds)\n",
    "\n",
    "print(np.mean(preds))\n",
    "print(np.max(preds))\n",
    "\n",
    "submission = test.loc[:,['ID']]\n",
    "submission['item_cnt_month'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
