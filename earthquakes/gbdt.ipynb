{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import itertools\n",
    "\n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS=1\n",
    "\n",
    "import build_segment\n",
    "importlib.reload(build_segment)\n",
    "\n",
    "from build_segment import build_segment_f\n",
    "\n",
    "split_chunks = np.array_split(splits,mp.cpu_count())\n",
    "\n",
    "#def build_segment_f(splits, number_of_groups,test=False, augment=False, scale=True, noise=0.5):\n",
    "\n",
    "param_test = False\n",
    "param_augment = False\n",
    "param_scale = False\n",
    "param_noise = 0.9\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS,param_test,param_augment,param_scale,param_noise]) for chunk in split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>abs</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>sum</th>\n",
       "      <th>uniq</th>\n",
       "      <th>pos</th>\n",
       "      <th>negs</th>\n",
       "      <th>ssum</th>\n",
       "      <th>imax</th>\n",
       "      <th>imin</th>\n",
       "      <th>abs_nrg</th>\n",
       "      <th>abs_sum_chg</th>\n",
       "      <th>autocorr_10</th>\n",
       "      <th>cid_ce</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean_chg</th>\n",
       "      <th>reocurring_pct</th>\n",
       "      <th>r_sigma</th>\n",
       "      <th>ratio_to_length</th>\n",
       "      <th>skewness</th>\n",
       "      <th>strike_below</th>\n",
       "      <th>strike_above</th>\n",
       "      <th>last_loc_max</th>\n",
       "      <th>first_loc_max</th>\n",
       "      <th>last_loc_min</th>\n",
       "      <th>first_loc_min</th>\n",
       "      <th>perc_reocurr_dp</th>\n",
       "      <th>perc_reocurr_all</th>\n",
       "      <th>sum_reoccurr_val</th>\n",
       "      <th>sum_reoccurr_dp</th>\n",
       "      <th>ratio_value_number</th>\n",
       "      <th>peaks</th>\n",
       "      <th>mean_head</th>\n",
       "      <th>mean_tail</th>\n",
       "      <th>abs_diff_head_tail</th>\n",
       "      <th>pos_head</th>\n",
       "      <th>neg_head</th>\n",
       "      <th>pos_tail</th>\n",
       "      <th>neg_tail</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.444313</td>\n",
       "      <td>240.0</td>\n",
       "      <td>-251.0</td>\n",
       "      <td>6.772888</td>\n",
       "      <td>491.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>666647.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>130706.0</td>\n",
       "      <td>12757.0</td>\n",
       "      <td>805813.0</td>\n",
       "      <td>123721.0</td>\n",
       "      <td>123730.0</td>\n",
       "      <td>9843589.0</td>\n",
       "      <td>398960.0</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>211.444229</td>\n",
       "      <td>196.416366</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.021727</td>\n",
       "      <td>0.00172</td>\n",
       "      <td>-0.913277</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.824813</td>\n",
       "      <td>0.824807</td>\n",
       "      <td>0.824873</td>\n",
       "      <td>0.824867</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.99956</td>\n",
       "      <td>525.0</td>\n",
       "      <td>666440.0</td>\n",
       "      <td>0.00172</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.824</td>\n",
       "      <td>4.483</td>\n",
       "      <td>45.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.150997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean    max    min       std    abs  q25  q50  q75       sum   uniq       pos     negs      ssum      imax      imin    abs_nrg  abs_sum_chg  autocorr_10      cid_ce    kurtosis  mean_chg  reocurring_pct   r_sigma  ratio_to_length  skewness  strike_below  strike_above  last_loc_max  first_loc_max  last_loc_min  first_loc_min  perc_reocurr_dp  perc_reocurr_all  sum_reoccurr_val  sum_reoccurr_dp  ratio_value_number  peaks  mean_head  mean_tail  abs_diff_head_tail  pos_head  neg_head  pos_tail  neg_tail  time_to_failure  augmented\n",
       "0  4.444313  240.0 -251.0  6.772888  491.0  2.0  4.0  7.0  666647.0  258.0  130706.0  12757.0  805813.0  123721.0  123730.0  9843589.0  398960.0    -0.501602     211.444229  196.416366  0.000013  0.744186        0.021727  0.00172         -0.913277  28.0          27.0          0.824813      0.824807       0.824873      0.824867       0.744186         0.99956           525.0             666440.0         0.00172             40.0   4.824      4.483      45.0                707.0     254.0     881.0     85.0      3.150997         False    "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].get()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=res[0].get()[0].columns.values\n",
    "\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "i=0\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        data = data.append(df)\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "data.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>abs</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>sum</th>\n",
       "      <th>uniq</th>\n",
       "      <th>pos</th>\n",
       "      <th>negs</th>\n",
       "      <th>ssum</th>\n",
       "      <th>imax</th>\n",
       "      <th>imin</th>\n",
       "      <th>abs_nrg</th>\n",
       "      <th>abs_sum_chg</th>\n",
       "      <th>autocorr_10</th>\n",
       "      <th>cid_ce</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>mean_chg</th>\n",
       "      <th>reocurring_pct</th>\n",
       "      <th>r_sigma</th>\n",
       "      <th>ratio_to_length</th>\n",
       "      <th>skewness</th>\n",
       "      <th>strike_below</th>\n",
       "      <th>strike_above</th>\n",
       "      <th>last_loc_max</th>\n",
       "      <th>first_loc_max</th>\n",
       "      <th>last_loc_min</th>\n",
       "      <th>first_loc_min</th>\n",
       "      <th>perc_reocurr_dp</th>\n",
       "      <th>perc_reocurr_all</th>\n",
       "      <th>sum_reoccurr_val</th>\n",
       "      <th>sum_reoccurr_dp</th>\n",
       "      <th>ratio_value_number</th>\n",
       "      <th>peaks</th>\n",
       "      <th>mean_head</th>\n",
       "      <th>mean_tail</th>\n",
       "      <th>abs_diff_head_tail</th>\n",
       "      <th>pos_head</th>\n",
       "      <th>neg_head</th>\n",
       "      <th>pos_tail</th>\n",
       "      <th>neg_tail</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>augmented</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>4.643867</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>3.987769</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>696580.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>135937.0</td>\n",
       "      <td>8275.0</td>\n",
       "      <td>757508.0</td>\n",
       "      <td>72392.0</td>\n",
       "      <td>63848.0</td>\n",
       "      <td>5620170.0</td>\n",
       "      <td>376861.0</td>\n",
       "      <td>-0.326331</td>\n",
       "      <td>312.661925</td>\n",
       "      <td>22.240299</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.031933</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.482620</td>\n",
       "      <td>0.482613</td>\n",
       "      <td>0.425660</td>\n",
       "      <td>0.425653</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>348.0</td>\n",
       "      <td>696098.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.741</td>\n",
       "      <td>4.810</td>\n",
       "      <td>25.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.733397</td>\n",
       "      <td>False</td>\n",
       "      <td>xzeio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>4.891307</td>\n",
       "      <td>112.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>5.069033</td>\n",
       "      <td>213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>733696.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133960.0</td>\n",
       "      <td>10626.0</td>\n",
       "      <td>835534.0</td>\n",
       "      <td>100215.0</td>\n",
       "      <td>100223.0</td>\n",
       "      <td>7442996.0</td>\n",
       "      <td>392408.0</td>\n",
       "      <td>-0.431684</td>\n",
       "      <td>260.905044</td>\n",
       "      <td>33.524518</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>-0.038370</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.668107</td>\n",
       "      <td>0.668100</td>\n",
       "      <td>0.668160</td>\n",
       "      <td>0.668153</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>509.0</td>\n",
       "      <td>733254.0</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.322</td>\n",
       "      <td>4.968</td>\n",
       "      <td>19.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.696996</td>\n",
       "      <td>False</td>\n",
       "      <td>xrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>4.667487</td>\n",
       "      <td>150.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>5.349547</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>700123.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>132397.0</td>\n",
       "      <td>11505.0</td>\n",
       "      <td>810901.0</td>\n",
       "      <td>143210.0</td>\n",
       "      <td>37736.0</td>\n",
       "      <td>7560463.0</td>\n",
       "      <td>391036.0</td>\n",
       "      <td>-0.419792</td>\n",
       "      <td>247.991951</td>\n",
       "      <td>53.330164</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.779980</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.954740</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.251580</td>\n",
       "      <td>0.251573</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>699290.0</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.520</td>\n",
       "      <td>5.005</td>\n",
       "      <td>21.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.137698</td>\n",
       "      <td>False</td>\n",
       "      <td>xvt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>4.542147</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>7.470333</td>\n",
       "      <td>453.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>681322.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>130531.0</td>\n",
       "      <td>13318.0</td>\n",
       "      <td>851086.0</td>\n",
       "      <td>120351.0</td>\n",
       "      <td>120342.0</td>\n",
       "      <td>11465546.0</td>\n",
       "      <td>409913.0</td>\n",
       "      <td>-0.517219</td>\n",
       "      <td>201.575079</td>\n",
       "      <td>155.520072</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.802347</td>\n",
       "      <td>0.802340</td>\n",
       "      <td>0.802287</td>\n",
       "      <td>0.802280</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>997.0</td>\n",
       "      <td>680780.0</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.526</td>\n",
       "      <td>4.328</td>\n",
       "      <td>20.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.318796</td>\n",
       "      <td>False</td>\n",
       "      <td>xzcgl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>4.731200</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>5.096663</td>\n",
       "      <td>194.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>709680.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>134258.0</td>\n",
       "      <td>10078.0</td>\n",
       "      <td>805816.0</td>\n",
       "      <td>31573.0</td>\n",
       "      <td>31618.0</td>\n",
       "      <td>7254034.0</td>\n",
       "      <td>389248.0</td>\n",
       "      <td>-0.438253</td>\n",
       "      <td>259.584952</td>\n",
       "      <td>43.378283</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.053329</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.210493</td>\n",
       "      <td>0.210487</td>\n",
       "      <td>0.210793</td>\n",
       "      <td>0.210787</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>534.0</td>\n",
       "      <td>709710.0</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.903</td>\n",
       "      <td>5.006</td>\n",
       "      <td>18.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.632196</td>\n",
       "      <td>False</td>\n",
       "      <td>xqi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>4.185240</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>3.418934</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>627786.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>135901.0</td>\n",
       "      <td>7498.0</td>\n",
       "      <td>669528.0</td>\n",
       "      <td>81286.0</td>\n",
       "      <td>81277.0</td>\n",
       "      <td>4380802.0</td>\n",
       "      <td>366743.0</td>\n",
       "      <td>-0.248424</td>\n",
       "      <td>354.375849</td>\n",
       "      <td>115.698288</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.023733</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>1.232481</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.541913</td>\n",
       "      <td>0.541907</td>\n",
       "      <td>0.541853</td>\n",
       "      <td>0.541847</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>52.0</td>\n",
       "      <td>627338.0</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.731</td>\n",
       "      <td>4.555</td>\n",
       "      <td>17.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.789199</td>\n",
       "      <td>False</td>\n",
       "      <td>xzevu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>4.597953</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>6.328488</td>\n",
       "      <td>243.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>689693.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>127876.0</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>859743.0</td>\n",
       "      <td>108845.0</td>\n",
       "      <td>108834.0</td>\n",
       "      <td>9178641.0</td>\n",
       "      <td>411467.0</td>\n",
       "      <td>-0.487239</td>\n",
       "      <td>222.517467</td>\n",
       "      <td>38.297358</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>-0.294414</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.725640</td>\n",
       "      <td>0.725633</td>\n",
       "      <td>0.725567</td>\n",
       "      <td>0.725560</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>193.0</td>\n",
       "      <td>689722.0</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.633</td>\n",
       "      <td>4.624</td>\n",
       "      <td>23.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.846696</td>\n",
       "      <td>False</td>\n",
       "      <td>xap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>4.315687</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>3.142984</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>647353.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>135930.0</td>\n",
       "      <td>7537.0</td>\n",
       "      <td>683071.0</td>\n",
       "      <td>129823.0</td>\n",
       "      <td>129882.0</td>\n",
       "      <td>4275525.0</td>\n",
       "      <td>365867.0</td>\n",
       "      <td>-0.191543</td>\n",
       "      <td>381.220472</td>\n",
       "      <td>6.807165</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.865493</td>\n",
       "      <td>0.865487</td>\n",
       "      <td>0.865887</td>\n",
       "      <td>0.865880</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>316.0</td>\n",
       "      <td>647388.0</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.361</td>\n",
       "      <td>3.999</td>\n",
       "      <td>22.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>14.933897</td>\n",
       "      <td>False</td>\n",
       "      <td>xzbne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>4.344767</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>4.230174</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>651715.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>133081.0</td>\n",
       "      <td>10394.0</td>\n",
       "      <td>732695.0</td>\n",
       "      <td>64967.0</td>\n",
       "      <td>75942.0</td>\n",
       "      <td>5515705.0</td>\n",
       "      <td>381380.0</td>\n",
       "      <td>-0.352936</td>\n",
       "      <td>299.893315</td>\n",
       "      <td>20.128079</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.939853</td>\n",
       "      <td>0.433113</td>\n",
       "      <td>0.506287</td>\n",
       "      <td>0.506280</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>465.0</td>\n",
       "      <td>651822.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.301</td>\n",
       "      <td>29.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6.357498</td>\n",
       "      <td>False</td>\n",
       "      <td>xzcdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>4.274520</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>4.215539</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>641178.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>132487.0</td>\n",
       "      <td>10678.0</td>\n",
       "      <td>723068.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>5406344.0</td>\n",
       "      <td>380375.0</td>\n",
       "      <td>-0.357197</td>\n",
       "      <td>299.299486</td>\n",
       "      <td>20.464042</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.079068</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>305.0</td>\n",
       "      <td>640924.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.090</td>\n",
       "      <td>4.433</td>\n",
       "      <td>38.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.375098</td>\n",
       "      <td>False</td>\n",
       "      <td>xzbos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean    max    min       std    abs  q25  q50  q75       sum   uniq       pos     negs      ssum      imax      imin     abs_nrg  abs_sum_chg  autocorr_10      cid_ce    kurtosis  mean_chg  reocurring_pct   r_sigma  ratio_to_length  skewness  strike_below  strike_above  last_loc_max  first_loc_max  last_loc_min  first_loc_min  perc_reocurr_dp  perc_reocurr_all  sum_reoccurr_val  sum_reoccurr_dp  ratio_value_number  peaks  mean_head  mean_tail  abs_diff_head_tail  pos_head  neg_head  pos_tail  neg_tail  time_to_failure augmented segment\n",
       "3064  4.643867  73.0  -61.0   3.987769  134.0  3.0  5.0  7.0  696580.0  117.0  135937.0  8275.0   757508.0  72392.0   63848.0   5620170.0   376861.0    -0.326331     312.661925  22.240299   0.000060  0.854701        0.031933  0.000780         0.085846  19.0          23.0          0.482620      0.482613       0.425660      0.425653       0.854701         0.999887          348.0             696098.0         0.000780            47.0   4.741      4.810      25.0                833.0     110.0     886.0     73.0      12.733397        False     xzeio \n",
       "1629  4.891307  112.0 -101.0  5.069033  213.0  3.0  5.0  7.0  733696.0  155.0  133960.0  10626.0  835534.0  100215.0  100223.0  7442996.0   392408.0    -0.431684     260.905044  33.524518   0.000013  0.800000        0.032847  0.001033        -0.038370  19.0          25.0          0.668107      0.668100       0.668160      0.668153       0.800000         0.999793          509.0             733254.0         0.001033            41.0   5.322      4.968      19.0                956.0     21.0      943.0     21.0      9.696996         False     xrg   \n",
       "2691  4.667487  150.0 -90.0   5.349547  240.0  2.0  5.0  7.0  700123.0  177.0  132397.0  11505.0  810901.0  143210.0  37736.0   7560463.0   391036.0    -0.419792     247.991951  53.330164  -0.000013  0.824859        0.029167  0.001180         0.779980  24.0          31.0          0.954740      0.954733       0.251580      0.251573       0.824859         0.999793          1251.0            699290.0         0.001180            50.0   4.520      5.005      21.0                932.0     27.0      918.0     54.0      5.137698         False     xvt   \n",
       "3951  4.542147  243.0 -210.0  7.470333  453.0  2.0  5.0  7.0  681322.0  280.0  130531.0  13318.0  851086.0  120351.0  120342.0  11465546.0  409913.0    -0.517219     201.575079  155.520072 -0.000060  0.717857        0.025127  0.001867         0.240547  33.0          34.0          0.802347      0.802340       0.802287      0.802280       0.717857         0.999473          997.0             680780.0         0.001867            49.0   4.526      4.328      20.0                868.0     70.0      876.0     82.0      3.318796         False     xzcgl \n",
       "2668  4.731200  105.0 -89.0   5.096663  194.0  3.0  5.0  7.0  709680.0  165.0  134258.0  10078.0  805816.0  31573.0   31618.0   7254034.0   389248.0    -0.438253     259.584952  43.378283  -0.000027  0.830303        0.029287  0.001100         0.053329  24.0          25.0          0.210493      0.210487       0.210793      0.210787       0.830303         0.999813          534.0             709710.0         0.001100            46.0   4.903      5.006      18.0                947.0     20.0      956.0     15.0      10.632196        False     xqi   \n",
       "1020  4.185240  148.0 -90.0   3.418934  238.0  2.0  4.0  6.0  627786.0  121.0  135901.0  7498.0   669528.0  81286.0   81277.0   4380802.0   366743.0    -0.248424     354.375849  115.698288 -0.000020  0.710744        0.023733  0.000807         1.232481  21.0          20.0          0.541913      0.541907       0.541853      0.541847       0.710744         0.999767          52.0              627338.0         0.000807            41.0   4.731      4.555      17.0                935.0     26.0      940.0     28.0      8.789199         False     xzevu \n",
       "3672  4.597953  126.0 -117.0  6.328488  243.0  2.0  5.0  7.0  689693.0  182.0  127876.0  15600.0  859743.0  108845.0  108834.0  9178641.0   411467.0    -0.487239     222.517467  38.297358  -0.000087  0.829670        0.034947  0.001213        -0.294414  28.0          24.0          0.725640      0.725633       0.725567      0.725560       0.829670         0.999793          193.0             689722.0         0.001213            47.0   4.633      4.624      23.0                850.0     82.0      896.0     57.0      0.846696         False     xap   \n",
       "2830  4.315687  52.0  -44.0   3.142984  96.0   2.0  4.0  6.0  647353.0  73.0   135930.0  7537.0   683071.0  129823.0  129882.0  4275525.0   365867.0    -0.191543     381.220472  6.807165   -0.000020  0.863014        0.046300  0.000487         0.013886  22.0          17.0          0.865493      0.865487       0.865887      0.865880       0.863014         0.999933          316.0             647388.0         0.000487            50.0   4.361      3.999      22.0                914.0     43.0      873.0     62.0      14.933897        False     xzbne \n",
       "1324  4.344767  70.0  -68.0   4.230174  138.0  2.0  4.0  6.0  651715.0  117.0  133081.0  10394.0  732695.0  64967.0   75942.0   5515705.0   381380.0    -0.352936     299.893315  20.128079   0.000053  0.854701        0.034333  0.000780         0.021851  22.0          20.0          0.939853      0.433113       0.506287      0.506280       0.854701         0.999887          465.0             651822.0         0.000780            41.0   4.360      4.301      29.0                929.0     35.0      819.0     142.0     6.357498         False     xzcdl \n",
       "212   4.274520  81.0  -58.0   4.215539  139.0  2.0  4.0  6.0  641178.0  117.0  132487.0  10678.0  723068.0  1444.0    1436.0    5406344.0   380375.0    -0.357197     299.299486  20.464042  -0.000020  0.854701        0.034553  0.000780         0.079068  25.0          22.0          0.009640      0.009627       0.009580      0.009573       0.854701         0.999887          305.0             640924.0         0.000780            42.0   4.090      4.433      38.0                685.0     273.0     935.0     27.0      13.375098        False     xzbos "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shemery/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n",
      "/home/shemery/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns.values:\n",
    "    #col_mean = data[column].mean()\n",
    "    if \"augmented\" not in column:\n",
    "        data[f'log_{column}'] =  np.log(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations2 = list(itertools.combinations(data.columns.values, 2))\n",
    "combinations3 = list(itertools.combinations(data.columns.values, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations2:\n",
    "    if 'augmented' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    feature = f'{f1}_mult_{f2}'\n",
    "    data[feature] = data[f1] * data[f2]\n",
    "    feature = f'{f1}_plus_{f2}'\n",
    "    data[feature] = data[f1] + data[f2]\n",
    "    feature = f'{f1}_div_{f2}'\n",
    "    #print(feature)\n",
    "    data[feature] = data[f1] / data[f2]\n",
    "    data[feature] = pd.to_numeric(data[feature], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations3:\n",
    "    if 'augmented' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    f3 = combination[2]\n",
    "    feature = f'{f1}_mult_{f2}_mult_{f3}'\n",
    "    data[feature] = data[f1] * data[f2] * data[f3]\n",
    "    feature = f'{f1}_plus_{f2}_plus_{f3}'\n",
    "    data[feature] = data[f1] + data[f2] + data[f3]\n",
    "    feature = f'{f1}_div_{f2}_div_{f3}'\n",
    "    #print(feature)\n",
    "    data[feature] = data[f1] / data[f2] / data[f3]\n",
    "    data[feature] = pd.to_numeric(data[feature], downcast='float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits\n",
    "\n",
    "shared_train_data, shared_val_data = train_test_split(splits, test_size=0.1, random_state=42)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(shared_train_data, open( \"shared_train_data.pickle\", \"wb\" ))\n",
    "pickle.dump(shared_val_data, open( \"shared_val_data.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training__ = data[data['segment'].isin(shared_train_data)]\n",
    "train_y = training__['time_to_failure']\n",
    "train_data = training__.drop(['segment', 'augmented', 'time_to_failure'], axis=1)\n",
    "\n",
    "validation__ = data[data['segment'].isin(shared_val_data)]\n",
    "val_y = validation__['time_to_failure']\n",
    "val_data = validation__.drop(['segment', 'augmented', 'time_to_failure'], axis=1)\n",
    "\n",
    "#test_size = 0.1\n",
    "#train_data, val_data, y_train, y_val = train_test_split(data, targets, test_size=test_size, random_state=42)\n",
    "\n",
    "# val_size = int(len(data)*0.1)\n",
    "# non_augmented = data[data['augmented'] == False]\n",
    "# val_indices = np.random.choice(non_augmented.index.values, val_size)\n",
    "# val_data = data[data.index.isin(val_indices)].drop('augmented', axis=1)\n",
    "# train_data = data[~data.index.isin(val_indices)].drop('augmented', axis=1)\n",
    "\n",
    "# train_y = train_data['time_to_failure']\n",
    "# val_y = val_data['time_to_failure']\n",
    "\n",
    "# train_data = train_data.drop('time_to_failure', axis=1)\n",
    "# val_data = val_data.drop('time_to_failure', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = train_data.columns.values\n",
    "cb_features = all_features\n",
    "lg_features = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 5.5266256\ttest: 5.4635058\tbest: 5.4635058 (0)\ttotal: 23.1ms\tremaining: 3m 51s\n",
      "1:\tlearn: 5.3721537\ttest: 5.3167075\tbest: 5.3167075 (1)\ttotal: 33.6ms\tremaining: 2m 47s\n",
      "2:\tlearn: 5.2230788\ttest: 5.1717322\tbest: 5.1717322 (2)\ttotal: 41.4ms\tremaining: 2m 17s\n",
      "3:\tlearn: 5.0792584\ttest: 5.0312715\tbest: 5.0312715 (3)\ttotal: 47.9ms\tremaining: 1m 59s\n",
      "4:\tlearn: 4.9419461\ttest: 4.8955398\tbest: 4.8955398 (4)\ttotal: 53.9ms\tremaining: 1m 47s\n",
      "5:\tlearn: 4.8092755\ttest: 4.7650990\tbest: 4.7650990 (5)\ttotal: 59.9ms\tremaining: 1m 39s\n",
      "6:\tlearn: 4.6819599\ttest: 4.6425422\tbest: 4.6425422 (6)\ttotal: 66.2ms\tremaining: 1m 34s\n",
      "7:\tlearn: 4.5603705\ttest: 4.5255815\tbest: 4.5255815 (7)\ttotal: 72.4ms\tremaining: 1m 30s\n",
      "8:\tlearn: 4.4448026\ttest: 4.4135813\tbest: 4.4135813 (8)\ttotal: 78.4ms\tremaining: 1m 27s\n",
      "9:\tlearn: 4.3332481\ttest: 4.3067683\tbest: 4.3067683 (9)\ttotal: 84.5ms\tremaining: 1m 24s\n",
      "10:\tlearn: 4.2260499\ttest: 4.2046613\tbest: 4.2046613 (10)\ttotal: 90.7ms\tremaining: 1m 22s\n",
      "11:\tlearn: 4.1241782\ttest: 4.1049472\tbest: 4.1049472 (11)\ttotal: 97ms\tremaining: 1m 20s\n",
      "12:\tlearn: 4.0256183\ttest: 4.0091383\tbest: 4.0091383 (12)\ttotal: 103ms\tremaining: 1m 19s\n",
      "13:\tlearn: 3.9308297\ttest: 3.9180308\tbest: 3.9180308 (13)\ttotal: 109ms\tremaining: 1m 17s\n",
      "14:\tlearn: 3.8399972\ttest: 3.8299644\tbest: 3.8299644 (14)\ttotal: 115ms\tremaining: 1m 16s\n",
      "15:\tlearn: 3.7522201\ttest: 3.7470560\tbest: 3.7470560 (15)\ttotal: 122ms\tremaining: 1m 15s\n",
      "16:\tlearn: 3.6674750\ttest: 3.6666931\tbest: 3.6666931 (16)\ttotal: 128ms\tremaining: 1m 15s\n",
      "17:\tlearn: 3.5872985\ttest: 3.5901551\tbest: 3.5901551 (17)\ttotal: 134ms\tremaining: 1m 14s\n",
      "18:\tlearn: 3.5112737\ttest: 3.5191634\tbest: 3.5191634 (18)\ttotal: 140ms\tremaining: 1m 13s\n",
      "19:\tlearn: 3.4376203\ttest: 3.4505849\tbest: 3.4505849 (19)\ttotal: 146ms\tremaining: 1m 12s\n",
      "20:\tlearn: 3.3661898\ttest: 3.3849987\tbest: 3.3849987 (20)\ttotal: 153ms\tremaining: 1m 12s\n",
      "21:\tlearn: 3.2971813\ttest: 3.3213398\tbest: 3.3213398 (21)\ttotal: 159ms\tremaining: 1m 12s\n",
      "22:\tlearn: 3.2314120\ttest: 3.2604593\tbest: 3.2604593 (22)\ttotal: 165ms\tremaining: 1m 11s\n",
      "23:\tlearn: 3.1682971\ttest: 3.2030889\tbest: 3.2030889 (23)\ttotal: 171ms\tremaining: 1m 11s\n",
      "24:\tlearn: 3.1079995\ttest: 3.1482286\tbest: 3.1482286 (24)\ttotal: 179ms\tremaining: 1m 11s\n",
      "25:\tlearn: 3.0492345\ttest: 3.0962308\tbest: 3.0962308 (25)\ttotal: 185ms\tremaining: 1m 11s\n",
      "26:\tlearn: 2.9950590\ttest: 3.0466697\tbest: 3.0466697 (26)\ttotal: 192ms\tremaining: 1m 10s\n",
      "27:\tlearn: 2.9422179\ttest: 2.9993500\tbest: 2.9993500 (27)\ttotal: 198ms\tremaining: 1m 10s\n",
      "28:\tlearn: 2.8916685\ttest: 2.9525095\tbest: 2.9525095 (28)\ttotal: 205ms\tremaining: 1m 10s\n",
      "29:\tlearn: 2.8439025\ttest: 2.9067440\tbest: 2.9067440 (29)\ttotal: 211ms\tremaining: 1m 10s\n",
      "30:\tlearn: 2.7985290\ttest: 2.8627533\tbest: 2.8627533 (30)\ttotal: 217ms\tremaining: 1m 9s\n",
      "31:\tlearn: 2.7555853\ttest: 2.8232590\tbest: 2.8232590 (31)\ttotal: 227ms\tremaining: 1m 10s\n",
      "32:\tlearn: 2.7140054\ttest: 2.7850137\tbest: 2.7850137 (32)\ttotal: 235ms\tremaining: 1m 11s\n",
      "33:\tlearn: 2.6741659\ttest: 2.7477414\tbest: 2.7477414 (33)\ttotal: 243ms\tremaining: 1m 11s\n",
      "34:\tlearn: 2.6378403\ttest: 2.7138015\tbest: 2.7138015 (34)\ttotal: 251ms\tremaining: 1m 11s\n",
      "35:\tlearn: 2.6017595\ttest: 2.6805809\tbest: 2.6805809 (35)\ttotal: 262ms\tremaining: 1m 12s\n",
      "36:\tlearn: 2.5680108\ttest: 2.6492834\tbest: 2.6492834 (36)\ttotal: 269ms\tremaining: 1m 12s\n",
      "37:\tlearn: 2.5358108\ttest: 2.6199791\tbest: 2.6199791 (37)\ttotal: 275ms\tremaining: 1m 12s\n",
      "38:\tlearn: 2.5055983\ttest: 2.5938616\tbest: 2.5938616 (38)\ttotal: 282ms\tremaining: 1m 12s\n",
      "39:\tlearn: 2.4783841\ttest: 2.5687338\tbest: 2.5687338 (39)\ttotal: 289ms\tremaining: 1m 11s\n",
      "40:\tlearn: 2.4528423\ttest: 2.5458303\tbest: 2.5458303 (40)\ttotal: 295ms\tremaining: 1m 11s\n",
      "41:\tlearn: 2.4275016\ttest: 2.5230826\tbest: 2.5230826 (41)\ttotal: 302ms\tremaining: 1m 11s\n",
      "42:\tlearn: 2.4046134\ttest: 2.5025945\tbest: 2.5025945 (42)\ttotal: 311ms\tremaining: 1m 12s\n",
      "43:\tlearn: 2.3823316\ttest: 2.4831876\tbest: 2.4831876 (43)\ttotal: 319ms\tremaining: 1m 12s\n",
      "44:\tlearn: 2.3611419\ttest: 2.4643002\tbest: 2.4643002 (44)\ttotal: 326ms\tremaining: 1m 12s\n",
      "45:\tlearn: 2.3404441\ttest: 2.4458737\tbest: 2.4458737 (45)\ttotal: 332ms\tremaining: 1m 11s\n",
      "46:\tlearn: 2.3220787\ttest: 2.4285100\tbest: 2.4285100 (46)\ttotal: 339ms\tremaining: 1m 11s\n",
      "47:\tlearn: 2.3043365\ttest: 2.4116032\tbest: 2.4116032 (47)\ttotal: 346ms\tremaining: 1m 11s\n",
      "48:\tlearn: 2.2896064\ttest: 2.3975290\tbest: 2.3975290 (48)\ttotal: 356ms\tremaining: 1m 12s\n",
      "49:\tlearn: 2.2739928\ttest: 2.3841401\tbest: 2.3841401 (49)\ttotal: 363ms\tremaining: 1m 12s\n",
      "50:\tlearn: 2.2603666\ttest: 2.3708825\tbest: 2.3708825 (50)\ttotal: 369ms\tremaining: 1m 12s\n",
      "51:\tlearn: 2.2469656\ttest: 2.3587857\tbest: 2.3587857 (51)\ttotal: 376ms\tremaining: 1m 11s\n",
      "52:\tlearn: 2.2345352\ttest: 2.3460503\tbest: 2.3460503 (52)\ttotal: 382ms\tremaining: 1m 11s\n",
      "53:\tlearn: 2.2231064\ttest: 2.3343240\tbest: 2.3343240 (53)\ttotal: 388ms\tremaining: 1m 11s\n",
      "54:\tlearn: 2.2122089\ttest: 2.3224207\tbest: 2.3224207 (54)\ttotal: 394ms\tremaining: 1m 11s\n",
      "55:\tlearn: 2.2015002\ttest: 2.3114464\tbest: 2.3114464 (55)\ttotal: 401ms\tremaining: 1m 11s\n",
      "56:\tlearn: 2.1919685\ttest: 2.3004839\tbest: 2.3004839 (56)\ttotal: 407ms\tremaining: 1m 10s\n",
      "57:\tlearn: 2.1824142\ttest: 2.2911133\tbest: 2.2911133 (57)\ttotal: 413ms\tremaining: 1m 10s\n",
      "58:\tlearn: 2.1748749\ttest: 2.2820531\tbest: 2.2820531 (58)\ttotal: 419ms\tremaining: 1m 10s\n",
      "59:\tlearn: 2.1671892\ttest: 2.2725183\tbest: 2.2725183 (59)\ttotal: 427ms\tremaining: 1m 10s\n",
      "60:\tlearn: 2.1601591\ttest: 2.2646635\tbest: 2.2646635 (60)\ttotal: 434ms\tremaining: 1m 10s\n",
      "61:\tlearn: 2.1540833\ttest: 2.2574005\tbest: 2.2574005 (61)\ttotal: 444ms\tremaining: 1m 11s\n",
      "62:\tlearn: 2.1475024\ttest: 2.2510463\tbest: 2.2510463 (62)\ttotal: 454ms\tremaining: 1m 11s\n",
      "63:\tlearn: 2.1415260\ttest: 2.2439329\tbest: 2.2439329 (63)\ttotal: 462ms\tremaining: 1m 11s\n",
      "64:\tlearn: 2.1352080\ttest: 2.2377223\tbest: 2.2377223 (64)\ttotal: 469ms\tremaining: 1m 11s\n",
      "65:\tlearn: 2.1299328\ttest: 2.2323350\tbest: 2.2323350 (65)\ttotal: 476ms\tremaining: 1m 11s\n",
      "66:\tlearn: 2.1250728\ttest: 2.2265297\tbest: 2.2265297 (66)\ttotal: 483ms\tremaining: 1m 11s\n",
      "67:\tlearn: 2.1215779\ttest: 2.2226207\tbest: 2.2226207 (67)\ttotal: 489ms\tremaining: 1m 11s\n",
      "68:\tlearn: 2.1176998\ttest: 2.2190056\tbest: 2.2190056 (68)\ttotal: 496ms\tremaining: 1m 11s\n",
      "69:\tlearn: 2.1137054\ttest: 2.2141697\tbest: 2.2141697 (69)\ttotal: 502ms\tremaining: 1m 11s\n",
      "70:\tlearn: 2.1104191\ttest: 2.2112864\tbest: 2.2112864 (70)\ttotal: 508ms\tremaining: 1m 11s\n",
      "71:\tlearn: 2.1066603\ttest: 2.2078225\tbest: 2.2078225 (71)\ttotal: 515ms\tremaining: 1m 10s\n",
      "72:\tlearn: 2.1037101\ttest: 2.2047688\tbest: 2.2047688 (72)\ttotal: 521ms\tremaining: 1m 10s\n",
      "73:\tlearn: 2.1006420\ttest: 2.2014913\tbest: 2.2014913 (73)\ttotal: 528ms\tremaining: 1m 10s\n",
      "74:\tlearn: 2.0981396\ttest: 2.1985840\tbest: 2.1985840 (74)\ttotal: 534ms\tremaining: 1m 10s\n",
      "75:\tlearn: 2.0958294\ttest: 2.1963738\tbest: 2.1963738 (75)\ttotal: 540ms\tremaining: 1m 10s\n",
      "76:\tlearn: 2.0932070\ttest: 2.1927855\tbest: 2.1927855 (76)\ttotal: 546ms\tremaining: 1m 10s\n",
      "77:\tlearn: 2.0909089\ttest: 2.1897570\tbest: 2.1897570 (77)\ttotal: 552ms\tremaining: 1m 10s\n",
      "78:\tlearn: 2.0890950\ttest: 2.1878292\tbest: 2.1878292 (78)\ttotal: 559ms\tremaining: 1m 10s\n",
      "79:\tlearn: 2.0874315\ttest: 2.1858103\tbest: 2.1858103 (79)\ttotal: 565ms\tremaining: 1m 10s\n",
      "80:\tlearn: 2.0851109\ttest: 2.1840412\tbest: 2.1840412 (80)\ttotal: 571ms\tremaining: 1m 9s\n",
      "81:\tlearn: 2.0832730\ttest: 2.1826710\tbest: 2.1826710 (81)\ttotal: 578ms\tremaining: 1m 9s\n",
      "82:\tlearn: 2.0818639\ttest: 2.1808626\tbest: 2.1808626 (82)\ttotal: 584ms\tremaining: 1m 9s\n",
      "83:\tlearn: 2.0808549\ttest: 2.1795548\tbest: 2.1795548 (83)\ttotal: 590ms\tremaining: 1m 9s\n",
      "84:\tlearn: 2.0793835\ttest: 2.1777686\tbest: 2.1777686 (84)\ttotal: 597ms\tremaining: 1m 9s\n",
      "85:\tlearn: 2.0784749\ttest: 2.1762703\tbest: 2.1762703 (85)\ttotal: 605ms\tremaining: 1m 9s\n",
      "86:\tlearn: 2.0769149\ttest: 2.1746961\tbest: 2.1746961 (86)\ttotal: 612ms\tremaining: 1m 9s\n",
      "87:\tlearn: 2.0758680\ttest: 2.1734816\tbest: 2.1734816 (87)\ttotal: 619ms\tremaining: 1m 9s\n",
      "88:\tlearn: 2.0746655\ttest: 2.1718370\tbest: 2.1718370 (88)\ttotal: 627ms\tremaining: 1m 9s\n",
      "89:\tlearn: 2.0738278\ttest: 2.1708875\tbest: 2.1708875 (89)\ttotal: 633ms\tremaining: 1m 9s\n",
      "90:\tlearn: 2.0727368\ttest: 2.1700787\tbest: 2.1700787 (90)\ttotal: 642ms\tremaining: 1m 9s\n",
      "91:\tlearn: 2.0717780\ttest: 2.1694264\tbest: 2.1694264 (91)\ttotal: 651ms\tremaining: 1m 10s\n",
      "92:\tlearn: 2.0710206\ttest: 2.1689990\tbest: 2.1689990 (92)\ttotal: 660ms\tremaining: 1m 10s\n",
      "93:\tlearn: 2.0707272\ttest: 2.1688003\tbest: 2.1688003 (93)\ttotal: 667ms\tremaining: 1m 10s\n",
      "94:\tlearn: 2.0701163\ttest: 2.1680420\tbest: 2.1680420 (94)\ttotal: 673ms\tremaining: 1m 10s\n",
      "95:\tlearn: 2.0693294\ttest: 2.1680435\tbest: 2.1680420 (94)\ttotal: 679ms\tremaining: 1m 10s\n",
      "96:\tlearn: 2.0684721\ttest: 2.1670656\tbest: 2.1670656 (96)\ttotal: 686ms\tremaining: 1m 9s\n",
      "97:\tlearn: 2.0676190\ttest: 2.1660960\tbest: 2.1660960 (97)\ttotal: 692ms\tremaining: 1m 9s\n",
      "98:\tlearn: 2.0667723\ttest: 2.1653159\tbest: 2.1653159 (98)\ttotal: 698ms\tremaining: 1m 9s\n",
      "99:\tlearn: 2.0661319\ttest: 2.1647922\tbest: 2.1647922 (99)\ttotal: 705ms\tremaining: 1m 9s\n",
      "100:\tlearn: 2.0655431\ttest: 2.1639825\tbest: 2.1639825 (100)\ttotal: 711ms\tremaining: 1m 9s\n",
      "101:\tlearn: 2.0654049\ttest: 2.1637648\tbest: 2.1637648 (101)\ttotal: 719ms\tremaining: 1m 9s\n",
      "102:\tlearn: 2.0649894\ttest: 2.1624983\tbest: 2.1624983 (102)\ttotal: 725ms\tremaining: 1m 9s\n",
      "103:\tlearn: 2.0648310\ttest: 2.1626578\tbest: 2.1624983 (102)\ttotal: 731ms\tremaining: 1m 9s\n",
      "104:\tlearn: 2.0640251\ttest: 2.1621146\tbest: 2.1621146 (104)\ttotal: 738ms\tremaining: 1m 9s\n",
      "105:\tlearn: 2.0635653\ttest: 2.1615902\tbest: 2.1615902 (105)\ttotal: 744ms\tremaining: 1m 9s\n",
      "106:\tlearn: 2.0634231\ttest: 2.1610419\tbest: 2.1610419 (106)\ttotal: 750ms\tremaining: 1m 9s\n",
      "107:\tlearn: 2.0630929\ttest: 2.1607624\tbest: 2.1607624 (107)\ttotal: 756ms\tremaining: 1m 9s\n",
      "108:\tlearn: 2.0621667\ttest: 2.1607889\tbest: 2.1607624 (107)\ttotal: 762ms\tremaining: 1m 9s\n",
      "109:\tlearn: 2.0622490\ttest: 2.1605282\tbest: 2.1605282 (109)\ttotal: 768ms\tremaining: 1m 9s\n",
      "110:\tlearn: 2.0618525\ttest: 2.1596426\tbest: 2.1596426 (110)\ttotal: 774ms\tremaining: 1m 8s\n",
      "111:\tlearn: 2.0618247\ttest: 2.1593624\tbest: 2.1593624 (111)\ttotal: 777ms\tremaining: 1m 8s\n",
      "112:\tlearn: 2.0615595\ttest: 2.1586573\tbest: 2.1586573 (112)\ttotal: 783ms\tremaining: 1m 8s\n",
      "113:\tlearn: 2.0612515\ttest: 2.1584677\tbest: 2.1584677 (113)\ttotal: 789ms\tremaining: 1m 8s\n",
      "114:\tlearn: 2.0614910\ttest: 2.1584071\tbest: 2.1584071 (114)\ttotal: 792ms\tremaining: 1m 8s\n",
      "115:\tlearn: 2.0611784\ttest: 2.1581745\tbest: 2.1581745 (115)\ttotal: 798ms\tremaining: 1m 8s\n",
      "116:\tlearn: 2.0608670\ttest: 2.1581428\tbest: 2.1581428 (116)\ttotal: 805ms\tremaining: 1m 7s\n",
      "117:\tlearn: 2.0605263\ttest: 2.1580192\tbest: 2.1580192 (117)\ttotal: 811ms\tremaining: 1m 7s\n",
      "118:\tlearn: 2.0602898\ttest: 2.1576402\tbest: 2.1576402 (118)\ttotal: 817ms\tremaining: 1m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119:\tlearn: 2.0601505\ttest: 2.1575071\tbest: 2.1575071 (119)\ttotal: 824ms\tremaining: 1m 7s\n",
      "120:\tlearn: 2.0599302\ttest: 2.1574515\tbest: 2.1574515 (120)\ttotal: 831ms\tremaining: 1m 7s\n",
      "121:\tlearn: 2.0599551\ttest: 2.1573860\tbest: 2.1573860 (121)\ttotal: 837ms\tremaining: 1m 7s\n",
      "122:\tlearn: 2.0595463\ttest: 2.1567036\tbest: 2.1567036 (122)\ttotal: 846ms\tremaining: 1m 7s\n",
      "123:\tlearn: 2.0594475\ttest: 2.1567564\tbest: 2.1567036 (122)\ttotal: 857ms\tremaining: 1m 8s\n",
      "124:\tlearn: 2.0589680\ttest: 2.1565346\tbest: 2.1565346 (124)\ttotal: 864ms\tremaining: 1m 8s\n",
      "125:\tlearn: 2.0583246\ttest: 2.1559215\tbest: 2.1559215 (125)\ttotal: 870ms\tremaining: 1m 8s\n",
      "126:\tlearn: 2.0578291\ttest: 2.1564406\tbest: 2.1559215 (125)\ttotal: 876ms\tremaining: 1m 8s\n",
      "127:\tlearn: 2.0572290\ttest: 2.1559257\tbest: 2.1559215 (125)\ttotal: 882ms\tremaining: 1m 8s\n",
      "128:\tlearn: 2.0570066\ttest: 2.1557646\tbest: 2.1557646 (128)\ttotal: 888ms\tremaining: 1m 7s\n",
      "129:\tlearn: 2.0565552\ttest: 2.1551525\tbest: 2.1551525 (129)\ttotal: 895ms\tremaining: 1m 7s\n",
      "130:\tlearn: 2.0566514\ttest: 2.1552075\tbest: 2.1551525 (129)\ttotal: 901ms\tremaining: 1m 7s\n",
      "131:\tlearn: 2.0562054\ttest: 2.1548556\tbest: 2.1548556 (131)\ttotal: 908ms\tremaining: 1m 7s\n",
      "132:\tlearn: 2.0562132\ttest: 2.1547409\tbest: 2.1547409 (132)\ttotal: 917ms\tremaining: 1m 8s\n",
      "133:\tlearn: 2.0559612\ttest: 2.1547040\tbest: 2.1547040 (133)\ttotal: 925ms\tremaining: 1m 8s\n",
      "134:\tlearn: 2.0556565\ttest: 2.1542494\tbest: 2.1542494 (134)\ttotal: 932ms\tremaining: 1m 8s\n",
      "135:\tlearn: 2.0558305\ttest: 2.1543460\tbest: 2.1542494 (134)\ttotal: 934ms\tremaining: 1m 7s\n",
      "136:\tlearn: 2.0558812\ttest: 2.1544600\tbest: 2.1542494 (134)\ttotal: 941ms\tremaining: 1m 7s\n",
      "137:\tlearn: 2.0558358\ttest: 2.1544741\tbest: 2.1542494 (134)\ttotal: 948ms\tremaining: 1m 7s\n",
      "138:\tlearn: 2.0555876\ttest: 2.1543027\tbest: 2.1542494 (134)\ttotal: 955ms\tremaining: 1m 7s\n",
      "139:\tlearn: 2.0554352\ttest: 2.1542455\tbest: 2.1542455 (139)\ttotal: 962ms\tremaining: 1m 7s\n",
      "140:\tlearn: 2.0550932\ttest: 2.1540348\tbest: 2.1540348 (140)\ttotal: 968ms\tremaining: 1m 7s\n",
      "141:\tlearn: 2.0549172\ttest: 2.1542937\tbest: 2.1540348 (140)\ttotal: 977ms\tremaining: 1m 7s\n",
      "142:\tlearn: 2.0543572\ttest: 2.1541017\tbest: 2.1540348 (140)\ttotal: 983ms\tremaining: 1m 7s\n",
      "143:\tlearn: 2.0538218\ttest: 2.1545355\tbest: 2.1540348 (140)\ttotal: 990ms\tremaining: 1m 7s\n",
      "144:\tlearn: 2.0536148\ttest: 2.1548960\tbest: 2.1540348 (140)\ttotal: 997ms\tremaining: 1m 7s\n",
      "145:\tlearn: 2.0531981\ttest: 2.1544558\tbest: 2.1540348 (140)\ttotal: 1s\tremaining: 1m 7s\n",
      "146:\tlearn: 2.0529410\ttest: 2.1539989\tbest: 2.1539989 (146)\ttotal: 1.01s\tremaining: 1m 7s\n",
      "147:\tlearn: 2.0530401\ttest: 2.1540408\tbest: 2.1539989 (146)\ttotal: 1.02s\tremaining: 1m 7s\n",
      "148:\tlearn: 2.0526557\ttest: 2.1542497\tbest: 2.1539989 (146)\ttotal: 1.03s\tremaining: 1m 7s\n",
      "149:\tlearn: 2.0524440\ttest: 2.1542151\tbest: 2.1539989 (146)\ttotal: 1.04s\tremaining: 1m 8s\n",
      "150:\tlearn: 2.0523856\ttest: 2.1541873\tbest: 2.1539989 (146)\ttotal: 1.05s\tremaining: 1m 8s\n",
      "151:\tlearn: 2.0517303\ttest: 2.1535198\tbest: 2.1535198 (151)\ttotal: 1.05s\tremaining: 1m 8s\n",
      "152:\tlearn: 2.0515470\ttest: 2.1535499\tbest: 2.1535198 (151)\ttotal: 1.06s\tremaining: 1m 8s\n",
      "153:\tlearn: 2.0512901\ttest: 2.1531627\tbest: 2.1531627 (153)\ttotal: 1.07s\tremaining: 1m 8s\n",
      "154:\tlearn: 2.0511892\ttest: 2.1529755\tbest: 2.1529755 (154)\ttotal: 1.07s\tremaining: 1m 8s\n",
      "155:\tlearn: 2.0509082\ttest: 2.1527469\tbest: 2.1527469 (155)\ttotal: 1.08s\tremaining: 1m 8s\n",
      "156:\tlearn: 2.0503545\ttest: 2.1529683\tbest: 2.1527469 (155)\ttotal: 1.09s\tremaining: 1m 8s\n",
      "157:\tlearn: 2.0500449\ttest: 2.1526107\tbest: 2.1526107 (157)\ttotal: 1.1s\tremaining: 1m 8s\n",
      "158:\tlearn: 2.0499074\ttest: 2.1524725\tbest: 2.1524725 (158)\ttotal: 1.1s\tremaining: 1m 7s\n",
      "159:\tlearn: 2.0500553\ttest: 2.1526245\tbest: 2.1524725 (158)\ttotal: 1.1s\tremaining: 1m 7s\n",
      "160:\tlearn: 2.0496548\ttest: 2.1527656\tbest: 2.1524725 (158)\ttotal: 1.11s\tremaining: 1m 7s\n",
      "161:\tlearn: 2.0493284\ttest: 2.1523220\tbest: 2.1523220 (161)\ttotal: 1.12s\tremaining: 1m 7s\n",
      "162:\tlearn: 2.0490050\ttest: 2.1524995\tbest: 2.1523220 (161)\ttotal: 1.12s\tremaining: 1m 7s\n",
      "163:\tlearn: 2.0487814\ttest: 2.1524349\tbest: 2.1523220 (161)\ttotal: 1.13s\tremaining: 1m 7s\n",
      "164:\tlearn: 2.0485909\ttest: 2.1524116\tbest: 2.1523220 (161)\ttotal: 1.14s\tremaining: 1m 7s\n",
      "165:\tlearn: 2.0481656\ttest: 2.1525240\tbest: 2.1523220 (161)\ttotal: 1.14s\tremaining: 1m 7s\n",
      "166:\tlearn: 2.0478347\ttest: 2.1523554\tbest: 2.1523220 (161)\ttotal: 1.15s\tremaining: 1m 7s\n",
      "167:\tlearn: 2.0476286\ttest: 2.1524883\tbest: 2.1523220 (161)\ttotal: 1.16s\tremaining: 1m 7s\n",
      "168:\tlearn: 2.0475401\ttest: 2.1524234\tbest: 2.1523220 (161)\ttotal: 1.16s\tremaining: 1m 7s\n",
      "169:\tlearn: 2.0475365\ttest: 2.1523353\tbest: 2.1523220 (161)\ttotal: 1.17s\tremaining: 1m 7s\n",
      "170:\tlearn: 2.0472002\ttest: 2.1522450\tbest: 2.1522450 (170)\ttotal: 1.18s\tremaining: 1m 7s\n",
      "171:\tlearn: 2.0470389\ttest: 2.1526584\tbest: 2.1522450 (170)\ttotal: 1.19s\tremaining: 1m 7s\n",
      "172:\tlearn: 2.0471370\ttest: 2.1527095\tbest: 2.1522450 (170)\ttotal: 1.19s\tremaining: 1m 7s\n",
      "173:\tlearn: 2.0466581\ttest: 2.1528458\tbest: 2.1522450 (170)\ttotal: 1.2s\tremaining: 1m 7s\n",
      "174:\tlearn: 2.0465117\ttest: 2.1529040\tbest: 2.1522450 (170)\ttotal: 1.2s\tremaining: 1m 7s\n",
      "175:\tlearn: 2.0460974\ttest: 2.1530082\tbest: 2.1522450 (170)\ttotal: 1.21s\tremaining: 1m 7s\n",
      "176:\tlearn: 2.0455679\ttest: 2.1528659\tbest: 2.1522450 (170)\ttotal: 1.22s\tremaining: 1m 7s\n",
      "177:\tlearn: 2.0452679\ttest: 2.1525179\tbest: 2.1522450 (170)\ttotal: 1.23s\tremaining: 1m 7s\n",
      "178:\tlearn: 2.0450327\ttest: 2.1521654\tbest: 2.1521654 (178)\ttotal: 1.24s\tremaining: 1m 7s\n",
      "179:\tlearn: 2.0447164\ttest: 2.1519658\tbest: 2.1519658 (179)\ttotal: 1.24s\tremaining: 1m 7s\n",
      "180:\tlearn: 2.0447756\ttest: 2.1520104\tbest: 2.1519658 (179)\ttotal: 1.25s\tremaining: 1m 7s\n",
      "181:\tlearn: 2.0445785\ttest: 2.1520527\tbest: 2.1519658 (179)\ttotal: 1.26s\tremaining: 1m 7s\n",
      "182:\tlearn: 2.0442968\ttest: 2.1516772\tbest: 2.1516772 (182)\ttotal: 1.26s\tremaining: 1m 7s\n",
      "183:\tlearn: 2.0439952\ttest: 2.1515605\tbest: 2.1515605 (183)\ttotal: 1.27s\tremaining: 1m 7s\n",
      "184:\tlearn: 2.0438603\ttest: 2.1515361\tbest: 2.1515361 (184)\ttotal: 1.28s\tremaining: 1m 7s\n",
      "185:\tlearn: 2.0436199\ttest: 2.1515252\tbest: 2.1515252 (185)\ttotal: 1.28s\tremaining: 1m 7s\n",
      "186:\tlearn: 2.0431781\ttest: 2.1516846\tbest: 2.1515252 (185)\ttotal: 1.29s\tremaining: 1m 7s\n",
      "187:\tlearn: 2.0430574\ttest: 2.1517228\tbest: 2.1515252 (185)\ttotal: 1.3s\tremaining: 1m 7s\n",
      "188:\tlearn: 2.0431809\ttest: 2.1518754\tbest: 2.1515252 (185)\ttotal: 1.3s\tremaining: 1m 7s\n",
      "189:\tlearn: 2.0427315\ttest: 2.1515760\tbest: 2.1515252 (185)\ttotal: 1.31s\tremaining: 1m 7s\n",
      "190:\tlearn: 2.0425176\ttest: 2.1516585\tbest: 2.1515252 (185)\ttotal: 1.31s\tremaining: 1m 7s\n",
      "191:\tlearn: 2.0418779\ttest: 2.1515106\tbest: 2.1515106 (191)\ttotal: 1.32s\tremaining: 1m 7s\n",
      "192:\tlearn: 2.0416542\ttest: 2.1512748\tbest: 2.1512748 (192)\ttotal: 1.33s\tremaining: 1m 7s\n",
      "193:\tlearn: 2.0413249\ttest: 2.1513991\tbest: 2.1512748 (192)\ttotal: 1.33s\tremaining: 1m 7s\n",
      "194:\tlearn: 2.0407058\ttest: 2.1511273\tbest: 2.1511273 (194)\ttotal: 1.34s\tremaining: 1m 7s\n",
      "195:\tlearn: 2.0404300\ttest: 2.1510986\tbest: 2.1510986 (195)\ttotal: 1.35s\tremaining: 1m 7s\n",
      "196:\tlearn: 2.0402721\ttest: 2.1510692\tbest: 2.1510692 (196)\ttotal: 1.35s\tremaining: 1m 7s\n",
      "197:\tlearn: 2.0401884\ttest: 2.1510905\tbest: 2.1510692 (196)\ttotal: 1.36s\tremaining: 1m 7s\n",
      "198:\tlearn: 2.0398868\ttest: 2.1508244\tbest: 2.1508244 (198)\ttotal: 1.36s\tremaining: 1m 7s\n",
      "199:\tlearn: 2.0396672\ttest: 2.1510235\tbest: 2.1508244 (198)\ttotal: 1.37s\tremaining: 1m 7s\n",
      "200:\tlearn: 2.0396855\ttest: 2.1509663\tbest: 2.1508244 (198)\ttotal: 1.38s\tremaining: 1m 7s\n",
      "201:\tlearn: 2.0396940\ttest: 2.1509360\tbest: 2.1508244 (198)\ttotal: 1.38s\tremaining: 1m 7s\n",
      "202:\tlearn: 2.0395687\ttest: 2.1508437\tbest: 2.1508244 (198)\ttotal: 1.39s\tremaining: 1m 7s\n",
      "203:\tlearn: 2.0392805\ttest: 2.1510977\tbest: 2.1508244 (198)\ttotal: 1.39s\tremaining: 1m 6s\n",
      "204:\tlearn: 2.0389193\ttest: 2.1505733\tbest: 2.1505733 (204)\ttotal: 1.4s\tremaining: 1m 6s\n",
      "205:\tlearn: 2.0387174\ttest: 2.1504168\tbest: 2.1504168 (205)\ttotal: 1.41s\tremaining: 1m 6s\n",
      "206:\tlearn: 2.0385677\ttest: 2.1501945\tbest: 2.1501945 (206)\ttotal: 1.41s\tremaining: 1m 6s\n",
      "207:\tlearn: 2.0381822\ttest: 2.1498888\tbest: 2.1498888 (207)\ttotal: 1.42s\tremaining: 1m 6s\n",
      "208:\tlearn: 2.0376471\ttest: 2.1494785\tbest: 2.1494785 (208)\ttotal: 1.43s\tremaining: 1m 6s\n",
      "209:\tlearn: 2.0374712\ttest: 2.1494715\tbest: 2.1494715 (209)\ttotal: 1.44s\tremaining: 1m 6s\n",
      "210:\tlearn: 2.0373847\ttest: 2.1494140\tbest: 2.1494140 (210)\ttotal: 1.45s\tremaining: 1m 7s\n",
      "211:\tlearn: 2.0369912\ttest: 2.1496299\tbest: 2.1494140 (210)\ttotal: 1.45s\tremaining: 1m 7s\n",
      "212:\tlearn: 2.0369553\ttest: 2.1494615\tbest: 2.1494140 (210)\ttotal: 1.46s\tremaining: 1m 7s\n",
      "213:\tlearn: 2.0369098\ttest: 2.1494427\tbest: 2.1494140 (210)\ttotal: 1.47s\tremaining: 1m 7s\n",
      "214:\tlearn: 2.0366921\ttest: 2.1492285\tbest: 2.1492285 (214)\ttotal: 1.47s\tremaining: 1m 7s\n",
      "215:\tlearn: 2.0366326\ttest: 2.1492334\tbest: 2.1492285 (214)\ttotal: 1.48s\tremaining: 1m 7s\n",
      "216:\tlearn: 2.0365816\ttest: 2.1494406\tbest: 2.1492285 (214)\ttotal: 1.49s\tremaining: 1m 7s\n",
      "217:\tlearn: 2.0363470\ttest: 2.1495331\tbest: 2.1492285 (214)\ttotal: 1.49s\tremaining: 1m 6s\n",
      "218:\tlearn: 2.0358772\ttest: 2.1489876\tbest: 2.1489876 (218)\ttotal: 1.5s\tremaining: 1m 6s\n",
      "219:\tlearn: 2.0356795\ttest: 2.1489303\tbest: 2.1489303 (219)\ttotal: 1.5s\tremaining: 1m 6s\n",
      "220:\tlearn: 2.0352421\ttest: 2.1490753\tbest: 2.1489303 (219)\ttotal: 1.51s\tremaining: 1m 6s\n",
      "221:\tlearn: 2.0348623\ttest: 2.1485921\tbest: 2.1485921 (221)\ttotal: 1.52s\tremaining: 1m 6s\n",
      "222:\tlearn: 2.0346648\ttest: 2.1486013\tbest: 2.1485921 (221)\ttotal: 1.52s\tremaining: 1m 6s\n",
      "223:\tlearn: 2.0344312\ttest: 2.1485224\tbest: 2.1485224 (223)\ttotal: 1.53s\tremaining: 1m 6s\n",
      "224:\tlearn: 2.0342463\ttest: 2.1484425\tbest: 2.1484425 (224)\ttotal: 1.53s\tremaining: 1m 6s\n",
      "225:\tlearn: 2.0339626\ttest: 2.1480786\tbest: 2.1480786 (225)\ttotal: 1.54s\tremaining: 1m 6s\n",
      "226:\tlearn: 2.0331895\ttest: 2.1479974\tbest: 2.1479974 (226)\ttotal: 1.55s\tremaining: 1m 6s\n",
      "227:\tlearn: 2.0328346\ttest: 2.1481348\tbest: 2.1479974 (226)\ttotal: 1.55s\tremaining: 1m 6s\n",
      "228:\tlearn: 2.0328141\ttest: 2.1481510\tbest: 2.1479974 (226)\ttotal: 1.55s\tremaining: 1m 6s\n",
      "229:\tlearn: 2.0324893\ttest: 2.1482045\tbest: 2.1479974 (226)\ttotal: 1.56s\tremaining: 1m 6s\n",
      "230:\tlearn: 2.0319625\ttest: 2.1485198\tbest: 2.1479974 (226)\ttotal: 1.57s\tremaining: 1m 6s\n",
      "231:\tlearn: 2.0318124\ttest: 2.1483389\tbest: 2.1479974 (226)\ttotal: 1.57s\tremaining: 1m 6s\n",
      "232:\tlearn: 2.0313128\ttest: 2.1483688\tbest: 2.1479974 (226)\ttotal: 1.58s\tremaining: 1m 6s\n",
      "233:\tlearn: 2.0311034\ttest: 2.1485006\tbest: 2.1479974 (226)\ttotal: 1.59s\tremaining: 1m 6s\n",
      "234:\tlearn: 2.0307662\ttest: 2.1484856\tbest: 2.1479974 (226)\ttotal: 1.59s\tremaining: 1m 6s\n",
      "235:\tlearn: 2.0306129\ttest: 2.1484460\tbest: 2.1479974 (226)\ttotal: 1.6s\tremaining: 1m 6s\n",
      "236:\tlearn: 2.0300369\ttest: 2.1485912\tbest: 2.1479974 (226)\ttotal: 1.6s\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 2.1479974\n",
      "bestIteration = 226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shrink model to first 227 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('negs', 25.796996616639593),\n",
       " ('pos', 15.690237551091663),\n",
       " ('abs_sum_chg', 11.44808437360685),\n",
       " ('ssum', 8.523593360400719),\n",
       " ('r_sigma', 6.158298045482079),\n",
       " ('mean', 5.426830783926509),\n",
       " ('abs_nrg', 5.15330976785389),\n",
       " ('cid_ce', 4.306440013905397),\n",
       " ('std', 4.110897263640748),\n",
       " ('q75', 3.495115484409624),\n",
       " ('sum_reoccurr_dp', 3.4137884750860534),\n",
       " ('sum', 3.387658516691831),\n",
       " ('pos_head', 3.0887497472650667)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cb_model = CatBoostRegressor(iterations=10000,\n",
    "                             #learning_rate=0.05,\n",
    "                             eval_metric='MAE',\n",
    "                             #task_type = \"GPU\",\n",
    "                             use_best_model=True,\n",
    "                             od_type = \"Iter\",\n",
    "                             od_wait = 10,\n",
    "                             #depth=3,\n",
    "                             #border_count=254,\n",
    "                             #bagging_temperature = 3,\n",
    "                             #cat_features=[0],\n",
    "                             random_seed = 42)\n",
    "\n",
    "\n",
    "\n",
    "cb_model.fit(train_data[cb_features], train_y, #cat_features=categorical_features_indices,\n",
    "             eval_set=(val_data[cb_features],val_y),\n",
    "             #cat_features=categorical_features_pos,         \n",
    "             verbose=True)\n",
    "\n",
    "cb_scores = {}\n",
    "for i,score in enumerate(cb_model.get_feature_importance()):\n",
    "    cb_scores[cb_features[i]] = score\n",
    "\n",
    "sorted(cb_scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_features = [item[0] for item in cb_scores.items() if item[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.save_model(\"cb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3 rounds.\n",
      "[10]\tvalid_0's l1: 2.69091\n",
      "[20]\tvalid_0's l1: 2.44172\n",
      "[30]\tvalid_0's l1: 2.31659\n",
      "[40]\tvalid_0's l1: 2.2502\n",
      "[50]\tvalid_0's l1: 2.21469\n",
      "[60]\tvalid_0's l1: 2.19412\n",
      "[70]\tvalid_0's l1: 2.18055\n",
      "[80]\tvalid_0's l1: 2.17054\n",
      "[90]\tvalid_0's l1: 2.16586\n",
      "[100]\tvalid_0's l1: 2.16165\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 2.16118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('negs', 57),\n",
       " ('ssum', 40),\n",
       " ('pos', 31),\n",
       " ('mean', 29),\n",
       " ('r_sigma', 27),\n",
       " ('abs_sum_chg', 27),\n",
       " ('autocorr_10', 18),\n",
       " ('sum_reoccurr_dp', 16),\n",
       " ('pos_head', 9),\n",
       " ('mean_head', 9),\n",
       " ('skewness', 8),\n",
       " ('reocurring_pct', 8),\n",
       " ('abs_nrg', 8),\n",
       " ('neg_head', 7)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgtrain = lgbm.Dataset(train_data[lg_features], label=train_y)\n",
    "lgval = lgbm.Dataset(val_data[lg_features], label=val_y)\n",
    "\n",
    "\n",
    "# needs to keep overfiting under control, default params don't cut it at all\n",
    "params = {\n",
    "        \"num_threads\": 8,\n",
    "        \"verbosity\": -1,\n",
    "        #\"zero_as_missing\": \"true\",\n",
    "        \"boosting\":'gbdt',\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"mae\",\n",
    "        \"seed\": 42,\n",
    "        \"learning_rate\" : 0.05,\n",
    "        #\"min_data_in_leaf\": 100,\n",
    "        \"num_leaves\": 4,\n",
    "        #\"max_depth\" : 4,\n",
    "        #\"bagging_fraction\": 0.7,\n",
    "        #\"bagging_freq\": 1,\n",
    "        #\"feature_fraction\": 0.7,\n",
    "        #\"lambda_l1\": 10,\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "model_lgb = lgbm.train(params, lgtrain, 10000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=3, \n",
    "                      verbose_eval=10, \n",
    "                      evals_result=evals_result)\n",
    "\n",
    "\n",
    "lg_scores = {}\n",
    "for i,score in enumerate(model_lgb.feature_importance()):\n",
    "    lg_scores[lg_features[i]] = score\n",
    "\n",
    "sorted(lg_scores.items(), key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_features = [item[0] for item in lg_scores.items() if item[1] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f6befeb9a20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.save_model(\"lg_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  2.174876142058951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression,BayesianRidge, HuberRegressor\n",
    "\n",
    "lr_features = cb_features + lg_features\n",
    "\n",
    "lr_model =  LinearRegression()\n",
    "lr_model.fit(train_data[lr_features], train_y)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_preds = lr_model.predict(val_data[lr_features])\n",
    "print(\"mae: \", mean_absolute_error(val_y, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  2.1756378463224335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abs_sum_chg</th>\n",
       "      <td>0.430111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negs</th>\n",
       "      <td>0.378275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssum</th>\n",
       "      <td>0.071898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_sigma</th>\n",
       "      <td>0.019689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_reoccurr_dp</th>\n",
       "      <td>0.016514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autocorr_10</th>\n",
       "      <td>0.014917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.014874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>0.011579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_head</th>\n",
       "      <td>0.011303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_head</th>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_reoccurr_val</th>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "abs_sum_chg       0.430111  \n",
       "negs              0.378275  \n",
       "ssum              0.071898  \n",
       "r_sigma           0.019689  \n",
       "sum_reoccurr_dp   0.016514  \n",
       "autocorr_10       0.014917  \n",
       "pos               0.014874  \n",
       "sum               0.011579  \n",
       "pos_head          0.011303  \n",
       "mean              0.010878  \n",
       "mean_head         0.010438  \n",
       "sum_reoccurr_val  0.009524  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
    "rf_model.fit(train_data[rf_features], train_y)\n",
    "\n",
    "val_preds = rf_model.predict(val_data[rf_features])\n",
    "print(\"mae: \", mean_absolute_error(val_y, val_preds))\n",
    "\n",
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                        index = rf_features,\n",
    "                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = feature_importances[feature_importances['importance'] > 0.005].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_cb_preds = []\n",
    "stacked_lg_preds = []\n",
    "stacked_lr_preds = []\n",
    "stacked_rf_preds = []\n",
    "\n",
    "\n",
    "grouped = data[data['segment'].isin(shared_val_data)].sort_values(by='segment')\\\n",
    "            .drop(['augmented', 'time_to_failure'], axis=1)\\\n",
    "            .groupby('segment')\n",
    "\n",
    "\n",
    "for name, group in grouped:\n",
    "    stacked_cb_preds.append(cb_model.predict(group.drop(['segment'], axis=1)[cb_features])[0])\n",
    "    stacked_lg_preds.append(model_lgb.predict(group.drop(['segment'], axis=1)[lg_features])[0])\n",
    "    stacked_lr_preds.append(lr_model.predict(group.drop(['segment'], axis=1)[lr_features])[0])\n",
    "    stacked_rf_preds.append(rf_model.predict(group.drop(['segment'], axis=1)[rf_features])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm_preds = pickle.load(open(\"stacked_lstm_val.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_lstm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = pd.DataFrame(columns=['cb', 'lg', 'lr', 'rf', 'lstm', 'target'])\n",
    "stacked['cb'] = stacked_cb_preds\n",
    "stacked['lg'] = stacked_lg_preds\n",
    "stacked['lr'] = stacked_lr_preds\n",
    "stacked['rf'] = stacked_rf_preds\n",
    "\n",
    "stacked['lstm'] = stacked_lstm_preds\n",
    "stacked['target'] = data[data['segment'].isin(shared_val_data)]\\\n",
    "            .sort_values(by='segment')['time_to_failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cb</th>\n",
       "      <th>lg</th>\n",
       "      <th>lr</th>\n",
       "      <th>rf</th>\n",
       "      <th>lstm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.670437</td>\n",
       "      <td>5.676948</td>\n",
       "      <td>5.731730</td>\n",
       "      <td>5.689958</td>\n",
       "      <td>5.651226</td>\n",
       "      <td>5.624439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.511996</td>\n",
       "      <td>2.427609</td>\n",
       "      <td>2.528115</td>\n",
       "      <td>2.508108</td>\n",
       "      <td>2.876751</td>\n",
       "      <td>3.812896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.616565</td>\n",
       "      <td>2.168571</td>\n",
       "      <td>-0.641036</td>\n",
       "      <td>2.083151</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.334390</td>\n",
       "      <td>3.343795</td>\n",
       "      <td>3.665854</td>\n",
       "      <td>3.340644</td>\n",
       "      <td>3.311233</td>\n",
       "      <td>2.427723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.410076</td>\n",
       "      <td>5.459009</td>\n",
       "      <td>5.249059</td>\n",
       "      <td>5.380600</td>\n",
       "      <td>5.083039</td>\n",
       "      <td>5.060248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.119852</td>\n",
       "      <td>8.150925</td>\n",
       "      <td>7.908877</td>\n",
       "      <td>8.157234</td>\n",
       "      <td>8.324682</td>\n",
       "      <td>8.101398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.723187</td>\n",
       "      <td>9.995442</td>\n",
       "      <td>10.930895</td>\n",
       "      <td>10.269243</td>\n",
       "      <td>11.138508</td>\n",
       "      <td>15.907400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cb          lg          lr          rf        lstm      target\n",
       "count  420.000000  420.000000  420.000000  420.000000  420.000000  420.000000\n",
       "mean   5.670437    5.676948    5.731730    5.689958    5.651226    5.624439  \n",
       "std    2.511996    2.427609    2.528115    2.508108    2.876751    3.812896  \n",
       "min    1.616565    2.168571   -0.641036    2.083151    0.021533    0.007298  \n",
       "25%    3.334390    3.343795    3.665854    3.340644    3.311233    2.427723  \n",
       "50%    5.410076    5.459009    5.249059    5.380600    5.083039    5.060248  \n",
       "75%    8.119852    8.150925    7.908877    8.157234    8.324682    8.101398  \n",
       "max    10.723187   9.995442    10.930895   10.269243   11.138508   15.907400 "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cb</th>\n",
       "      <th>lg</th>\n",
       "      <th>lr</th>\n",
       "      <th>rf</th>\n",
       "      <th>lstm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>3.176438</td>\n",
       "      <td>3.231730</td>\n",
       "      <td>3.109987</td>\n",
       "      <td>3.507083</td>\n",
       "      <td>3.456000</td>\n",
       "      <td>2.747698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>9.036171</td>\n",
       "      <td>8.854511</td>\n",
       "      <td>9.186449</td>\n",
       "      <td>9.422650</td>\n",
       "      <td>9.382122</td>\n",
       "      <td>15.050897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>5.387594</td>\n",
       "      <td>5.396724</td>\n",
       "      <td>4.425759</td>\n",
       "      <td>5.590806</td>\n",
       "      <td>4.855852</td>\n",
       "      <td>2.383497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>7.889212</td>\n",
       "      <td>7.633675</td>\n",
       "      <td>7.518509</td>\n",
       "      <td>8.040081</td>\n",
       "      <td>9.043433</td>\n",
       "      <td>7.704498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.970706</td>\n",
       "      <td>7.777513</td>\n",
       "      <td>8.011529</td>\n",
       "      <td>8.248686</td>\n",
       "      <td>7.622410</td>\n",
       "      <td>5.170996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.080057</td>\n",
       "      <td>5.205100</td>\n",
       "      <td>4.493865</td>\n",
       "      <td>5.014412</td>\n",
       "      <td>4.914300</td>\n",
       "      <td>6.466496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2.260006</td>\n",
       "      <td>2.583559</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>2.254381</td>\n",
       "      <td>1.263363</td>\n",
       "      <td>6.888896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.486997</td>\n",
       "      <td>4.281732</td>\n",
       "      <td>5.209185</td>\n",
       "      <td>4.163997</td>\n",
       "      <td>5.115164</td>\n",
       "      <td>3.269299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>6.137800</td>\n",
       "      <td>5.988577</td>\n",
       "      <td>5.946808</td>\n",
       "      <td>6.160445</td>\n",
       "      <td>5.480802</td>\n",
       "      <td>8.076396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.557864</td>\n",
       "      <td>6.447178</td>\n",
       "      <td>6.271061</td>\n",
       "      <td>6.722218</td>\n",
       "      <td>7.079798</td>\n",
       "      <td>5.928599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cb        lg        lr        rf      lstm     target\n",
       "250  3.176438  3.231730  3.109987  3.507083  3.456000  2.747698 \n",
       "178  9.036171  8.854511  9.186449  9.422650  9.382122  15.050897\n",
       "226  5.387594  5.396724  4.425759  5.590806  4.855852  2.383497 \n",
       "297  7.889212  7.633675  7.518509  8.040081  9.043433  7.704498 \n",
       "140  7.970706  7.777513  8.011529  8.248686  7.622410  5.170996 \n",
       "121  5.080057  5.205100  4.493865  5.014412  4.914300  6.466496 \n",
       "381  2.260006  2.583559  0.022175  2.254381  1.263363  6.888896 \n",
       "31   4.486997  4.281732  5.209185  4.163997  5.115164  3.269299 \n",
       "190  6.137800  5.988577  5.946808  6.160445  5.480802  8.076396 \n",
       "86   6.557864  6.447178  6.271061  6.722218  7.079798  5.928599 "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.sample(10)\n",
    "#meta_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4194.000000\n",
       "mean     5.682698   \n",
       "std      3.673145   \n",
       "min      0.006398   \n",
       "25%      2.634173   \n",
       "50%      5.354847   \n",
       "75%      8.175924   \n",
       "max      16.103196  \n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_to_failure'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b878df940>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(column='time_to_failure')#.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  2.131716731112961\n"
     ]
    }
   ],
   "source": [
    "meta_model =  Lasso(positive=True, alpha=0.5)\n",
    "meta_model.fit(stacked.drop('target',axis=1), stacked['target'])\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "meta_preds = meta_model.predict(stacked.drop('target',axis=1))\n",
    "print(\"mae: \", mean_absolute_error(meta_preds, stacked['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44301687, 0.12964423, 0.40689408, 0.        , 0.        ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLITS='test'\n",
    "test_splits = [f for f in listdir(TEST_SPLITS) if isfile(join(TEST_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "test_split_chunks = np.array_split(test_splits,mp.cpu_count())\n",
    "    \n",
    "    \n",
    "param_test = True\n",
    "param_augment = False\n",
    "param_scale = False\n",
    "param_noise = 0.6\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    test_res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS,param_test,param_augment,param_scale,param_noise]) for chunk in test_split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624\n"
     ]
    }
   ],
   "source": [
    "columns=test_res[0].get()[0].columns.values\n",
    "\n",
    "test_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "i=0\n",
    "for r in test_res:\n",
    "    for df in r.get():\n",
    "        #print(df)\n",
    "        test_data = test_data.append(df)\n",
    "        #print(len(test_data))\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations2 = list(itertools.combinations(test_data.columns.values, 2))\n",
    "combinations3 = list(itertools.combinations(test_data.columns.values, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations2:\n",
    "    if 'seg_id' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    feature = f'{f1}_mult_{f2}'\n",
    "    test_data[feature] = test_data[f1] * test_data[f2]\n",
    "    feature = f'{f1}_plus_{f2}'\n",
    "    test_data[feature] = test_data[f1] + test_data[f2]\n",
    "    feature = f'{f1}_div_{f2}'\n",
    "    #print(feature)\n",
    "    test_data[feature] = test_data[f1] / test_data[f2]\n",
    "    test_data[feature] = pd.to_numeric(test_data[feature], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for combination in combinations3:\n",
    "    if 'seg_id' in combination or 'time_to_failure' in combination:\n",
    "        continue\n",
    "    f1 = combination[0]\n",
    "    f2 = combination[1]\n",
    "    f3 = combination[2]\n",
    "    feature = f'{f1}_mult_{f2}_mult_{f3}'\n",
    "    test_data[feature] = test_data[f1] * test_data[f2] * test_data[f3]\n",
    "    feature = f'{f1}_plus_{f2}_plus_{f3}'\n",
    "    test_data[feature] = test_data[f1] + test_data[f2] + test_data[f3]\n",
    "    feature = f'{f1}_div_{f2}_div_{f3}'\n",
    "    #print(feature)\n",
    "    test_data[feature] = test_data[f1] / test_data[f2] / test_data[f3]\n",
    "    test_data[feature] = pd.to_numeric(test_data[feature], downcast='float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data['seg_id'].apply(lambda id: id.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = cb_model.predict(test_data[cb_features])\n",
    "lg_preds = model_lgb.predict(test_data[lg_features])\n",
    "lr_preds = lr_model.predict(test_data[lr_features])\n",
    "rf_preds = rf_model.predict(test_data[rf_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr_model.predict(test_data[lr_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (lg_preds * 0.5) + (lr_preds * 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = rf_preds\n",
    "\n",
    "submission.to_csv('rf_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = pd.read_csv('cb_preds.csv')['time_to_failure']\n",
    "lg_preds = pd.read_csv('lg_preds.csv')['time_to_failure']\n",
    "lr_preds = pd.read_csv('lr_preds.csv')['time_to_failure']\n",
    "rf_preds = pd.read_csv('rf_preds.csv')['time_to_failure']\n",
    "lstm_preds = pd.read_csv('lstm_preds.csv')['time_to_failure']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98685109, 0.93244451, 0.98776879, 0.92942709],\n",
       "       [0.98685109, 1.        , 0.93064613, 0.98523281, 0.9349964 ],\n",
       "       [0.93244451, 0.93064613, 1.        , 0.92330153, 0.93254004],\n",
       "       [0.98776879, 0.98523281, 0.92330153, 1.        , 0.92384266],\n",
       "       [0.92942709, 0.9349964 , 0.93254004, 0.92384266, 1.        ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([cb_preds, lg_preds, lr_preds, rf_preds, lstm_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_test = pd.DataFrame(columns=['cb', 'lg', 'lr', 'rf', 'lstm'])\n",
    "stacked_test['cb'] = cb_preds\n",
    "stacked_test['lg'] = lg_preds\n",
    "stacked_test['lr'] = lr_preds\n",
    "stacked_test['rf'] = rf_preds\n",
    "stacked_test['lstm'] = lstm_preds\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(stacked_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = final_preds\n",
    "\n",
    "submission.to_csv('final_preds.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean     5.694498   \n",
       "std      2.444551   \n",
       "min     -6.191154   \n",
       "25%      3.691049   \n",
       "50%      5.144718   \n",
       "75%      7.775610   \n",
       "max      11.304780  \n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2624.000000\n",
       "mean     5.642406   \n",
       "std      2.223331   \n",
       "min     -4.319585   \n",
       "25%      3.883431   \n",
       "50%      5.081091   \n",
       "75%      7.549768   \n",
       "max      10.355927  \n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
