{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,Conv1D,TimeDistributed,MaxPooling1D,Flatten,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "columns = ['acoustic_data','time_to_failure']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(splits, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS=150000\n",
    "BATCH_SIZE=32\n",
    "NUMBER_OF_BATCHES = int(np.ceil(len(train_data)/BATCH_SIZE))\n",
    "NUMBER_OF_VALIDATION_STEPS = int(np.ceil(len(val_data) / BATCH_SIZE))\n",
    "NUMBER_OF_FEATURES=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batch = np.array_split(train_data, NUMBER_OF_BATCHES)\n",
    "val_data_batch = np.array_split(val_data, NUMBER_OF_VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE=0.75\n",
    "\n",
    "def add_noise(dff, pct=NOISE):\n",
    "    mu = dff['acoustic_data'].mean()\n",
    "    sigma = dff['acoustic_data'].std()\n",
    "\n",
    "    indices = np.random.choice(dff.index.values, int(len(dff)*pct))\n",
    "    dff.loc[indices, 'acoustic_data'] = np.random.normal(mu, sigma, len(indices)) \n",
    "    return dff\n",
    "\n",
    "\n",
    "def get_batch(list_of_files, valid=False):\n",
    "#     batch = np.empty((len(list_of_files),TIMESTEPS,1),dtype=float)\n",
    "#     target = np.empty((len(list_of_files),1),dtype=float)\n",
    "    #print(list_of_files)\n",
    "    batch = []\n",
    "    target = []\n",
    "\n",
    "    for idx, file in enumerate(list_of_files):\n",
    "        #print(idx,file)\n",
    "        path = f'train/{file}'\n",
    "        df = pd.read_csv(path, float_precision='round_trip', header=None)\n",
    "        df.columns = columns\n",
    "        df[['acoustic_data']] = StandardScaler().fit_transform(df[['acoustic_data']].astype('float'))\n",
    "        df['roll_1000'] = df['acoustic_data'].rolling(1000,min_periods=1000).mean()\n",
    "        df['roll_1000'].fillna(df['roll_1000'][1000],inplace=True)\n",
    "        df['shifted_1'] = df['roll_1000'].shift(1)\n",
    "        df['shifted_1'].fillna(df['roll_1000'][1000],inplace=True)\n",
    "        df[\"roll_diff_1\"] = df['shifted_1'] - df['roll_1000']\n",
    "        #df['shifted_1000'] = df['roll_1000'].shift(1000)\n",
    "        #df['shifted_1000'].fillna(df['roll_1000'][1000],inplace=True)\n",
    "        #df[\"roll_diff_1000\"] = df['shifted_1000'] - df['roll_1000']\n",
    "        #print(df.head())\n",
    "        #print(len(batch))\n",
    "        batch.append(df[['acoustic_data', 'roll_1000', 'roll_diff_1']].values)\n",
    "        target.append(df['time_to_failure'].values[-1])\n",
    "        #print(df_noise.head())\n",
    "        #if not valid:\n",
    "            #df_noise = add_noise(df)\n",
    "            #batch.append(df_noise['acoustic_data'].values)#.reshape(-1,TIMESTEPS,1))\n",
    "            #target.append(df_noise['time_to_failure'].values[-1])#.reshape(-1,1))\n",
    "        #print(np.array(batch).reshape(-1,TIMESTEPS,1).shape)\n",
    "        #batch = np.array(batch).reshape(-1,TIMESTEPS,1)\n",
    "        #target = np.array(target).reshape(-1,1)\n",
    "    return (batch, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class MY_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, list_of_files, steps,name):\n",
    "        self.list_of_files = list_of_files\n",
    "        self.steps = steps\n",
    "        self.name = name\n",
    "\n",
    "    #This function computes the number of batches that this generator is supposed to produce. \n",
    "    #So, we divide the number of total samples by the batch_size and return that value.    \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    #Here, given the batch numberidx you need to put together a list that consists of data \n",
    "    #batch and the ground-truth (GT). In this example, we read a batch images of size \n",
    "    #self.batch and return an array of form[image_batch, GT]\n",
    "    def __getitem__(self, idx):\n",
    "#         if self.name == 'val':\n",
    "        #print('idx', idx)\n",
    "        #print(\"DEBUG\", self.list_of_files[idx])\n",
    "        #if idx == len(self.list_of_files):\n",
    "            #print(idx, self.list_of_files)\n",
    "        if self.name == 'val':\n",
    "            valid = True\n",
    "        else:\n",
    "            valid=False\n",
    "        train,Y = get_batch(self.list_of_files[idx], valid)\n",
    "            \n",
    "        #print(np.array(train).reshape(-1,TIMESTEPS,1).shape)\n",
    "        #print(\"idx\",idx)\n",
    "        #print(\"LOLILOL\")\n",
    "        #print(train.shape, Y.shape)\n",
    "        train = np.array(train).reshape(-1,TIMESTEPS,NUMBER_OF_FEATURES)\n",
    "        #print(train.shape)\n",
    "        Y = np.array(Y).reshape(-1,1)\n",
    "\n",
    "        return (train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 30000, 2)          32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15000, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3000, 2)           22        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1500, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 300, 2)            22        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 150, 2)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 2)                 30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 5.4532 - mean_absolute_error: 5.4532\n",
      "\n",
      "118/118 [==============================] - 64s 540ms/step - loss: 5.4490 - mean_absolute_error: 5.4490 - val_loss: 5.2028 - val_mean_absolute_error: 5.2028\n",
      "\n",
      "Epoch 00001: val_mean_absolute_error improved from inf to 5.20281, saving model to weights.01-5.20.hdf5\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - 57s 486ms/step - loss: 4.7240 - mean_absolute_error: 4.7240 - val_loss: 4.4127 - val_mean_absolute_error: 4.4127\n",
      "\n",
      "Epoch 00002: val_mean_absolute_error improved from 5.20281 to 4.41267, saving model to weights.02-4.41.hdf5\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - 61s 518ms/step - loss: 3.9898 - mean_absolute_error: 3.9898 - val_loss: 3.7313 - val_mean_absolute_error: 3.7313\n",
      "\n",
      "Epoch 00003: val_mean_absolute_error improved from 4.41267 to 3.73126, saving model to weights.03-3.73.hdf5\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - 60s 507ms/step - loss: 3.4614 - mean_absolute_error: 3.4614 - val_loss: 3.2684 - val_mean_absolute_error: 3.2684\n",
      "\n",
      "Epoch 00004: val_mean_absolute_error improved from 3.73126 to 3.26843, saving model to weights.04-3.27.hdf5\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 3.1783 - mean_absolute_error: 3.1783 - val_loss: 3.0582 - val_mean_absolute_error: 3.0582\n",
      "\n",
      "Epoch 00005: val_mean_absolute_error improved from 3.26843 to 3.05815, saving model to weights.05-3.06.hdf5\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 3.0477 - mean_absolute_error: 3.0477 - val_loss: 2.9383 - val_mean_absolute_error: 2.9383\n",
      "\n",
      "Epoch 00006: val_mean_absolute_error improved from 3.05815 to 2.93833, saving model to weights.06-2.94.hdf5\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - 60s 507ms/step - loss: 2.8329 - mean_absolute_error: 2.8329 - val_loss: 2.7195 - val_mean_absolute_error: 2.7195\n",
      "\n",
      "Epoch 00007: val_mean_absolute_error improved from 2.93833 to 2.71950, saving model to weights.07-2.72.hdf5\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 2.5767 - mean_absolute_error: 2.5767 - val_loss: 2.5135 - val_mean_absolute_error: 2.5135\n",
      "\n",
      "Epoch 00008: val_mean_absolute_error improved from 2.71950 to 2.51350, saving model to weights.08-2.51.hdf5\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.4364 - mean_absolute_error: 2.4364 - val_loss: 2.4385 - val_mean_absolute_error: 2.4385\n",
      "\n",
      "Epoch 00009: val_mean_absolute_error improved from 2.51350 to 2.43852, saving model to weights.09-2.44.hdf5\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - 60s 508ms/step - loss: 2.3646 - mean_absolute_error: 2.3646 - val_loss: 2.3962 - val_mean_absolute_error: 2.3962\n",
      "\n",
      "Epoch 00010: val_mean_absolute_error improved from 2.43852 to 2.39624, saving model to weights.10-2.40.hdf5\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.3266 - mean_absolute_error: 2.3266 - val_loss: 2.3773 - val_mean_absolute_error: 2.3773\n",
      "\n",
      "Epoch 00011: val_mean_absolute_error improved from 2.39624 to 2.37734, saving model to weights.11-2.38.hdf5\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.3053 - mean_absolute_error: 2.3053 - val_loss: 2.3525 - val_mean_absolute_error: 2.3525\n",
      "\n",
      "Epoch 00012: val_mean_absolute_error improved from 2.37734 to 2.35252, saving model to weights.12-2.35.hdf5\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.2955 - mean_absolute_error: 2.2955 - val_loss: 2.3476 - val_mean_absolute_error: 2.3476\n",
      "\n",
      "Epoch 00013: val_mean_absolute_error improved from 2.35252 to 2.34762, saving model to weights.13-2.35.hdf5\n",
      "Epoch 14/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.3012 - mean_absolute_error: 2.3012 - val_loss: 2.3429 - val_mean_absolute_error: 2.3429\n",
      "\n",
      "Epoch 00014: val_mean_absolute_error improved from 2.34762 to 2.34291, saving model to weights.14-2.34.hdf5\n",
      "Epoch 15/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.2856 - mean_absolute_error: 2.2856 - val_loss: 2.3683 - val_mean_absolute_error: 2.3683\n",
      "\n",
      "Epoch 00015: val_mean_absolute_error did not improve from 2.34291\n",
      "Epoch 16/1000\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 2.2912 - mean_absolute_error: 2.2912 - val_loss: 2.3310 - val_mean_absolute_error: 2.3310\n",
      "\n",
      "Epoch 00016: val_mean_absolute_error improved from 2.34291 to 2.33095, saving model to weights.16-2.33.hdf5\n",
      "Epoch 17/1000\n",
      "118/118 [==============================] - 58s 492ms/step - loss: 2.2750 - mean_absolute_error: 2.2750 - val_loss: 2.3290 - val_mean_absolute_error: 2.3290\n",
      "\n",
      "Epoch 00017: val_mean_absolute_error improved from 2.33095 to 2.32903, saving model to weights.17-2.33.hdf5\n",
      "Epoch 18/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.2722 - mean_absolute_error: 2.2722 - val_loss: 2.3203 - val_mean_absolute_error: 2.3203\n",
      "\n",
      "Epoch 00018: val_mean_absolute_error improved from 2.32903 to 2.32029, saving model to weights.18-2.32.hdf5\n",
      "Epoch 19/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.2669 - mean_absolute_error: 2.2669 - val_loss: 2.3259 - val_mean_absolute_error: 2.3259\n",
      "\n",
      "Epoch 00019: val_mean_absolute_error did not improve from 2.32029\n",
      "Epoch 20/1000\n",
      "118/118 [==============================] - 58s 493ms/step - loss: 2.2639 - mean_absolute_error: 2.2639 - val_loss: 2.3146 - val_mean_absolute_error: 2.3146\n",
      "\n",
      "Epoch 00020: val_mean_absolute_error improved from 2.32029 to 2.31461, saving model to weights.20-2.31.hdf5\n",
      "Epoch 21/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.2601 - mean_absolute_error: 2.2601 - val_loss: 2.3172 - val_mean_absolute_error: 2.3172\n",
      "\n",
      "Epoch 00021: val_mean_absolute_error did not improve from 2.31461\n",
      "Epoch 22/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.2548 - mean_absolute_error: 2.2548 - val_loss: 2.3035 - val_mean_absolute_error: 2.3035\n",
      "\n",
      "Epoch 00022: val_mean_absolute_error improved from 2.31461 to 2.30351, saving model to weights.22-2.30.hdf5\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 58s 493ms/step - loss: 2.2575 - mean_absolute_error: 2.2575 - val_loss: 2.3058 - val_mean_absolute_error: 2.3058\n",
      "\n",
      "Epoch 00023: val_mean_absolute_error did not improve from 2.30351\n",
      "Epoch 24/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.2471 - mean_absolute_error: 2.2471 - val_loss: 2.2986 - val_mean_absolute_error: 2.2986\n",
      "\n",
      "Epoch 00024: val_mean_absolute_error improved from 2.30351 to 2.29864, saving model to weights.24-2.30.hdf5\n",
      "Epoch 25/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.2496 - mean_absolute_error: 2.2496 - val_loss: 2.2981 - val_mean_absolute_error: 2.2981\n",
      "\n",
      "Epoch 00025: val_mean_absolute_error improved from 2.29864 to 2.29809, saving model to weights.25-2.30.hdf5\n",
      "Epoch 26/1000\n",
      "118/118 [==============================] - 58s 495ms/step - loss: 2.2475 - mean_absolute_error: 2.2475 - val_loss: 2.2936 - val_mean_absolute_error: 2.2936\n",
      "\n",
      "Epoch 00026: val_mean_absolute_error improved from 2.29809 to 2.29360, saving model to weights.26-2.29.hdf5\n",
      "Epoch 27/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.2410 - mean_absolute_error: 2.2410 - val_loss: 2.2933 - val_mean_absolute_error: 2.2933\n",
      "\n",
      "Epoch 00027: val_mean_absolute_error improved from 2.29360 to 2.29325, saving model to weights.27-2.29.hdf5\n",
      "Epoch 28/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.2417 - mean_absolute_error: 2.2417 - val_loss: 2.2863 - val_mean_absolute_error: 2.2863\n",
      "\n",
      "Epoch 00028: val_mean_absolute_error improved from 2.29325 to 2.28630, saving model to weights.28-2.29.hdf5\n",
      "Epoch 29/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.2383 - mean_absolute_error: 2.2383 - val_loss: 2.2901 - val_mean_absolute_error: 2.2901\n",
      "\n",
      "Epoch 00029: val_mean_absolute_error did not improve from 2.28630\n",
      "Epoch 30/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.2311 - mean_absolute_error: 2.2311 - val_loss: 2.2806 - val_mean_absolute_error: 2.2806\n",
      "\n",
      "Epoch 00030: val_mean_absolute_error improved from 2.28630 to 2.28064, saving model to weights.30-2.28.hdf5\n",
      "Epoch 31/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.2269 - mean_absolute_error: 2.2269 - val_loss: 2.2889 - val_mean_absolute_error: 2.2889\n",
      "\n",
      "Epoch 00031: val_mean_absolute_error did not improve from 2.28064\n",
      "Epoch 32/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.2228 - mean_absolute_error: 2.2228 - val_loss: 2.2890 - val_mean_absolute_error: 2.2890\n",
      "\n",
      "Epoch 00032: val_mean_absolute_error did not improve from 2.28064\n",
      "Epoch 33/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.2202 - mean_absolute_error: 2.2202 - val_loss: 2.2679 - val_mean_absolute_error: 2.2679\n",
      "\n",
      "Epoch 00033: val_mean_absolute_error improved from 2.28064 to 2.26793, saving model to weights.33-2.27.hdf5\n",
      "Epoch 34/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.2216 - mean_absolute_error: 2.2216 - val_loss: 2.2741 - val_mean_absolute_error: 2.2741\n",
      "\n",
      "Epoch 00034: val_mean_absolute_error did not improve from 2.26793\n",
      "Epoch 35/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.2165 - mean_absolute_error: 2.2165 - val_loss: 2.2614 - val_mean_absolute_error: 2.2614\n",
      "\n",
      "Epoch 00035: val_mean_absolute_error improved from 2.26793 to 2.26135, saving model to weights.35-2.26.hdf5\n",
      "Epoch 36/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.2164 - mean_absolute_error: 2.2164 - val_loss: 2.2773 - val_mean_absolute_error: 2.2773\n",
      "\n",
      "Epoch 00036: val_mean_absolute_error did not improve from 2.26135\n",
      "Epoch 37/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.2125 - mean_absolute_error: 2.2125 - val_loss: 2.2544 - val_mean_absolute_error: 2.2544\n",
      "\n",
      "Epoch 00037: val_mean_absolute_error improved from 2.26135 to 2.25440, saving model to weights.37-2.25.hdf5\n",
      "Epoch 38/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.2052 - mean_absolute_error: 2.2052 - val_loss: 2.2517 - val_mean_absolute_error: 2.2517\n",
      "\n",
      "Epoch 00038: val_mean_absolute_error improved from 2.25440 to 2.25173, saving model to weights.38-2.25.hdf5\n",
      "Epoch 39/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.2039 - mean_absolute_error: 2.2039 - val_loss: 2.2469 - val_mean_absolute_error: 2.2469\n",
      "\n",
      "Epoch 00039: val_mean_absolute_error improved from 2.25173 to 2.24686, saving model to weights.39-2.25.hdf5\n",
      "Epoch 40/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.2034 - mean_absolute_error: 2.2034 - val_loss: 2.2439 - val_mean_absolute_error: 2.2439\n",
      "\n",
      "Epoch 00040: val_mean_absolute_error improved from 2.24686 to 2.24386, saving model to weights.40-2.24.hdf5\n",
      "Epoch 41/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.1965 - mean_absolute_error: 2.1965 - val_loss: 2.2522 - val_mean_absolute_error: 2.2522\n",
      "\n",
      "Epoch 00041: val_mean_absolute_error did not improve from 2.24386\n",
      "Epoch 42/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.1955 - mean_absolute_error: 2.1955 - val_loss: 2.3016 - val_mean_absolute_error: 2.3016\n",
      "\n",
      "Epoch 00042: val_mean_absolute_error did not improve from 2.24386\n",
      "Epoch 43/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.1868 - mean_absolute_error: 2.1868 - val_loss: 2.2292 - val_mean_absolute_error: 2.2292\n",
      "\n",
      "Epoch 00043: val_mean_absolute_error improved from 2.24386 to 2.22922, saving model to weights.43-2.23.hdf5\n",
      "Epoch 44/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.1853 - mean_absolute_error: 2.1853 - val_loss: 2.2327 - val_mean_absolute_error: 2.2327\n",
      "\n",
      "Epoch 00044: val_mean_absolute_error did not improve from 2.22922\n",
      "Epoch 45/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.1824 - mean_absolute_error: 2.1824 - val_loss: 2.2230 - val_mean_absolute_error: 2.2230\n",
      "\n",
      "Epoch 00045: val_mean_absolute_error improved from 2.22922 to 2.22299, saving model to weights.45-2.22.hdf5\n",
      "Epoch 46/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.1713 - mean_absolute_error: 2.1713 - val_loss: 2.2200 - val_mean_absolute_error: 2.2200\n",
      "\n",
      "Epoch 00046: val_mean_absolute_error improved from 2.22299 to 2.22002, saving model to weights.46-2.22.hdf5\n",
      "Epoch 47/1000\n",
      "118/118 [==============================] - 58s 491ms/step - loss: 2.1736 - mean_absolute_error: 2.1736 - val_loss: 2.2161 - val_mean_absolute_error: 2.2161\n",
      "\n",
      "Epoch 00047: val_mean_absolute_error improved from 2.22002 to 2.21607, saving model to weights.47-2.22.hdf5\n",
      "Epoch 48/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1692 - mean_absolute_error: 2.1692 - val_loss: 2.2101 - val_mean_absolute_error: 2.2101\n",
      "\n",
      "Epoch 00048: val_mean_absolute_error improved from 2.21607 to 2.21007, saving model to weights.48-2.21.hdf5\n",
      "Epoch 49/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.1594 - mean_absolute_error: 2.1594 - val_loss: 2.2170 - val_mean_absolute_error: 2.2170\n",
      "\n",
      "Epoch 00049: val_mean_absolute_error did not improve from 2.21007\n",
      "Epoch 50/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.1561 - mean_absolute_error: 2.1561 - val_loss: 2.2234 - val_mean_absolute_error: 2.2234\n",
      "\n",
      "Epoch 00050: val_mean_absolute_error did not improve from 2.21007\n",
      "Epoch 51/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.1521 - mean_absolute_error: 2.1521 - val_loss: 2.2170 - val_mean_absolute_error: 2.2170\n",
      "\n",
      "Epoch 00051: val_mean_absolute_error did not improve from 2.21007\n",
      "Epoch 52/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.1623 - mean_absolute_error: 2.1623 - val_loss: 2.1931 - val_mean_absolute_error: 2.1931\n",
      "\n",
      "Epoch 00052: val_mean_absolute_error improved from 2.21007 to 2.19310, saving model to weights.52-2.19.hdf5\n",
      "Epoch 53/1000\n",
      "118/118 [==============================] - 58s 492ms/step - loss: 2.1536 - mean_absolute_error: 2.1536 - val_loss: 2.1988 - val_mean_absolute_error: 2.1988\n",
      "\n",
      "Epoch 00053: val_mean_absolute_error did not improve from 2.19310\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1305 - mean_absolute_error: 2.1305 - val_loss: 2.1804 - val_mean_absolute_error: 2.1804\n",
      "\n",
      "Epoch 00054: val_mean_absolute_error improved from 2.19310 to 2.18040, saving model to weights.54-2.18.hdf5\n",
      "Epoch 55/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.1350 - mean_absolute_error: 2.1350 - val_loss: 2.1786 - val_mean_absolute_error: 2.1786\n",
      "\n",
      "Epoch 00055: val_mean_absolute_error improved from 2.18040 to 2.17863, saving model to weights.55-2.18.hdf5\n",
      "Epoch 56/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.1337 - mean_absolute_error: 2.1337 - val_loss: 2.1745 - val_mean_absolute_error: 2.1745\n",
      "\n",
      "Epoch 00056: val_mean_absolute_error improved from 2.17863 to 2.17446, saving model to weights.56-2.17.hdf5\n",
      "Epoch 57/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1371 - mean_absolute_error: 2.1371 - val_loss: 2.1794 - val_mean_absolute_error: 2.1794\n",
      "\n",
      "Epoch 00057: val_mean_absolute_error did not improve from 2.17446\n",
      "Epoch 58/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1356 - mean_absolute_error: 2.1356 - val_loss: 2.1696 - val_mean_absolute_error: 2.1696\n",
      "\n",
      "Epoch 00058: val_mean_absolute_error improved from 2.17446 to 2.16957, saving model to weights.58-2.17.hdf5\n",
      "Epoch 59/1000\n",
      "118/118 [==============================] - 58s 492ms/step - loss: 2.1236 - mean_absolute_error: 2.1236 - val_loss: 2.1891 - val_mean_absolute_error: 2.1891\n",
      "\n",
      "Epoch 00059: val_mean_absolute_error did not improve from 2.16957\n",
      "Epoch 60/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.1128 - mean_absolute_error: 2.1128 - val_loss: 2.1619 - val_mean_absolute_error: 2.1619\n",
      "\n",
      "Epoch 00060: val_mean_absolute_error improved from 2.16957 to 2.16187, saving model to weights.60-2.16.hdf5\n",
      "Epoch 61/1000\n",
      "118/118 [==============================] - 58s 492ms/step - loss: 2.1274 - mean_absolute_error: 2.1274 - val_loss: 2.1713 - val_mean_absolute_error: 2.1713\n",
      "\n",
      "Epoch 00061: val_mean_absolute_error did not improve from 2.16187\n",
      "Epoch 62/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1395 - mean_absolute_error: 2.1395 - val_loss: 2.1823 - val_mean_absolute_error: 2.1823\n",
      "\n",
      "Epoch 00062: val_mean_absolute_error did not improve from 2.16187\n",
      "Epoch 63/1000\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 2.1114 - mean_absolute_error: 2.1114 - val_loss: 2.1620 - val_mean_absolute_error: 2.1620\n",
      "\n",
      "Epoch 00063: val_mean_absolute_error did not improve from 2.16187\n",
      "Epoch 64/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.1070 - mean_absolute_error: 2.1070 - val_loss: 2.1538 - val_mean_absolute_error: 2.1538\n",
      "\n",
      "Epoch 00064: val_mean_absolute_error improved from 2.16187 to 2.15383, saving model to weights.64-2.15.hdf5\n",
      "Epoch 65/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1043 - mean_absolute_error: 2.1043 - val_loss: 2.2197 - val_mean_absolute_error: 2.2197\n",
      "\n",
      "Epoch 00065: val_mean_absolute_error did not improve from 2.15383\n",
      "Epoch 66/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.1017 - mean_absolute_error: 2.1017 - val_loss: 2.1922 - val_mean_absolute_error: 2.1922\n",
      "\n",
      "Epoch 00066: val_mean_absolute_error did not improve from 2.15383\n",
      "Epoch 67/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.1051 - mean_absolute_error: 2.1051 - val_loss: 2.1507 - val_mean_absolute_error: 2.1507\n",
      "\n",
      "Epoch 00067: val_mean_absolute_error improved from 2.15383 to 2.15073, saving model to weights.67-2.15.hdf5\n",
      "Epoch 68/1000\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 2.1030 - mean_absolute_error: 2.1030 - val_loss: 2.1584 - val_mean_absolute_error: 2.1584\n",
      "\n",
      "Epoch 00068: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 69/1000\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 2.1223 - mean_absolute_error: 2.1223 - val_loss: 2.2226 - val_mean_absolute_error: 2.2226\n",
      "\n",
      "Epoch 00069: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 70/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.1052 - mean_absolute_error: 2.1052 - val_loss: 2.1921 - val_mean_absolute_error: 2.1921\n",
      "\n",
      "Epoch 00070: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 71/1000\n",
      "118/118 [==============================] - 60s 504ms/step - loss: 2.1011 - mean_absolute_error: 2.1011 - val_loss: 2.1816 - val_mean_absolute_error: 2.1816\n",
      "\n",
      "Epoch 00071: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 72/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.0923 - mean_absolute_error: 2.0923 - val_loss: 2.2856 - val_mean_absolute_error: 2.2856\n",
      "\n",
      "Epoch 00072: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 73/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.1083 - mean_absolute_error: 2.1083 - val_loss: 2.1629 - val_mean_absolute_error: 2.1629\n",
      "\n",
      "Epoch 00073: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 74/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.1147 - mean_absolute_error: 2.1147 - val_loss: 2.2247 - val_mean_absolute_error: 2.2247\n",
      "\n",
      "Epoch 00074: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 75/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.1023 - mean_absolute_error: 2.1023 - val_loss: 2.1973 - val_mean_absolute_error: 2.1973\n",
      "\n",
      "Epoch 00075: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 76/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0935 - mean_absolute_error: 2.0935 - val_loss: 2.1512 - val_mean_absolute_error: 2.1512\n",
      "\n",
      "Epoch 00076: val_mean_absolute_error did not improve from 2.15073\n",
      "Epoch 77/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0881 - mean_absolute_error: 2.0881 - val_loss: 2.1395 - val_mean_absolute_error: 2.1395\n",
      "\n",
      "Epoch 00077: val_mean_absolute_error improved from 2.15073 to 2.13952, saving model to weights.77-2.14.hdf5\n",
      "Epoch 78/1000\n",
      "118/118 [==============================] - 58s 495ms/step - loss: 2.0898 - mean_absolute_error: 2.0898 - val_loss: 2.1664 - val_mean_absolute_error: 2.1664\n",
      "\n",
      "Epoch 00078: val_mean_absolute_error did not improve from 2.13952\n",
      "Epoch 79/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.0919 - mean_absolute_error: 2.0919 - val_loss: 2.1365 - val_mean_absolute_error: 2.1365\n",
      "\n",
      "Epoch 00079: val_mean_absolute_error improved from 2.13952 to 2.13650, saving model to weights.79-2.14.hdf5\n",
      "Epoch 80/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.0952 - mean_absolute_error: 2.0952 - val_loss: 2.1361 - val_mean_absolute_error: 2.1361\n",
      "\n",
      "Epoch 00080: val_mean_absolute_error improved from 2.13650 to 2.13611, saving model to weights.80-2.14.hdf5\n",
      "Epoch 81/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.0881 - mean_absolute_error: 2.0881 - val_loss: 2.1368 - val_mean_absolute_error: 2.1368\n",
      "\n",
      "Epoch 00081: val_mean_absolute_error did not improve from 2.13611\n",
      "Epoch 82/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.0922 - mean_absolute_error: 2.0922 - val_loss: 2.1519 - val_mean_absolute_error: 2.1519\n",
      "\n",
      "Epoch 00082: val_mean_absolute_error did not improve from 2.13611\n",
      "Epoch 83/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0868 - mean_absolute_error: 2.0868 - val_loss: 2.1639 - val_mean_absolute_error: 2.1639\n",
      "\n",
      "Epoch 00083: val_mean_absolute_error did not improve from 2.13611\n",
      "Epoch 84/1000\n",
      "118/118 [==============================] - 58s 496ms/step - loss: 2.0887 - mean_absolute_error: 2.0887 - val_loss: 2.1904 - val_mean_absolute_error: 2.1904\n",
      "\n",
      "Epoch 00084: val_mean_absolute_error did not improve from 2.13611\n",
      "Epoch 85/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0909 - mean_absolute_error: 2.0909 - val_loss: 2.1398 - val_mean_absolute_error: 2.1398\n",
      "\n",
      "Epoch 00085: val_mean_absolute_error did not improve from 2.13611\n",
      "Epoch 86/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0874 - mean_absolute_error: 2.0874 - val_loss: 2.1342 - val_mean_absolute_error: 2.1342\n",
      "\n",
      "Epoch 00086: val_mean_absolute_error improved from 2.13611 to 2.13423, saving model to weights.86-2.13.hdf5\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 58s 494ms/step - loss: 2.1000 - mean_absolute_error: 2.1000 - val_loss: 2.1323 - val_mean_absolute_error: 2.1323\n",
      "\n",
      "Epoch 00087: val_mean_absolute_error improved from 2.13423 to 2.13233, saving model to weights.87-2.13.hdf5\n",
      "Epoch 88/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.0880 - mean_absolute_error: 2.0880 - val_loss: 2.1411 - val_mean_absolute_error: 2.1411\n",
      "\n",
      "Epoch 00088: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 89/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0860 - mean_absolute_error: 2.0860 - val_loss: 2.1618 - val_mean_absolute_error: 2.1618\n",
      "\n",
      "Epoch 00089: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 90/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.0899 - mean_absolute_error: 2.0899 - val_loss: 2.1576 - val_mean_absolute_error: 2.1576\n",
      "\n",
      "Epoch 00090: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 91/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.0910 - mean_absolute_error: 2.0910 - val_loss: 2.1605 - val_mean_absolute_error: 2.1605\n",
      "\n",
      "Epoch 00091: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 92/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.0809 - mean_absolute_error: 2.0809 - val_loss: 2.1371 - val_mean_absolute_error: 2.1371\n",
      "\n",
      "Epoch 00092: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 93/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.0877 - mean_absolute_error: 2.0877 - val_loss: 2.1357 - val_mean_absolute_error: 2.1357\n",
      "\n",
      "Epoch 00093: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 94/1000\n",
      "118/118 [==============================] - 58s 493ms/step - loss: 2.0908 - mean_absolute_error: 2.0908 - val_loss: 2.1935 - val_mean_absolute_error: 2.1935\n",
      "\n",
      "Epoch 00094: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 95/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.0877 - mean_absolute_error: 2.0877 - val_loss: 2.1349 - val_mean_absolute_error: 2.1349\n",
      "\n",
      "Epoch 00095: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 96/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.0781 - mean_absolute_error: 2.0781 - val_loss: 2.1332 - val_mean_absolute_error: 2.1332\n",
      "\n",
      "Epoch 00096: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 97/1000\n",
      "118/118 [==============================] - 60s 506ms/step - loss: 2.0723 - mean_absolute_error: 2.0723 - val_loss: 2.1350 - val_mean_absolute_error: 2.1350\n",
      "\n",
      "Epoch 00097: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 98/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.0754 - mean_absolute_error: 2.0754 - val_loss: 2.1565 - val_mean_absolute_error: 2.1565\n",
      "\n",
      "Epoch 00098: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 99/1000\n",
      "118/118 [==============================] - 60s 504ms/step - loss: 2.0830 - mean_absolute_error: 2.0830 - val_loss: 2.1352 - val_mean_absolute_error: 2.1352\n",
      "\n",
      "Epoch 00099: val_mean_absolute_error did not improve from 2.13233\n",
      "Epoch 100/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.0728 - mean_absolute_error: 2.0728 - val_loss: 2.1318 - val_mean_absolute_error: 2.1318\n",
      "\n",
      "Epoch 00100: val_mean_absolute_error improved from 2.13233 to 2.13184, saving model to weights.100-2.13.hdf5\n",
      "Epoch 101/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0794 - mean_absolute_error: 2.0794 - val_loss: 2.2090 - val_mean_absolute_error: 2.2090\n",
      "\n",
      "Epoch 00101: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 102/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.1044 - mean_absolute_error: 2.1044 - val_loss: 2.1694 - val_mean_absolute_error: 2.1694\n",
      "\n",
      "Epoch 00102: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 103/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0881 - mean_absolute_error: 2.0881 - val_loss: 2.1455 - val_mean_absolute_error: 2.1455\n",
      "\n",
      "Epoch 00103: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 104/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.0751 - mean_absolute_error: 2.0751 - val_loss: 2.1489 - val_mean_absolute_error: 2.1489\n",
      "\n",
      "Epoch 00104: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 105/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0811 - mean_absolute_error: 2.0811 - val_loss: 2.1441 - val_mean_absolute_error: 2.1441\n",
      "\n",
      "Epoch 00105: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 106/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0717 - mean_absolute_error: 2.0717 - val_loss: 2.1420 - val_mean_absolute_error: 2.1420\n",
      "\n",
      "Epoch 00106: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 107/1000\n",
      "118/118 [==============================] - 60s 510ms/step - loss: 2.0677 - mean_absolute_error: 2.0677 - val_loss: 2.1404 - val_mean_absolute_error: 2.1404\n",
      "\n",
      "Epoch 00107: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 108/1000\n",
      "118/118 [==============================] - 61s 513ms/step - loss: 2.0678 - mean_absolute_error: 2.0678 - val_loss: 2.1484 - val_mean_absolute_error: 2.1484\n",
      "\n",
      "Epoch 00108: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 109/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0705 - mean_absolute_error: 2.0705 - val_loss: 2.1427 - val_mean_absolute_error: 2.1427\n",
      "\n",
      "Epoch 00109: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 110/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.0797 - mean_absolute_error: 2.0797 - val_loss: 2.1618 - val_mean_absolute_error: 2.1618\n",
      "\n",
      "Epoch 00110: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 111/1000\n",
      "118/118 [==============================] - 58s 495ms/step - loss: 2.0767 - mean_absolute_error: 2.0767 - val_loss: 2.1345 - val_mean_absolute_error: 2.1345\n",
      "\n",
      "Epoch 00111: val_mean_absolute_error did not improve from 2.13184\n",
      "Epoch 112/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.0775 - mean_absolute_error: 2.0775 - val_loss: 2.1313 - val_mean_absolute_error: 2.1313\n",
      "\n",
      "Epoch 00112: val_mean_absolute_error improved from 2.13184 to 2.13133, saving model to weights.112-2.13.hdf5\n",
      "Epoch 113/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0748 - mean_absolute_error: 2.0748 - val_loss: 2.1594 - val_mean_absolute_error: 2.1594\n",
      "\n",
      "Epoch 00113: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 114/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.0754 - mean_absolute_error: 2.0754 - val_loss: 2.1584 - val_mean_absolute_error: 2.1584\n",
      "\n",
      "Epoch 00114: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 115/1000\n",
      "118/118 [==============================] - 61s 517ms/step - loss: 2.0756 - mean_absolute_error: 2.0756 - val_loss: 2.1352 - val_mean_absolute_error: 2.1352\n",
      "\n",
      "Epoch 00115: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 116/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0730 - mean_absolute_error: 2.0730 - val_loss: 2.1325 - val_mean_absolute_error: 2.1325\n",
      "\n",
      "Epoch 00116: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 117/1000\n",
      "118/118 [==============================] - 60s 510ms/step - loss: 2.0748 - mean_absolute_error: 2.0748 - val_loss: 2.2023 - val_mean_absolute_error: 2.2023\n",
      "\n",
      "Epoch 00117: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 118/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0772 - mean_absolute_error: 2.0772 - val_loss: 2.1392 - val_mean_absolute_error: 2.1392\n",
      "\n",
      "Epoch 00118: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 119/1000\n",
      "118/118 [==============================] - 61s 517ms/step - loss: 2.0815 - mean_absolute_error: 2.0815 - val_loss: 2.1739 - val_mean_absolute_error: 2.1739\n",
      "\n",
      "Epoch 00119: val_mean_absolute_error did not improve from 2.13133\n",
      "Epoch 120/1000\n",
      "118/118 [==============================] - 62s 523ms/step - loss: 2.0814 - mean_absolute_error: 2.0814 - val_loss: 2.1308 - val_mean_absolute_error: 2.1308\n",
      "\n",
      "Epoch 00120: val_mean_absolute_error improved from 2.13133 to 2.13078, saving model to weights.120-2.13.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "118/118 [==============================] - 61s 520ms/step - loss: 2.0735 - mean_absolute_error: 2.0735 - val_loss: 2.1352 - val_mean_absolute_error: 2.1352\n",
      "\n",
      "Epoch 00121: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 122/1000\n",
      "118/118 [==============================] - 62s 524ms/step - loss: 2.0658 - mean_absolute_error: 2.0658 - val_loss: 2.1345 - val_mean_absolute_error: 2.1345\n",
      "\n",
      "Epoch 00122: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 123/1000\n",
      "118/118 [==============================] - 61s 521ms/step - loss: 2.0771 - mean_absolute_error: 2.0771 - val_loss: 2.1784 - val_mean_absolute_error: 2.1784\n",
      "\n",
      "Epoch 00123: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 124/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0687 - mean_absolute_error: 2.0687 - val_loss: 2.2007 - val_mean_absolute_error: 2.2007\n",
      "\n",
      "Epoch 00124: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 125/1000\n",
      "118/118 [==============================] - 62s 522ms/step - loss: 2.0711 - mean_absolute_error: 2.0711 - val_loss: 2.1347 - val_mean_absolute_error: 2.1347\n",
      "\n",
      "Epoch 00125: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 126/1000\n",
      "118/118 [==============================] - 62s 523ms/step - loss: 2.0667 - mean_absolute_error: 2.0667 - val_loss: 2.1520 - val_mean_absolute_error: 2.1520\n",
      "\n",
      "Epoch 00126: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 127/1000\n",
      "118/118 [==============================] - 62s 522ms/step - loss: 2.0713 - mean_absolute_error: 2.0713 - val_loss: 2.1430 - val_mean_absolute_error: 2.1430\n",
      "\n",
      "Epoch 00127: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 128/1000\n",
      "118/118 [==============================] - 61s 519ms/step - loss: 2.0668 - mean_absolute_error: 2.0668 - val_loss: 2.1343 - val_mean_absolute_error: 2.1343\n",
      "\n",
      "Epoch 00128: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 129/1000\n",
      "118/118 [==============================] - 62s 522ms/step - loss: 2.0743 - mean_absolute_error: 2.0743 - val_loss: 2.1752 - val_mean_absolute_error: 2.1752\n",
      "\n",
      "Epoch 00129: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 130/1000\n",
      "118/118 [==============================] - 62s 524ms/step - loss: 2.0635 - mean_absolute_error: 2.0635 - val_loss: 2.1460 - val_mean_absolute_error: 2.1460\n",
      "\n",
      "Epoch 00130: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 131/1000\n",
      "118/118 [==============================] - 62s 524ms/step - loss: 2.0645 - mean_absolute_error: 2.0645 - val_loss: 2.1490 - val_mean_absolute_error: 2.1490\n",
      "\n",
      "Epoch 00131: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 132/1000\n",
      "118/118 [==============================] - 62s 525ms/step - loss: 2.0650 - mean_absolute_error: 2.0650 - val_loss: 2.1461 - val_mean_absolute_error: 2.1461\n",
      "\n",
      "Epoch 00132: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 133/1000\n",
      "118/118 [==============================] - 62s 523ms/step - loss: 2.0732 - mean_absolute_error: 2.0732 - val_loss: 2.1349 - val_mean_absolute_error: 2.1349\n",
      "\n",
      "Epoch 00133: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 134/1000\n",
      "118/118 [==============================] - 61s 521ms/step - loss: 2.0746 - mean_absolute_error: 2.0746 - val_loss: 2.1400 - val_mean_absolute_error: 2.1400\n",
      "\n",
      "Epoch 00134: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 135/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0606 - mean_absolute_error: 2.0606 - val_loss: 2.1465 - val_mean_absolute_error: 2.1465\n",
      "\n",
      "Epoch 00135: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 136/1000\n",
      "118/118 [==============================] - 62s 521ms/step - loss: 2.0656 - mean_absolute_error: 2.0656 - val_loss: 2.1334 - val_mean_absolute_error: 2.1334\n",
      "\n",
      "Epoch 00136: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 137/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0609 - mean_absolute_error: 2.0609 - val_loss: 2.1416 - val_mean_absolute_error: 2.1416\n",
      "\n",
      "Epoch 00137: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 138/1000\n",
      "118/118 [==============================] - 62s 523ms/step - loss: 2.0648 - mean_absolute_error: 2.0648 - val_loss: 2.1522 - val_mean_absolute_error: 2.1522\n",
      "\n",
      "Epoch 00138: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 139/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0736 - mean_absolute_error: 2.0736 - val_loss: 2.1375 - val_mean_absolute_error: 2.1375\n",
      "\n",
      "Epoch 00139: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 140/1000\n",
      "118/118 [==============================] - 62s 526ms/step - loss: 2.0599 - mean_absolute_error: 2.0599 - val_loss: 2.1737 - val_mean_absolute_error: 2.1737\n",
      "\n",
      "Epoch 00140: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 141/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0663 - mean_absolute_error: 2.0663 - val_loss: 2.1738 - val_mean_absolute_error: 2.1738\n",
      "\n",
      "Epoch 00141: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 142/1000\n",
      "118/118 [==============================] - 61s 520ms/step - loss: 2.0668 - mean_absolute_error: 2.0668 - val_loss: 2.1441 - val_mean_absolute_error: 2.1441\n",
      "\n",
      "Epoch 00142: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 143/1000\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 2.0726 - mean_absolute_error: 2.0726 - val_loss: 2.1363 - val_mean_absolute_error: 2.1363\n",
      "\n",
      "Epoch 00143: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 144/1000\n",
      "118/118 [==============================] - 61s 519ms/step - loss: 2.0637 - mean_absolute_error: 2.0637 - val_loss: 2.1697 - val_mean_absolute_error: 2.1697\n",
      "\n",
      "Epoch 00144: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 145/1000\n",
      "118/118 [==============================] - 61s 513ms/step - loss: 2.0627 - mean_absolute_error: 2.0627 - val_loss: 2.1373 - val_mean_absolute_error: 2.1373\n",
      "\n",
      "Epoch 00145: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 146/1000\n",
      "118/118 [==============================] - 62s 526ms/step - loss: 2.0757 - mean_absolute_error: 2.0757 - val_loss: 2.1335 - val_mean_absolute_error: 2.1335\n",
      "\n",
      "Epoch 00146: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 147/1000\n",
      "118/118 [==============================] - 61s 516ms/step - loss: 2.0611 - mean_absolute_error: 2.0611 - val_loss: 2.1415 - val_mean_absolute_error: 2.1415\n",
      "\n",
      "Epoch 00147: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 148/1000\n",
      "118/118 [==============================] - 60s 512ms/step - loss: 2.0549 - mean_absolute_error: 2.0549 - val_loss: 2.1456 - val_mean_absolute_error: 2.1456\n",
      "\n",
      "Epoch 00148: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 149/1000\n",
      "118/118 [==============================] - 60s 506ms/step - loss: 2.0763 - mean_absolute_error: 2.0763 - val_loss: 2.1539 - val_mean_absolute_error: 2.1539\n",
      "\n",
      "Epoch 00149: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 150/1000\n",
      "118/118 [==============================] - 60s 511ms/step - loss: 2.0623 - mean_absolute_error: 2.0623 - val_loss: 2.1905 - val_mean_absolute_error: 2.1905\n",
      "\n",
      "Epoch 00150: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 151/1000\n",
      "118/118 [==============================] - 63s 535ms/step - loss: 2.0634 - mean_absolute_error: 2.0634 - val_loss: 2.1666 - val_mean_absolute_error: 2.1666\n",
      "\n",
      "Epoch 00151: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 152/1000\n",
      "118/118 [==============================] - 64s 545ms/step - loss: 2.0726 - mean_absolute_error: 2.0726 - val_loss: 2.2050 - val_mean_absolute_error: 2.2050\n",
      "\n",
      "Epoch 00152: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 153/1000\n",
      "118/118 [==============================] - 63s 535ms/step - loss: 2.0655 - mean_absolute_error: 2.0655 - val_loss: 2.2026 - val_mean_absolute_error: 2.2026\n",
      "\n",
      "Epoch 00153: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 154/1000\n",
      "118/118 [==============================] - 60s 512ms/step - loss: 2.0695 - mean_absolute_error: 2.0695 - val_loss: 2.1705 - val_mean_absolute_error: 2.1705\n",
      "\n",
      "Epoch 00154: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 60s 509ms/step - loss: 2.0581 - mean_absolute_error: 2.0581 - val_loss: 2.1414 - val_mean_absolute_error: 2.1414\n",
      "\n",
      "Epoch 00155: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 156/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0604 - mean_absolute_error: 2.0604 - val_loss: 2.1353 - val_mean_absolute_error: 2.1353\n",
      "\n",
      "Epoch 00156: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 157/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0512 - mean_absolute_error: 2.0512 - val_loss: 2.1455 - val_mean_absolute_error: 2.1455\n",
      "\n",
      "Epoch 00157: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 158/1000\n",
      "118/118 [==============================] - 61s 519ms/step - loss: 2.0623 - mean_absolute_error: 2.0623 - val_loss: 2.1324 - val_mean_absolute_error: 2.1324\n",
      "\n",
      "Epoch 00158: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 159/1000\n",
      "118/118 [==============================] - 61s 513ms/step - loss: 2.0558 - mean_absolute_error: 2.0558 - val_loss: 2.2434 - val_mean_absolute_error: 2.2434\n",
      "\n",
      "Epoch 00159: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 160/1000\n",
      "118/118 [==============================] - 62s 525ms/step - loss: 2.0850 - mean_absolute_error: 2.0850 - val_loss: 2.1338 - val_mean_absolute_error: 2.1338\n",
      "\n",
      "Epoch 00160: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 161/1000\n",
      "118/118 [==============================] - 65s 549ms/step - loss: 2.0607 - mean_absolute_error: 2.0607 - val_loss: 2.1507 - val_mean_absolute_error: 2.1507\n",
      "\n",
      "Epoch 00161: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 162/1000\n",
      "118/118 [==============================] - 62s 526ms/step - loss: 2.0687 - mean_absolute_error: 2.0687 - val_loss: 2.1444 - val_mean_absolute_error: 2.1444\n",
      "\n",
      "Epoch 00162: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 163/1000\n",
      "118/118 [==============================] - 63s 538ms/step - loss: 2.0638 - mean_absolute_error: 2.0638 - val_loss: 2.1437 - val_mean_absolute_error: 2.1437\n",
      "\n",
      "Epoch 00163: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 164/1000\n",
      "118/118 [==============================] - 63s 530ms/step - loss: 2.0620 - mean_absolute_error: 2.0620 - val_loss: 2.1360 - val_mean_absolute_error: 2.1360\n",
      "\n",
      "Epoch 00164: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 165/1000\n",
      "118/118 [==============================] - 63s 534ms/step - loss: 2.0606 - mean_absolute_error: 2.0606 - val_loss: 2.1393 - val_mean_absolute_error: 2.1393\n",
      "\n",
      "Epoch 00165: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 166/1000\n",
      "118/118 [==============================] - 60s 508ms/step - loss: 2.0666 - mean_absolute_error: 2.0666 - val_loss: 2.1358 - val_mean_absolute_error: 2.1358\n",
      "\n",
      "Epoch 00166: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 167/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0559 - mean_absolute_error: 2.0559 - val_loss: 2.1554 - val_mean_absolute_error: 2.1554\n",
      "\n",
      "Epoch 00167: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 168/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0673 - mean_absolute_error: 2.0673 - val_loss: 2.1599 - val_mean_absolute_error: 2.1599\n",
      "\n",
      "Epoch 00168: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 169/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0576 - mean_absolute_error: 2.0576 - val_loss: 2.1426 - val_mean_absolute_error: 2.1426\n",
      "\n",
      "Epoch 00169: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 170/1000\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 2.0599 - mean_absolute_error: 2.0599 - val_loss: 2.1361 - val_mean_absolute_error: 2.1361\n",
      "\n",
      "Epoch 00170: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 171/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0565 - mean_absolute_error: 2.0565 - val_loss: 2.1435 - val_mean_absolute_error: 2.1435\n",
      "\n",
      "Epoch 00171: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 172/1000\n",
      "118/118 [==============================] - 60s 506ms/step - loss: 2.0593 - mean_absolute_error: 2.0593 - val_loss: 2.1518 - val_mean_absolute_error: 2.1518\n",
      "\n",
      "Epoch 00172: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 173/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0638 - mean_absolute_error: 2.0638 - val_loss: 2.1439 - val_mean_absolute_error: 2.1439\n",
      "\n",
      "Epoch 00173: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 174/1000\n",
      "118/118 [==============================] - 59s 500ms/step - loss: 2.0643 - mean_absolute_error: 2.0643 - val_loss: 2.1489 - val_mean_absolute_error: 2.1489\n",
      "\n",
      "Epoch 00174: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 175/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0545 - mean_absolute_error: 2.0545 - val_loss: 2.1970 - val_mean_absolute_error: 2.1970\n",
      "\n",
      "Epoch 00175: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 176/1000\n",
      "118/118 [==============================] - 59s 498ms/step - loss: 2.0635 - mean_absolute_error: 2.0635 - val_loss: 2.1436 - val_mean_absolute_error: 2.1436\n",
      "\n",
      "Epoch 00176: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 177/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0542 - mean_absolute_error: 2.0542 - val_loss: 2.1375 - val_mean_absolute_error: 2.1375\n",
      "\n",
      "Epoch 00177: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 178/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0603 - mean_absolute_error: 2.0603 - val_loss: 2.1559 - val_mean_absolute_error: 2.1559\n",
      "\n",
      "Epoch 00178: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 179/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0616 - mean_absolute_error: 2.0616 - val_loss: 2.1582 - val_mean_absolute_error: 2.1582\n",
      "\n",
      "Epoch 00179: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 180/1000\n",
      "118/118 [==============================] - 60s 507ms/step - loss: 2.0581 - mean_absolute_error: 2.0581 - val_loss: 2.1491 - val_mean_absolute_error: 2.1491\n",
      "\n",
      "Epoch 00180: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 181/1000\n",
      "118/118 [==============================] - 59s 497ms/step - loss: 2.0578 - mean_absolute_error: 2.0578 - val_loss: 2.1378 - val_mean_absolute_error: 2.1378\n",
      "\n",
      "Epoch 00181: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 182/1000\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 2.0628 - mean_absolute_error: 2.0628 - val_loss: 2.1504 - val_mean_absolute_error: 2.1504\n",
      "\n",
      "Epoch 00182: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 183/1000\n",
      "118/118 [==============================] - 60s 506ms/step - loss: 2.0666 - mean_absolute_error: 2.0666 - val_loss: 2.1427 - val_mean_absolute_error: 2.1427\n",
      "\n",
      "Epoch 00183: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 184/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0523 - mean_absolute_error: 2.0523 - val_loss: 2.1422 - val_mean_absolute_error: 2.1422\n",
      "\n",
      "Epoch 00184: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 185/1000\n",
      "118/118 [==============================] - 59s 499ms/step - loss: 2.0639 - mean_absolute_error: 2.0639 - val_loss: 2.1600 - val_mean_absolute_error: 2.1600\n",
      "\n",
      "Epoch 00185: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 186/1000\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 2.0600 - mean_absolute_error: 2.0600 - val_loss: 2.1519 - val_mean_absolute_error: 2.1519\n",
      "\n",
      "Epoch 00186: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 187/1000\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 2.0624 - mean_absolute_error: 2.0624 - val_loss: 2.1421 - val_mean_absolute_error: 2.1421\n",
      "\n",
      "Epoch 00187: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 188/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0581 - mean_absolute_error: 2.0581 - val_loss: 2.1442 - val_mean_absolute_error: 2.1442\n",
      "\n",
      "Epoch 00188: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 189/1000\n",
      "118/118 [==============================] - 60s 505ms/step - loss: 2.0551 - mean_absolute_error: 2.0551 - val_loss: 2.1385 - val_mean_absolute_error: 2.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00189: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 190/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0610 - mean_absolute_error: 2.0610 - val_loss: 2.1396 - val_mean_absolute_error: 2.1396\n",
      "\n",
      "Epoch 00190: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 191/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0647 - mean_absolute_error: 2.0647 - val_loss: 2.1456 - val_mean_absolute_error: 2.1456\n",
      "\n",
      "Epoch 00191: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 192/1000\n",
      "118/118 [==============================] - 59s 496ms/step - loss: 2.0495 - mean_absolute_error: 2.0495 - val_loss: 2.1524 - val_mean_absolute_error: 2.1524\n",
      "\n",
      "Epoch 00192: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 193/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0529 - mean_absolute_error: 2.0529 - val_loss: 2.1499 - val_mean_absolute_error: 2.1499\n",
      "\n",
      "Epoch 00193: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 194/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0570 - mean_absolute_error: 2.0570 - val_loss: 2.1390 - val_mean_absolute_error: 2.1390\n",
      "\n",
      "Epoch 00194: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 195/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0547 - mean_absolute_error: 2.0547 - val_loss: 2.1386 - val_mean_absolute_error: 2.1386\n",
      "\n",
      "Epoch 00195: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 196/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0543 - mean_absolute_error: 2.0543 - val_loss: 2.1851 - val_mean_absolute_error: 2.1851\n",
      "\n",
      "Epoch 00196: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 197/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0787 - mean_absolute_error: 2.0787 - val_loss: 2.1421 - val_mean_absolute_error: 2.1421\n",
      "\n",
      "Epoch 00197: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 198/1000\n",
      "118/118 [==============================] - 59s 502ms/step - loss: 2.0555 - mean_absolute_error: 2.0555 - val_loss: 2.1403 - val_mean_absolute_error: 2.1403\n",
      "\n",
      "Epoch 00198: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 199/1000\n",
      "118/118 [==============================] - 61s 513ms/step - loss: 2.0572 - mean_absolute_error: 2.0572 - val_loss: 2.1495 - val_mean_absolute_error: 2.1495\n",
      "\n",
      "Epoch 00199: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 200/1000\n",
      "118/118 [==============================] - 59s 504ms/step - loss: 2.0648 - mean_absolute_error: 2.0648 - val_loss: 2.1704 - val_mean_absolute_error: 2.1704\n",
      "\n",
      "Epoch 00200: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 201/1000\n",
      "118/118 [==============================] - 59s 503ms/step - loss: 2.0699 - mean_absolute_error: 2.0699 - val_loss: 2.1457 - val_mean_absolute_error: 2.1457\n",
      "\n",
      "Epoch 00201: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 202/1000\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 2.0665 - mean_absolute_error: 2.0665 - val_loss: 2.1556 - val_mean_absolute_error: 2.1556\n",
      "\n",
      "Epoch 00202: val_mean_absolute_error did not improve from 2.13078\n",
      "Epoch 203/1000\n"
     ]
    }
   ],
   "source": [
    "#train_data, val_data, y_train, y_val = train_test_split(training, targets, test_size=0.1, random_state=42)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "TIMESTEPS=150000\n",
    "\n",
    "units=2\n",
    "dropout=0\n",
    "\n",
    "kernel_size=5\n",
    "filters=2\n",
    "strides=5\n",
    "pool_size=2\n",
    "regularizer=l2(0)\n",
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation=\"relu\",\n",
    "               kernel_regularizer=regularizer,\n",
    "               strides=strides, input_shape=(TIMESTEPS,NUMBER_OF_FEATURES))\n",
    ")\n",
    "             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "#y_model.add(BatchNormalization())\n",
    "\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu',\n",
    "               kernel_regularizer=regularizer,\n",
    "               strides=strides, input_shape=(TIMESTEPS,NUMBER_OF_FEATURES))\n",
    ")             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "#y_model.add(BatchNormalization())\n",
    "\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu',\n",
    "               kernel_regularizer=regularizer,\n",
    "               strides=strides, input_shape=(TIMESTEPS,NUMBER_OF_FEATURES))\n",
    ")             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "#y_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "my_model.add(GRU(units = units,dropout=dropout,recurrent_dropout=dropout))\n",
    "\n",
    "my_model.add(Dense(10, activation='relu'))\n",
    "\n",
    "\n",
    "#y_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "my_model.compile(loss = 'mae',optimizer = 'adam', metrics = ['mean_absolute_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "filepath=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "callbacks = [\n",
    "    #EarlyStopping(monitor='val_loss', patience=30, verbose=0),\n",
    "    ModelCheckpoint(filepath, monitor='val_mean_absolute_error', verbose=1, \n",
    "                    save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "my_training_batch_generator = MY_Generator(train_data_batch, NUMBER_OF_BATCHES, 'train')\n",
    "my_validation_batch_generator = MY_Generator(val_data_batch, NUMBER_OF_VALIDATION_STEPS, 'val')\n",
    "\n",
    "\n",
    "history = my_model.fit_generator(generator=my_training_batch_generator,\n",
    "                                      #steps_per_epoch=NUMBER_OF_BATCHES,\n",
    "                                      epochs=1000,\n",
    "                                      validation_data=my_validation_batch_generator,\n",
    "                                      #validation_steps=NUMBER_OF_VALIDATION_STEPS,\n",
    "                                      callbacks=callbacks,\n",
    "                                      shuffle=True,\n",
    "                                      #verbose=1,\n",
    "                                      #validation_data=my_validation_batch_generator,\n",
    "                                      #validation_steps=(num_validation_samples // batch_size),\n",
    "                                      use_multiprocessing=True,\n",
    "                                      workers=8,\n",
    "                                      max_queue_size=32\n",
    "                  )\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "#import math\n",
    "#print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))\n",
    "\n",
    "\n",
    "#my_model.load_weights('weights.515-2.17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLITS='test'\n",
    "test_splits = [f for f in listdir(TEST_SPLITS) if isfile(join(TEST_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits\n",
    "\n",
    "ids = []\n",
    "preds = []\n",
    "\n",
    "i = 0\n",
    "for test_file in test_splits:\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    path = f'test/{test_file}'\n",
    "    df = pd.read_csv(path, float_precision='round_trip', header=0)\n",
    "    df.columns = ['acoustic_data']\n",
    "    df[['acoustic_data']] = StandardScaler().fit_transform(df[['acoustic_data']].astype('float'))\n",
    "    ids.append(test_file.split(\".\")[0])\n",
    "    preds.append(my_model.predict(df['acoustic_data'].values.reshape(1,TIMESTEPS,1))[0][0])\n",
    "    i+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res[0].get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test/%s' % (np.random.choice(test_splits))\n",
    "#\n",
    "\n",
    "df = pd.read_csv(path, float_precision='round_trip', header=[0])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
