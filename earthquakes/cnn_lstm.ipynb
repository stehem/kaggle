{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import gc\n",
    "import pickle as pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tail -n +2 train.csv | split -l 150000\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "TRAIN_SPLITS='train'\n",
    "splits = [f for f in listdir(TRAIN_SPLITS) if isfile(join(TRAIN_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "columns = ['acoustic_data','time_to_failure']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(splits, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS=150000\n",
    "BATCH_SIZE=16\n",
    "NUMBER_OF_BATCHES = int(np.ceil(len(train_data)/BATCH_SIZE))\n",
    "NUMBER_OF_VALIDATION_STEPS = int(np.ceil(len(val_data) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batch = np.array_split(train_data, NUMBER_OF_BATCHES)\n",
    "val_data_batch = np.array_split(val_data, NUMBER_OF_VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE=0.75\n",
    "\n",
    "def add_noise(dff, pct=NOISE):\n",
    "    mu = dff['acoustic_data'].mean()\n",
    "    sigma = dff['acoustic_data'].std()\n",
    "\n",
    "    indices = np.random.choice(dff.index.values, int(len(dff)*pct))\n",
    "    dff.loc[indices, 'acoustic_data'] = np.random.normal(mu, sigma, len(indices)) \n",
    "    return dff\n",
    "\n",
    "\n",
    "def get_batch(list_of_files):\n",
    "#     batch = np.empty((len(list_of_files),TIMESTEPS,1),dtype=float)\n",
    "#     target = np.empty((len(list_of_files),1),dtype=float)\n",
    "    #print(list_of_files)\n",
    "    batch = []\n",
    "    target = []\n",
    "\n",
    "    for idx, file in enumerate(list_of_files):\n",
    "        #print(idx,file)\n",
    "        path = f'train/{file}'\n",
    "        df = pd.read_csv(path, float_precision='round_trip', header=None)\n",
    "        df.columns = columns\n",
    "        df[['acoustic_data']] = StandardScaler().fit_transform(df[['acoustic_data']].astype('float'))\n",
    "        #print(df.head())\n",
    "        #print(len(batch))\n",
    "        batch.append(df['acoustic_data'].values)\n",
    "        target.append(df['time_to_failure'].values[-1])\n",
    "        df_noise = add_noise(df)\n",
    "        #print(df_noise.head())\n",
    "        batch.append(df_noise['acoustic_data'].values)#.reshape(-1,TIMESTEPS,1))\n",
    "        target.append(df_noise['time_to_failure'].values[-1])#.reshape(-1,1))\n",
    "        #print(np.array(batch).reshape(-1,TIMESTEPS,1).shape)\n",
    "        #batch = np.array(batch).reshape(-1,TIMESTEPS,1)\n",
    "        #target = np.array(target).reshape(-1,1)\n",
    "    return (batch, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class MY_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, list_of_files, steps,name):\n",
    "        self.list_of_files = list_of_files\n",
    "        self.steps = steps\n",
    "        self.name = name\n",
    "\n",
    "    #This function computes the number of batches that this generator is supposed to produce. \n",
    "    #So, we divide the number of total samples by the batch_size and return that value.    \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    #Here, given the batch numberidx you need to put together a list that consists of data \n",
    "    #batch and the ground-truth (GT). In this example, we read a batch images of size \n",
    "    #self.batch and return an array of form[image_batch, GT]\n",
    "    def __getitem__(self, idx):\n",
    "#         if self.name == 'val':\n",
    "        #print('idx', idx)\n",
    "        #print(\"DEBUG\", self.list_of_files[idx])\n",
    "        #if idx == len(self.list_of_files):\n",
    "            #print(idx, self.list_of_files)\n",
    "        train,Y = get_batch(self.list_of_files[idx])\n",
    "        #print(np.array(train).reshape(-1,TIMESTEPS,1).shape)\n",
    "        #print(\"idx\",idx)\n",
    "        #print(\"LOLILOL\")\n",
    "        #print(train.shape, Y.shape)\n",
    "        train = np.array(train).reshape(-1,TIMESTEPS,1)\n",
    "        #print(train.shape)\n",
    "        Y = np.array(Y).reshape(-1,1)\n",
    "\n",
    "        return (train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 30000, 10)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15000, 10)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15000, 10)         40        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3000, 10)          510       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1500, 10)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1500, 10)          40        \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 300, 10)           510       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 150, 10)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 150, 10)           40        \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 8)                 456       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,665\n",
      "Trainable params: 1,605\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/stephane/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "236/236 [==============================] - 71s 302ms/step - loss: 4.2410 - mean_absolute_error: 4.2410 - val_loss: 3.0862 - val_mean_absolute_error: 3.0862\n",
      "Epoch 2/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 3.0442 - mean_absolute_error: 3.0442 - val_loss: 2.9598 - val_mean_absolute_error: 2.9598\n",
      "Epoch 3/500\n",
      "236/236 [==============================] - 64s 272ms/step - loss: 2.9812 - mean_absolute_error: 2.9812 - val_loss: 2.8881 - val_mean_absolute_error: 2.8881\n",
      "Epoch 4/500\n",
      "236/236 [==============================] - 64s 272ms/step - loss: 2.9239 - mean_absolute_error: 2.9239 - val_loss: 2.8493 - val_mean_absolute_error: 2.8493\n",
      "Epoch 5/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.8911 - mean_absolute_error: 2.8911 - val_loss: 2.8587 - val_mean_absolute_error: 2.8587\n",
      "Epoch 6/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.8452 - mean_absolute_error: 2.8452 - val_loss: 2.7963 - val_mean_absolute_error: 2.7963\n",
      "Epoch 7/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.7905 - mean_absolute_error: 2.7905 - val_loss: 2.6879 - val_mean_absolute_error: 2.6879\n",
      "Epoch 8/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.7218 - mean_absolute_error: 2.7218 - val_loss: 2.6900 - val_mean_absolute_error: 2.6900\n",
      "Epoch 9/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.6749 - mean_absolute_error: 2.6749 - val_loss: 2.6061 - val_mean_absolute_error: 2.6061\n",
      "Epoch 10/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.6333 - mean_absolute_error: 2.6333 - val_loss: 2.5707 - val_mean_absolute_error: 2.5707\n",
      "Epoch 11/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.6121 - mean_absolute_error: 2.6121 - val_loss: 2.6267 - val_mean_absolute_error: 2.6267\n",
      "Epoch 12/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.5789 - mean_absolute_error: 2.5789 - val_loss: 2.5476 - val_mean_absolute_error: 2.5476\n",
      "Epoch 13/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.5805 - mean_absolute_error: 2.5805 - val_loss: 2.6096 - val_mean_absolute_error: 2.6096\n",
      "Epoch 14/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.5623 - mean_absolute_error: 2.5623 - val_loss: 2.6741 - val_mean_absolute_error: 2.6741\n",
      "Epoch 15/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.5498 - mean_absolute_error: 2.5498 - val_loss: 2.6347 - val_mean_absolute_error: 2.6347\n",
      "Epoch 16/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.5355 - mean_absolute_error: 2.5355 - val_loss: 2.5164 - val_mean_absolute_error: 2.5164\n",
      "Epoch 17/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.5143 - mean_absolute_error: 2.5143 - val_loss: 2.5177 - val_mean_absolute_error: 2.5177\n",
      "Epoch 18/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.5205 - mean_absolute_error: 2.5205 - val_loss: 2.5507 - val_mean_absolute_error: 2.5507\n",
      "Epoch 19/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.5096 - mean_absolute_error: 2.5096 - val_loss: 2.6550 - val_mean_absolute_error: 2.6550\n",
      "Epoch 20/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.4906 - mean_absolute_error: 2.4906 - val_loss: 2.7371 - val_mean_absolute_error: 2.7371\n",
      "Epoch 21/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.4818 - mean_absolute_error: 2.4818 - val_loss: 2.6069 - val_mean_absolute_error: 2.6069\n",
      "Epoch 22/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.4669 - mean_absolute_error: 2.4669 - val_loss: 2.4612 - val_mean_absolute_error: 2.4612\n",
      "Epoch 23/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.4611 - mean_absolute_error: 2.4611 - val_loss: 3.0525 - val_mean_absolute_error: 3.0525\n",
      "Epoch 24/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.4574 - mean_absolute_error: 2.4574 - val_loss: 2.5945 - val_mean_absolute_error: 2.5945\n",
      "Epoch 25/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.4485 - mean_absolute_error: 2.4485 - val_loss: 2.5684 - val_mean_absolute_error: 2.5684\n",
      "Epoch 26/500\n",
      "235/236 [============================>.] - ETA: 0s - loss: 2.4451 - mean_absolute_error: 2.4451Epoch 26/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.4437 - mean_absolute_error: 2.4437 - val_loss: 2.6997 - val_mean_absolute_error: 2.6997\n",
      "Epoch 27/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.4352 - mean_absolute_error: 2.4352 - val_loss: 2.4166 - val_mean_absolute_error: 2.4166\n",
      "Epoch 28/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.4304 - mean_absolute_error: 2.4304 - val_loss: 2.6401 - val_mean_absolute_error: 2.6401\n",
      "Epoch 29/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.4171 - mean_absolute_error: 2.4171 - val_loss: 3.2721 - val_mean_absolute_error: 3.2721\n",
      "Epoch 30/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.4205 - mean_absolute_error: 2.4205 - val_loss: 2.7120 - val_mean_absolute_error: 2.7120\n",
      "Epoch 31/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.4261 - mean_absolute_error: 2.4261 - val_loss: 2.5109 - val_mean_absolute_error: 2.5109\n",
      "Epoch 32/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.4027 - mean_absolute_error: 2.4027 - val_loss: 3.4823 - val_mean_absolute_error: 3.4823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "235/236 [============================>.] - ETA: 0s - loss: 2.4125 - mean_absolute_error: 2.4125Epoch 33/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.4137 - mean_absolute_error: 2.4137 - val_loss: 2.6802 - val_mean_absolute_error: 2.6802\n",
      "Epoch 34/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3908 - mean_absolute_error: 2.3908 - val_loss: 2.7315 - val_mean_absolute_error: 2.7315\n",
      "Epoch 35/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3929 - mean_absolute_error: 2.3929 - val_loss: 3.7560 - val_mean_absolute_error: 3.7560\n",
      "Epoch 36/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3683 - mean_absolute_error: 2.3683 - val_loss: 2.5474 - val_mean_absolute_error: 2.5474\n",
      "Epoch 37/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3634 - mean_absolute_error: 2.3634 - val_loss: 2.5316 - val_mean_absolute_error: 2.5316\n",
      "Epoch 38/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.3649 - mean_absolute_error: 2.3649 - val_loss: 2.9477 - val_mean_absolute_error: 2.9477\n",
      "Epoch 39/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3744 - mean_absolute_error: 2.3744 - val_loss: 2.4845 - val_mean_absolute_error: 2.4845\n",
      "Epoch 40/500\n",
      "\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3748 - mean_absolute_error: 2.3748 - val_loss: 3.0633 - val_mean_absolute_error: 3.0633\n",
      "Epoch 41/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3668 - mean_absolute_error: 2.3668 - val_loss: 2.6316 - val_mean_absolute_error: 2.6316\n",
      "Epoch 42/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3684 - mean_absolute_error: 2.3684 - val_loss: 3.4029 - val_mean_absolute_error: 3.4029\n",
      "Epoch 43/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3550 - mean_absolute_error: 2.3550 - val_loss: 2.4182 - val_mean_absolute_error: 2.4182\n",
      "Epoch 44/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3618 - mean_absolute_error: 2.3618 - val_loss: 2.3334 - val_mean_absolute_error: 2.3334\n",
      "Epoch 45/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3443 - mean_absolute_error: 2.3443 - val_loss: 2.7073 - val_mean_absolute_error: 2.7073\n",
      "Epoch 46/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3483 - mean_absolute_error: 2.3483 - val_loss: 3.9901 - val_mean_absolute_error: 3.9901\n",
      "Epoch 47/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3438 - mean_absolute_error: 2.3438 - val_loss: 3.1880 - val_mean_absolute_error: 3.1880\n",
      "Epoch 48/500\n",
      "235/236 [============================>.] - ETA: 0s - loss: 2.3382 - mean_absolute_error: 2.3382\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3346 - mean_absolute_error: 2.3346 - val_loss: 2.7363 - val_mean_absolute_error: 2.7363\n",
      "Epoch 49/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3382 - mean_absolute_error: 2.3382 - val_loss: 2.4127 - val_mean_absolute_error: 2.4127\n",
      "Epoch 50/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.3493 - mean_absolute_error: 2.3493 - val_loss: 2.9703 - val_mean_absolute_error: 2.9703\n",
      "Epoch 51/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3386 - mean_absolute_error: 2.3386 - val_loss: 2.3614 - val_mean_absolute_error: 2.3614\n",
      "Epoch 52/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3338 - mean_absolute_error: 2.3338 - val_loss: 3.0638 - val_mean_absolute_error: 3.0638\n",
      "Epoch 53/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3264 - mean_absolute_error: 2.3264 - val_loss: 2.3567 - val_mean_absolute_error: 2.3567\n",
      "Epoch 54/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3176 - mean_absolute_error: 2.3176 - val_loss: 2.3345 - val_mean_absolute_error: 2.3345\n",
      "Epoch 55/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3250 - mean_absolute_error: 2.3250 - val_loss: 2.9254 - val_mean_absolute_error: 2.9254\n",
      "Epoch 56/500\n",
      "236/236 [==============================] - 65s 275ms/step - loss: 2.3181 - mean_absolute_error: 2.3181 - val_loss: 2.3402 - val_mean_absolute_error: 2.3402\n",
      "Epoch 57/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.3059 - mean_absolute_error: 2.3059 - val_loss: 3.1816 - val_mean_absolute_error: 3.1816\n",
      "Epoch 58/500\n",
      "236/236 [==============================] - 64s 273ms/step - loss: 2.3075 - mean_absolute_error: 2.3075 - val_loss: 3.0108 - val_mean_absolute_error: 3.0108\n",
      "Epoch 59/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3256 - mean_absolute_error: 2.3256 - val_loss: 2.3205 - val_mean_absolute_error: 2.3205\n",
      "Epoch 60/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3128 - mean_absolute_error: 2.3128 - val_loss: 2.5554 - val_mean_absolute_error: 2.5554\n",
      "Epoch 61/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3325 - mean_absolute_error: 2.3325 - val_loss: 2.5589 - val_mean_absolute_error: 2.5589\n",
      "Epoch 62/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3153 - mean_absolute_error: 2.3153 - val_loss: 3.7685 - val_mean_absolute_error: 3.7685\n",
      "Epoch 63/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.3109 - mean_absolute_error: 2.3109 - val_loss: 2.6073 - val_mean_absolute_error: 2.6073\n",
      "Epoch 64/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.3103 - mean_absolute_error: 2.3103 - val_loss: 2.4714 - val_mean_absolute_error: 2.4714\n",
      "Epoch 65/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3074 - mean_absolute_error: 2.3074 - val_loss: 2.3566 - val_mean_absolute_error: 2.3566\n",
      "Epoch 66/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.2861 - mean_absolute_error: 2.2861 - val_loss: 4.4932 - val_mean_absolute_error: 4.4932\n",
      "Epoch 67/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.3053 - mean_absolute_error: 2.3053 - val_loss: 3.0462 - val_mean_absolute_error: 3.0462\n",
      "Epoch 68/500\n",
      "235/236 [============================>.] - ETA: 0s - loss: 2.2870 - mean_absolute_error: 2.2870Epoch 68/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.2870 - mean_absolute_error: 2.2870 - val_loss: 2.3408 - val_mean_absolute_error: 2.3408\n",
      "Epoch 69/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.3052 - mean_absolute_error: 2.3052 - val_loss: 5.1687 - val_mean_absolute_error: 5.1687\n",
      "Epoch 70/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.2973 - mean_absolute_error: 2.2973 - val_loss: 2.7668 - val_mean_absolute_error: 2.7668\n",
      "Epoch 71/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.3075 - mean_absolute_error: 2.3075 - val_loss: 3.5743 - val_mean_absolute_error: 3.5743\n",
      "Epoch 72/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.2936 - mean_absolute_error: 2.2936 - val_loss: 4.4340 - val_mean_absolute_error: 4.4340\n",
      "Epoch 73/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2957 - mean_absolute_error: 2.2957 - val_loss: 2.4893 - val_mean_absolute_error: 2.4893\n",
      "Epoch 74/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.2813 - mean_absolute_error: 2.2813 - val_loss: 2.5466 - val_mean_absolute_error: 2.5466\n",
      "Epoch 75/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2964 - mean_absolute_error: 2.2964 - val_loss: 2.6218 - val_mean_absolute_error: 2.6218\n",
      "Epoch 76/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.2764 - mean_absolute_error: 2.2764 - val_loss: 3.1026 - val_mean_absolute_error: 3.1026\n",
      "Epoch 77/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2920 - mean_absolute_error: 2.2920 - val_loss: 2.3195 - val_mean_absolute_error: 2.3195\n",
      "Epoch 78/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2780 - mean_absolute_error: 2.2780 - val_loss: 2.4717 - val_mean_absolute_error: 2.4717\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 64s 270ms/step - loss: 2.3006 - mean_absolute_error: 2.3006 - val_loss: 2.3120 - val_mean_absolute_error: 2.3120\n",
      "Epoch 80/500\n",
      "236/236 [==============================] - 64s 271ms/step - loss: 2.2760 - mean_absolute_error: 2.2760 - val_loss: 2.9535 - val_mean_absolute_error: 2.9535\n",
      "Epoch 81/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.2695 - mean_absolute_error: 2.2695 - val_loss: 2.5588 - val_mean_absolute_error: 2.5588\n",
      "Epoch 82/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2881 - mean_absolute_error: 2.2881 - val_loss: 3.2823 - val_mean_absolute_error: 3.2823\n",
      "Epoch 83/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2736 - mean_absolute_error: 2.2736 - val_loss: 2.2653 - val_mean_absolute_error: 2.2653\n",
      "Epoch 84/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.2744 - mean_absolute_error: 2.2744 - val_loss: 2.3519 - val_mean_absolute_error: 2.3519\n",
      "Epoch 85/500\n",
      "236/236 [==============================] - 63s 265ms/step - loss: 2.2818 - mean_absolute_error: 2.2818 - val_loss: 2.9788 - val_mean_absolute_error: 2.9788\n",
      "Epoch 86/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2793 - mean_absolute_error: 2.2793 - val_loss: 3.6985 - val_mean_absolute_error: 3.6985\n",
      "Epoch 87/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2882 - mean_absolute_error: 2.2882 - val_loss: 2.3169 - val_mean_absolute_error: 2.3169\n",
      "Epoch 88/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2664 - mean_absolute_error: 2.2664 - val_loss: 4.1733 - val_mean_absolute_error: 4.1733\n",
      "Epoch 89/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2833 - mean_absolute_error: 2.2833 - val_loss: 2.3158 - val_mean_absolute_error: 2.3158\n",
      "Epoch 90/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2954 - mean_absolute_error: 2.2954 - val_loss: 2.2880 - val_mean_absolute_error: 2.2880\n",
      "Epoch 91/500\n",
      "236/236 [==============================] - 63s 269ms/step - loss: 2.2754 - mean_absolute_error: 2.2754 - val_loss: 2.3475 - val_mean_absolute_error: 2.3475\n",
      "Epoch 92/500\n",
      "236/236 [==============================] - 63s 266ms/step - loss: 2.2671 - mean_absolute_error: 2.2671 - val_loss: 3.9560 - val_mean_absolute_error: 3.9560\n",
      "Epoch 93/500\n",
      "236/236 [==============================] - 63s 267ms/step - loss: 2.2640 - mean_absolute_error: 2.2640 - val_loss: 2.6477 - val_mean_absolute_error: 2.6477\n",
      "Epoch 94/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.2698 - mean_absolute_error: 2.2698 - val_loss: 2.3050 - val_mean_absolute_error: 2.3050\n",
      "Epoch 95/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2824 - mean_absolute_error: 2.2824 - val_loss: 4.0798 - val_mean_absolute_error: 4.0798\n",
      "Epoch 96/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2596 - mean_absolute_error: 2.2596 - val_loss: 2.8594 - val_mean_absolute_error: 2.8594\n",
      "Epoch 97/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2585 - mean_absolute_error: 2.2585 - val_loss: 4.1253 - val_mean_absolute_error: 4.1253\n",
      "Epoch 98/500\n",
      "236/236 [==============================] - 64s 269ms/step - loss: 2.2610 - mean_absolute_error: 2.2610 - val_loss: 5.2151 - val_mean_absolute_error: 5.2151\n",
      "Epoch 99/500\n",
      "236/236 [==============================] - 63s 268ms/step - loss: 2.2764 - mean_absolute_error: 2.2764 - val_loss: 3.9822 - val_mean_absolute_error: 3.9822\n",
      "Epoch 100/500\n",
      "236/236 [==============================] - 64s 270ms/step - loss: 2.2580 - mean_absolute_error: 2.2580 - val_loss: 2.9860 - val_mean_absolute_error: 2.9860\n",
      "Epoch 101/500\n",
      "176/236 [=====================>........] - ETA: 14s - loss: 2.2832 - mean_absolute_error: 2.2832"
     ]
    }
   ],
   "source": [
    "#train_data, val_data, y_train, y_val = train_test_split(training, targets, test_size=0.1, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Flatten,GRU,Conv1D,TimeDistributed,MaxPooling1D,Flatten,CuDNNGRU,CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "TIMESTEPS=150000\n",
    "\n",
    "dropout=0.2\n",
    "\n",
    "kernel_size=5\n",
    "filters=10\n",
    "strides=5\n",
    "pool_size=2\n",
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, #activation='relu',\n",
    "               strides=strides, input_shape=(TIMESTEPS,1))\n",
    ")\n",
    "             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "my_model.add(BatchNormalization())\n",
    "\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, #activation='relu',\n",
    "               strides=strides, input_shape=(TIMESTEPS,1))\n",
    ")             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "my_model.add(BatchNormalization())\n",
    "\n",
    "my_model.add(\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, #activation='relu',\n",
    "               strides=strides, input_shape=(TIMESTEPS,1))\n",
    ")             \n",
    "my_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "my_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "my_model.add(GRU(units = 8,dropout=dropout,recurrent_dropout=dropout))\n",
    "\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "my_model.compile(loss = 'mae',optimizer = 'adam', metrics = ['mean_absolute_error'])\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=30, verbose=0),\n",
    "    #Reseter()\n",
    "]\n",
    "\n",
    "my_training_batch_generator = MY_Generator(train_data_batch, NUMBER_OF_BATCHES, 'train')\n",
    "my_validation_batch_generator = MY_Generator(val_data_batch, NUMBER_OF_VALIDATION_STEPS, 'val')\n",
    "\n",
    "\n",
    "history = my_model.fit_generator(generator=my_training_batch_generator,\n",
    "                                          #steps_per_epoch=NUMBER_OF_BATCHES,\n",
    "                                          epochs=500,\n",
    "                                          validation_data=my_validation_batch_generator,\n",
    "                                          #validation_steps=NUMBER_OF_VALIDATION_STEPS,\n",
    "                                          callbacks=callbacks,\n",
    "                                          shuffle=True,\n",
    "                                          #verbose=1,\n",
    "                                          #validation_data=my_validation_batch_generator,\n",
    "                                          #validation_steps=(num_validation_samples // batch_size),\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=8,\n",
    "                                          #max_queue_size=32\n",
    "                      )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#import math\n",
    "#print(\"best rmse val:\", math.sqrt(my_model.history.history['val_mean_squared_error'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLITS='test'\n",
    "test_splits = [f for f in listdir(TEST_SPLITS) if isfile(join(TEST_SPLITS, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_chunks = np.array_split(test_splits,mp.cpu_count())\n",
    "\n",
    "import build_segment\n",
    "importlib.reload(build_segment)\n",
    "\n",
    "from build_segment import build_segment_f\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    res = [pool.apply_async(build_segment_f,args=[chunk,TIMESTEPS, True]) \\\n",
    "           for chunk in test_split_chunks]\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "preds = []\n",
    "i=0\n",
    "for r in res:\n",
    "    for df in r.get():\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        #training[i] = df.loc[:,df.columns != 'time_to_failure']\n",
    "        ids.append(df['seg_id'].unique()[0].split(\".\")[0])\n",
    "        test_df = df.drop('seg_id', axis=1)\n",
    "        preds.append(my_model.predict(test_df.values.reshape(1,-1,NUMBER_OF_FEATURES))[0][0])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(ids)\n",
    "submission.columns = ['seg_id']\n",
    "submission['time_to_failure'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"time_to_failure\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res[0].get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test/%s' % (np.random.choice(test_splits))\n",
    "#\n",
    "\n",
    "df = pd.read_csv(path, float_precision='round_trip', header=[0])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
